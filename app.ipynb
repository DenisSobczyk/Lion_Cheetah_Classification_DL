{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lion Cheetah Classification task\n",
    "\n",
    "Baed on the following Kaggle data set: https://www.kaggle.com/datasets/mikoajfish99/lions-or-cheetahs-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7f/lz8t8yrj0755nqv_kddd2ps00000gn/T/ipykernel_57482/3672777338.py:7: DeprecationWarning: 'imghdr' is deprecated and slated for removal in Python 3.13\n",
      "  import imghdr\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing dodgy images\n",
    "\n",
    "image_exts = ['jpeg', 'jpg', 'bmp', 'png']\n",
    "\n",
    "data_dir = 'images'\n",
    "for image_class in os.listdir(data_dir):\n",
    "    # Ignore .DS_Store file\n",
    "    if image_class == \".DS_Store\":\n",
    "        continue\n",
    "    \n",
    "    class_dir = os.path.join(data_dir, image_class)\n",
    "    \n",
    "    for image in os.listdir(class_dir):\n",
    "        # Ignore .DS_Store file\n",
    "        if image == \".DS_Store\":\n",
    "            continue\n",
    "        \n",
    "        image_path = os.path.join(class_dir, image)\n",
    "        # Process image_path as needed\n",
    "\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts:\n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print('Issue with image {}'.format(image_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;34m@\u001b[0m\u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0mDatasetV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcollections_abc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtracking_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcomposite_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompositeTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdata_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmetaclass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mABCMeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m\"\"\"Represents a potentially large set of elements.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  The `tf.data.Dataset` API supports writing descriptive and efficient input\u001b[0m\n",
      "\u001b[0;34m  pipelines. `Dataset` usage follows a common pattern:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  1. Create a source dataset from your input data.\u001b[0m\n",
      "\u001b[0;34m  2. Apply dataset transformations to preprocess the data.\u001b[0m\n",
      "\u001b[0;34m  3. Iterate over the dataset and process the elements.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Iteration happens in a streaming fashion, so the full dataset does not need to\u001b[0m\n",
      "\u001b[0;34m  fit into memory.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Source Datasets:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  The simplest way to create a dataset is to create it from a python `list`:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\u001b[0m\n",
      "\u001b[0;34m  >>> for element in dataset:\u001b[0m\n",
      "\u001b[0;34m  ...   print(element)\u001b[0m\n",
      "\u001b[0;34m  tf.Tensor(1, shape=(), dtype=int32)\u001b[0m\n",
      "\u001b[0;34m  tf.Tensor(2, shape=(), dtype=int32)\u001b[0m\n",
      "\u001b[0;34m  tf.Tensor(3, shape=(), dtype=int32)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  To process lines from files, use `tf.data.TextLineDataset`:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  >>> dataset = tf.data.TextLineDataset([\"file1.txt\", \"file2.txt\"])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  To process records written in the `TFRecord` format, use `TFRecordDataset`:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  >>> dataset = tf.data.TFRecordDataset([\"file1.tfrecords\", \"file2.tfrecords\"])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  To create a dataset of all files matching a pattern, use\u001b[0m\n",
      "\u001b[0;34m  `tf.data.Dataset.list_files`:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  ```python\u001b[0m\n",
      "\u001b[0;34m  dataset = tf.data.Dataset.list_files(\"/path/*.txt\")\u001b[0m\n",
      "\u001b[0;34m  ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  See `tf.data.FixedLengthRecordDataset` and `tf.data.Dataset.from_generator`\u001b[0m\n",
      "\u001b[0;34m  for more ways to create datasets.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Transformations:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Once you have a dataset, you can apply transformations to prepare the data for\u001b[0m\n",
      "\u001b[0;34m  your model:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\u001b[0m\n",
      "\u001b[0;34m  >>> dataset = dataset.map(lambda x: x*2)\u001b[0m\n",
      "\u001b[0;34m  >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m  [2, 4, 6]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Common Terms:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  **Element**: A single output from calling `next()` on a dataset iterator.\u001b[0m\n",
      "\u001b[0;34m    Elements may be nested structures containing multiple components. For\u001b[0m\n",
      "\u001b[0;34m    example, the element `(1, (3, \"apple\"))` has one tuple nested in another\u001b[0m\n",
      "\u001b[0;34m    tuple. The components are `1`, `3`, and `\"apple\"`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  **Component**: The leaf in the nested structure of an element.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Supported types:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  Elements can be nested structures of tuples, named tuples, and dictionaries.\u001b[0m\n",
      "\u001b[0;34m  Note that Python lists are *not* treated as nested structures of components.\u001b[0m\n",
      "\u001b[0;34m  Instead, lists are converted to tensors and treated as components. For\u001b[0m\n",
      "\u001b[0;34m  example, the element `(1, [1, 2, 3])` has only two components; the tensor `1`\u001b[0m\n",
      "\u001b[0;34m  and the tensor `[1, 2, 3]`. Element components can be of any type\u001b[0m\n",
      "\u001b[0;34m  representable by `tf.TypeSpec`, including `tf.Tensor`, `tf.data.Dataset`,\u001b[0m\n",
      "\u001b[0;34m  `tf.sparse.SparseTensor`, `tf.RaggedTensor`, and `tf.TensorArray`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  ```python\u001b[0m\n",
      "\u001b[0;34m  a = 1 # Integer element\u001b[0m\n",
      "\u001b[0;34m  b = 2.0 # Float element\u001b[0m\n",
      "\u001b[0;34m  c = (1, 2) # Tuple element with 2 components\u001b[0m\n",
      "\u001b[0;34m  d = {\"a\": (2, 2), \"b\": 3} # Dict element with 3 components\u001b[0m\n",
      "\u001b[0;34m  Point = collections.namedtuple(\"Point\", [\"x\", \"y\"])\u001b[0m\n",
      "\u001b[0;34m  e = Point(1, 2) # Named tuple\u001b[0m\n",
      "\u001b[0;34m  f = tf.data.Dataset.range(10) # Dataset element\u001b[0m\n",
      "\u001b[0;34m  ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m  For more information,\u001b[0m\n",
      "\u001b[0;34m  read [this guide](https://www.tensorflow.org/guide/data).\u001b[0m\n",
      "\u001b[0;34m  \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Creates a DatasetV2 object.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This is a difference between DatasetV1 and DatasetV2. DatasetV1 does not\u001b[0m\n",
      "\u001b[0;34m    take anything in its constructor whereas in the DatasetV2, we expect\u001b[0m\n",
      "\u001b[0;34m    subclasses to create a variant_tensor and pass it in to the super() call.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      variant_tensor: A DT_VARIANT tensor that represents the dataset.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Initialize the options for this dataset and its inputs.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0minput_dataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0minput_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# If the V1 dataset does not have the `_dataset` attribute, we assume it\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# is a dataset source and hence does not have options. Otherwise, we\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# grab the options of `_dataset` object\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"Each input of dataset {type(self)} should be a subclass of \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"`tf.data.Dataset` but encountered \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"{type(input_dataset._dataset)}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0minput_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options_attr\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0minput_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options_attr\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34mf\"Each input of dataset {type(self)} should be a subclass of \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34mf\"`tf.data.Dataset` but encountered {type(input_dataset)}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0minput_options\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mutable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_variant_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor_attr\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_variant_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The `_variant_tensor` property cannot be modified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Use external_state_policy instead\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                               \u001b[0;34m\"allow_stateful\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_as_serialized_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mallow_stateful\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mstrip_device_assignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mexternal_state_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExternalStatePolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Produces serialized graph representation of the dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      allow_stateful: If true, we allow stateful ops to be present in the graph\u001b[0m\n",
      "\u001b[0;34m        def. In that case, the state in these ops would be thrown away.\u001b[0m\n",
      "\u001b[0;34m      strip_device_assignment: If true, non-local (i.e. job and task) device\u001b[0m\n",
      "\u001b[0;34m        assignment is stripped from ops in the serialized graph.\u001b[0m\n",
      "\u001b[0;34m      external_state_policy: The ExternalStatePolicy enum that determines how we\u001b[0m\n",
      "\u001b[0;34m        handle input pipelines that depend on external state. By default, its\u001b[0m\n",
      "\u001b[0;34m        set to WARN.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A scalar `tf.Tensor` of `tf.string` type, representing this dataset as a\u001b[0m\n",
      "\u001b[0;34m      serialized graph.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mexternal_state_policy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexternal_state_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_to_graph_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mexternal_state_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mstrip_device_assignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrip_device_assignment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mstrip_device_assignment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mallow_stateful\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_stateful\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mstrip_device_assignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrip_device_assignment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_stateful\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_stateful\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_track_assets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Finds and tracks nodes in `graph_def` that refer to asset files.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      graph_def: Serialized graph representation of this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A dictionary mapping the node name of an asset constant to a tracked\u001b[0m\n",
      "\u001b[0;34m      `asset.Asset` object.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0masset_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FileIdentity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0masset_tracker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0masset_tracker\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0masset_tracker\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtensor_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CPU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mnode_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_parsing_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m              \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0masset_tracker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_track_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAsset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0masset_tracker\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_trackable_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                          \u001b[0msave_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtracking_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaveType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHECKPOINT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                          \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0msave_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtracking_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaveType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVEDMODEL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# _trace_variant_creation only works when executing eagerly, so we don't\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# want to run it in the object initialization.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mdef_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mresource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace_variant_creation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0m_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Trigger asset tracking\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_variant_tracker\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_VariantTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                                                   \u001b[0m_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_trace_variant_creation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Traces a function which outputs a variant `tf.Tensor` for this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note that creating this function involves evaluating an op, and is currently\u001b[0m\n",
      "\u001b[0;34m    only supported when executing eagerly.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A zero-argument `ConcreteFunction` which outputs a variant `tf.Tensor`.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvariant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;34m\"Constructing a tf.function that reproduces a given dataset is only \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;34m\"supported for datasets created eagerly. Please file a feature \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;34m\"request if this is important to you.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CPU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_serialized_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexternal_state_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions_lib\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                                    \u001b[0;34m.\u001b[0m\u001b[0mExternalStatePolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moutput_node_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"_Retval\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moutput_node_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_node_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;34mf\"Dataset graph is expected to only have one return value but found \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;34mf\"{len(output_node_names)} return values: {output_node_names}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moutput_node_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_node_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfile_path_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# When building a tf.function, track files as `saved_model.Asset`s.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilding_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0masset_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_track_assets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0masset_tracker\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0massets_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0masset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0masset_tracker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfile_path_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massets_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Add functions used in this Dataset to the function's graph, since they\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# need to follow it around (and for example be added to a SavedModel which\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# references the dataset).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvariant_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_from_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_node_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\":0\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcaptures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_path_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mused_function\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mused_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariant_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mvariant_function\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Returns a list of the input datasets of the dataset.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{type(self)}._inputs()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_attr\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The `_graph` property cannot be modified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;31m# TODO(jsimsa): Change this to be the transitive closure of functions used\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;31m# by this dataset and its inputs.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mStructuredFunctionWrapper\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Returns a list of functions associated with this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A list of `StructuredFunctionWrapper` objects.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Returns the options tensor for this dataset.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_options_tensor_to_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialized_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Converts options tensor to tf.data.Options object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_options\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mpb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_options_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mserialized_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Returns the options for this dataset and its inputs.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A `tf.data.Options` object representing the dataset options.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options_tensor_to_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mutable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"To make it possible to preserve tf.data options across \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                  \u001b[0;34m\"serialization boundaries, their implementation has moved to \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                  \u001b[0;34m\"be part of the TensorFlow graph. As a consequence, the \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                  \u001b[0;34m\"options value is in general no longer known at graph \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                  \u001b[0;34m\"construction time. Invoking this method in graph mode \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                  \u001b[0;34m\"retains the legacy behavior of the original implementation, \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                  \u001b[0;34m\"but note that the returned value might not reflect the \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                  \u001b[0;34m\"actual value of the options.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options_attr\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_apply_debug_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mdebug_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEBUG_MODE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# Disable autotuning and static optimizations that could introduce\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# parallelism or asynchrony.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautotune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_parallelization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_and_batch_fusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_parallelization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_OptionsDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Creates an iterator for elements of this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The returned iterator implements the Python Iterator protocol.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      An `tf.data.Iterator` for the elements of this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Raises:\u001b[0m\n",
      "\u001b[0;34m      RuntimeError: If not inside of tf.function and not executing eagerly.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`tf.data.Dataset` only supports Python-style \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                         \u001b[0;34m\"iteration in eager mode or within tf.function.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Required as __len__ is defined\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0m__nonzero__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__bool__\u001b[0m  \u001b[0;31m# Python 2 backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Returns the length of the dataset if it is known and finite.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This method requires that you are running in eager mode, and that the\u001b[0m\n",
      "\u001b[0;34m    length of the dataset is known and non-infinite. When the length may be\u001b[0m\n",
      "\u001b[0;34m    unknown or infinite, or if you are running in graph mode, use\u001b[0m\n",
      "\u001b[0;34m    `tf.data.Dataset.cardinality` instead.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      An integer representing the length of the dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Raises:\u001b[0m\n",
      "\u001b[0;34m      RuntimeError: If the dataset length is unknown or infinite, or if eager\u001b[0m\n",
      "\u001b[0;34m        execution is not enabled.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`tf.data.Dataset` only supports `len` in eager mode. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                      \u001b[0;34m\"Use `tf.data.Dataset.cardinality()` instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mINFINITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The dataset is infinite.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mUNKNOWN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The dataset length is unknown.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0melement_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"The type specification of an element of this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\u001b[0m\n",
      "\u001b[0;34m    >>> dataset.element_spec\u001b[0m\n",
      "\u001b[0;34m    TensorSpec(shape=(), dtype=tf.int32, name=None)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    For more information,\u001b[0m\n",
      "\u001b[0;34m    read [this guide](https://www.tensorflow.org/guide/data#dataset_structure).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A (nested) structure of `tf.TypeSpec` objects matching the structure of an\u001b[0m\n",
      "\u001b[0;34m      element of this dataset and specifying the type of individual components.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{type(self)}.element_spec()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetV1Adapter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"<{type_.__name__} element_spec={self.element_spec}>\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m__debug_string__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Returns a string showing the type of the dataset and its inputs.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This string is intended only for debugging purposes, and may change without\u001b[0m\n",
      "\u001b[0;34m    warning.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mto_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Stack of (dataset, depth) pairs.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mwhile\u001b[0m \u001b[0mto_process\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mto_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mas_numpy_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Returns an iterator which converts all elements of the dataset to numpy.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Use `as_numpy_iterator` to inspect the content of your dataset. To see\u001b[0m\n",
      "\u001b[0;34m    element shapes and types, print dataset elements directly instead of using\u001b[0m\n",
      "\u001b[0;34m    `as_numpy_iterator`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\u001b[0m\n",
      "\u001b[0;34m    >>> for element in dataset:\u001b[0m\n",
      "\u001b[0;34m    ...   print(element)\u001b[0m\n",
      "\u001b[0;34m    tf.Tensor(1, shape=(), dtype=int32)\u001b[0m\n",
      "\u001b[0;34m    tf.Tensor(2, shape=(), dtype=int32)\u001b[0m\n",
      "\u001b[0;34m    tf.Tensor(3, shape=(), dtype=int32)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This method requires that you are running in eager mode and the dataset's\u001b[0m\n",
      "\u001b[0;34m    element_spec contains only `TensorSpec` components.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\u001b[0m\n",
      "\u001b[0;34m    >>> for element in dataset.as_numpy_iterator():\u001b[0m\n",
      "\u001b[0;34m    ...   print(element)\u001b[0m\n",
      "\u001b[0;34m    1\u001b[0m\n",
      "\u001b[0;34m    2\u001b[0m\n",
      "\u001b[0;34m    3\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\u001b[0m\n",
      "\u001b[0;34m    >>> print(list(dataset.as_numpy_iterator()))\u001b[0m\n",
      "\u001b[0;34m    [1, 2, 3]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    `as_numpy_iterator()` will preserve the nested structure of dataset\u001b[0m\n",
      "\u001b[0;34m    elements.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]),\u001b[0m\n",
      "\u001b[0;34m    ...                                               'b': [5, 6]})\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator()) == [{'a': (1, 3), 'b': 5},\u001b[0m\n",
      "\u001b[0;34m    ...                                       {'a': (2, 4), 'b': 6}]\u001b[0m\n",
      "\u001b[0;34m    True\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      An iterable over the elements of the dataset, with their tensors converted\u001b[0m\n",
      "\u001b[0;34m      to numpy arrays.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Raises:\u001b[0m\n",
      "\u001b[0;34m      TypeError: if an element contains a non-`Tensor` value.\u001b[0m\n",
      "\u001b[0;34m      RuntimeError: if eager execution is not enabled.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`tf.data.Dataset.as_numpy_iterator()` is only \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                         \u001b[0;34m\"supported in eager mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mcomponent_spec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mcomponent_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;34m(\u001b[0m\u001b[0mtensor_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mragged_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRaggedTensorSpec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m           \u001b[0msparse_tensor_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensorSpec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoneTensorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34mf\"`tf.data.Dataset.as_numpy_iterator()` is not supported for \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34mf\"datasets that produce values of type {component_spec.value_type}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mNumpyIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_flat_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Returns a list `tf.TensorShapes`s for the element tensor representation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A list `tf.TensorShapes`s for the element tensor representation.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flat_tensor_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_flat_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Returns a list `tf.DType`s for the element tensor representation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A list `tf.DType`s for the element tensor representation.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flat_tensor_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_flat_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Helper for setting `output_shapes` and `output_types` attrs of an op.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Most dataset op constructors expect `output_shapes` and `output_types`\u001b[0m\n",
      "\u001b[0;34m    arguments that represent the flattened structure of an element. This helper\u001b[0m\n",
      "\u001b[0;34m    function generates these attrs as a keyword argument dictionary, allowing\u001b[0m\n",
      "\u001b[0;34m    `Dataset._variant_tensor` implementations to pass `**self._flat_structure`\u001b[0m\n",
      "\u001b[0;34m    to the op constructor.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A dictionary of keyword arguments that can be passed to a dataset op\u001b[0m\n",
      "\u001b[0;34m      constructor.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"output_shapes\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Helper for generating dataset metadata.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_metadata_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_and_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_common_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Helper for generating arguments that are common across most dataset ops.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Most dataset op constructors expect `output_shapes` and `output_types`\u001b[0m\n",
      "\u001b[0;34m    arguments that represent the flattened structure of an element, as well as a\u001b[0m\n",
      "\u001b[0;34m    `metadata` argument for additional metadata such as user-defined dataset\u001b[0m\n",
      "\u001b[0;34m    name. This helper function generates common attributes as a keyword argument\u001b[0m\n",
      "\u001b[0;34m    dictionary, allowing `Dataset._variant_tensor` implementations to pass\u001b[0m\n",
      "\u001b[0;34m    `**self._common_args` to the op constructor.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A dictionary of keyword arguments that can be passed to a dataset op\u001b[0m\n",
      "\u001b[0;34m      constructor.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"output_shapes\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_type_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Creates a `Dataset` with a single element, comprising the given tensors.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    `from_tensors` produces a dataset containing only a single element. To slice\u001b[0m\n",
      "\u001b[0;34m    the input tensor into multiple elements, use `from_tensor_slices` instead.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensors([1, 2, 3])\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [array([1, 2, 3], dtype=int32)]\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensors(([1, 2, 3], 'A'))\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [(array([1, 2, 3], dtype=int32), b'A')]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> # You can use `from_tensors` to produce a dataset which repeats\u001b[0m\n",
      "\u001b[0;34m    >>> # the same example many times.\u001b[0m\n",
      "\u001b[0;34m    >>> example = tf.constant([1,2,3])\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensors(example).repeat(2)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [array([1, 2, 3], dtype=int32), array([1, 2, 3], dtype=int32)]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note that if `tensors` contains a NumPy array, and eager execution is not\u001b[0m\n",
      "\u001b[0;34m    enabled, the values will be embedded in the graph as one or more\u001b[0m\n",
      "\u001b[0;34m    `tf.constant` operations. For large datasets (> 1 GB), this can waste\u001b[0m\n",
      "\u001b[0;34m    memory and run into byte limits of graph serialization. If `tensors`\u001b[0m\n",
      "\u001b[0;34m    contains one or more large NumPy arrays, consider the alternative described\u001b[0m\n",
      "\u001b[0;34m    in [this\u001b[0m\n",
      "\u001b[0;34m    guide](https://tensorflow.org/guide/data#consuming_numpy_arrays).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      tensors: A dataset \"element\". Supported values are documented\u001b[0m\n",
      "\u001b[0;34m        [here](https://www.tensorflow.org/guide/data#dataset_structure).\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      Dataset: A `Dataset`.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# from_tensors_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_tensors_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mfrom_tensors_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The given tensors are sliced along their first dimension. This operation\u001b[0m\n",
      "\u001b[0;34m    preserves the structure of the input tensors, removing the first dimension\u001b[0m\n",
      "\u001b[0;34m    of each tensor and using it as the dataset dimension. All input tensors\u001b[0m\n",
      "\u001b[0;34m    must have the same size in their first dimensions.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> # Slicing a 1D tensor produces scalar tensor elements.\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [1, 2, 3]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> # Slicing a 2D tensor produces 1D tensor elements.\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [array([1, 2], dtype=int32), array([3, 4], dtype=int32)]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> # Slicing a tuple of 1D tensors produces tuple elements containing\u001b[0m\n",
      "\u001b[0;34m    >>> # scalar tensors.\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6]))\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [(1, 3, 5), (2, 4, 6)]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> # Dictionary structure is also preserved.\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]})\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator()) == [{'a': 1, 'b': 3},\u001b[0m\n",
      "\u001b[0;34m    ...                                       {'a': 2, 'b': 4}]\u001b[0m\n",
      "\u001b[0;34m    True\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> # Two tensors can be combined into one Dataset object.\u001b[0m\n",
      "\u001b[0;34m    >>> features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor\u001b[0m\n",
      "\u001b[0;34m    >>> labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = Dataset.from_tensor_slices((features, labels))\u001b[0m\n",
      "\u001b[0;34m    >>> # Both the features and the labels tensors can be converted\u001b[0m\n",
      "\u001b[0;34m    >>> # to a Dataset object separately and combined after.\u001b[0m\n",
      "\u001b[0;34m    >>> features_dataset = Dataset.from_tensor_slices(features)\u001b[0m\n",
      "\u001b[0;34m    >>> labels_dataset = Dataset.from_tensor_slices(labels)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = Dataset.zip((features_dataset, labels_dataset))\u001b[0m\n",
      "\u001b[0;34m    >>> # A batched feature and label set can be converted to a Dataset\u001b[0m\n",
      "\u001b[0;34m    >>> # in similar fashion.\u001b[0m\n",
      "\u001b[0;34m    >>> batched_features = tf.constant([[[1, 3], [2, 3]],\u001b[0m\n",
      "\u001b[0;34m    ...                                 [[2, 1], [1, 2]],\u001b[0m\n",
      "\u001b[0;34m    ...                                 [[3, 3], [3, 2]]], shape=(3, 2, 2))\u001b[0m\n",
      "\u001b[0;34m    >>> batched_labels = tf.constant([['A', 'A'],\u001b[0m\n",
      "\u001b[0;34m    ...                               ['B', 'B'],\u001b[0m\n",
      "\u001b[0;34m    ...                               ['A', 'B']], shape=(3, 2, 1))\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = Dataset.from_tensor_slices((batched_features, batched_labels))\u001b[0m\n",
      "\u001b[0;34m    >>> for element in dataset.as_numpy_iterator():\u001b[0m\n",
      "\u001b[0;34m    ...   print(element)\u001b[0m\n",
      "\u001b[0;34m    (array([[1, 3],\u001b[0m\n",
      "\u001b[0;34m           [2, 3]], dtype=int32), array([[b'A'],\u001b[0m\n",
      "\u001b[0;34m           [b'A']], dtype=object))\u001b[0m\n",
      "\u001b[0;34m    (array([[2, 1],\u001b[0m\n",
      "\u001b[0;34m           [1, 2]], dtype=int32), array([[b'B'],\u001b[0m\n",
      "\u001b[0;34m           [b'B']], dtype=object))\u001b[0m\n",
      "\u001b[0;34m    (array([[3, 3],\u001b[0m\n",
      "\u001b[0;34m           [3, 2]], dtype=int32), array([[b'A'],\u001b[0m\n",
      "\u001b[0;34m           [b'B']], dtype=object))\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note that if `tensors` contains a NumPy array, and eager execution is not\u001b[0m\n",
      "\u001b[0;34m    enabled, the values will be embedded in the graph as one or more\u001b[0m\n",
      "\u001b[0;34m    `tf.constant` operations. For large datasets (> 1 GB), this can waste\u001b[0m\n",
      "\u001b[0;34m    memory and run into byte limits of graph serialization. If `tensors`\u001b[0m\n",
      "\u001b[0;34m    contains one or more large NumPy arrays, consider the alternative described\u001b[0m\n",
      "\u001b[0;34m    in [this guide](\u001b[0m\n",
      "\u001b[0;34m    https://tensorflow.org/guide/data#consuming_numpy_arrays).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      tensors: A dataset element, whose components have the same first\u001b[0m\n",
      "\u001b[0;34m        dimension. Supported values are documented\u001b[0m\n",
      "\u001b[0;34m        [here](https://www.tensorflow.org/guide/data#dataset_structure).\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      Dataset: A `Dataset`.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# from_tensor_slices_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_tensor_slices_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mfrom_tensor_slices_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Stores outstanding iterators created from a Python generator.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This class keeps track of potentially multiple iterators that may have\u001b[0m\n",
      "\u001b[0;34m    been created from a generator, e.g. in the case that the dataset is\u001b[0m\n",
      "\u001b[0;34m    repeated, or nested within a parallel computation.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# GUARDED_BY(self._lock)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_normalize_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# In debug mode, iterator ids may be eagerly-generated np.arrays instead\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# of Tensors. We convert them to scalars to make them hashable.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mget_next_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_id\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_id\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# NOTE(mrry): Explicitly create an array of `np.int64` because implicit\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# casting in `py_func()` will create an array of `np.int32` on Windows,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# leading to a runtime error.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mget_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0miterator_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0miterator_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Use output_signature instead\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                               \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_shapes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mfrom_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0moutput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0moutput_signature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Creates a `Dataset` whose elements are generated by `generator`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note: The current implementation of `Dataset.from_generator()` uses\u001b[0m\n",
      "\u001b[0;34m    `tf.numpy_function` and inherits the same constraints. In particular, it\u001b[0m\n",
      "\u001b[0;34m    requires the dataset and iterator related operations to be placed\u001b[0m\n",
      "\u001b[0;34m    on a device in the same process as the Python program that called\u001b[0m\n",
      "\u001b[0;34m    `Dataset.from_generator()`. In particular, using `from_generator` will\u001b[0m\n",
      "\u001b[0;34m    preclude the use of tf.data service for scaling out dataset processing.\u001b[0m\n",
      "\u001b[0;34m    The body of `generator` will not be serialized in a `GraphDef`, and you\u001b[0m\n",
      "\u001b[0;34m    should not use this method if you need to serialize your model and restore\u001b[0m\n",
      "\u001b[0;34m    it in a different environment.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The `generator` argument must be a callable object that returns\u001b[0m\n",
      "\u001b[0;34m    an object that supports the `iter()` protocol (e.g. a generator function).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The elements generated by `generator` must be compatible with either the\u001b[0m\n",
      "\u001b[0;34m    given `output_signature` argument or with the given `output_types` and\u001b[0m\n",
      "\u001b[0;34m    (optionally) `output_shapes` arguments, whichever was specified.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The recommended way to call `from_generator` is to use the\u001b[0m\n",
      "\u001b[0;34m    `output_signature` argument. In this case the output will be assumed to\u001b[0m\n",
      "\u001b[0;34m    consist of objects with the classes, shapes and types defined by\u001b[0m\n",
      "\u001b[0;34m    `tf.TypeSpec` objects from `output_signature` argument:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> def gen():\u001b[0m\n",
      "\u001b[0;34m    ...   ragged_tensor = tf.ragged.constant([[1, 2], [3]])\u001b[0m\n",
      "\u001b[0;34m    ...   yield 42, ragged_tensor\u001b[0m\n",
      "\u001b[0;34m    >>>\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_generator(\u001b[0m\n",
      "\u001b[0;34m    ...      gen,\u001b[0m\n",
      "\u001b[0;34m    ...      output_signature=(\u001b[0m\n",
      "\u001b[0;34m    ...          tf.TensorSpec(shape=(), dtype=tf.int32),\u001b[0m\n",
      "\u001b[0;34m    ...          tf.RaggedTensorSpec(shape=(2, None), dtype=tf.int32)))\u001b[0m\n",
      "\u001b[0;34m    >>>\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.take(1))\u001b[0m\n",
      "\u001b[0;34m    [(<tf.Tensor: shape=(), dtype=int32, numpy=42>,\u001b[0m\n",
      "\u001b[0;34m    <tf.RaggedTensor [[1, 2], [3]]>)]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    There is also a deprecated way to call `from_generator` by either with\u001b[0m\n",
      "\u001b[0;34m    `output_types` argument alone or together with `output_shapes` argument.\u001b[0m\n",
      "\u001b[0;34m    In this case the output of the function will be assumed to consist of\u001b[0m\n",
      "\u001b[0;34m    `tf.Tensor` objects with the types defined by `output_types` and with the\u001b[0m\n",
      "\u001b[0;34m    shapes which are either unknown or defined by `output_shapes`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note: If `generator` depends on mutable global variables or other external\u001b[0m\n",
      "\u001b[0;34m    state, be aware that the runtime may invoke `generator` multiple times\u001b[0m\n",
      "\u001b[0;34m    (in order to support repeating the `Dataset`) and at any time\u001b[0m\n",
      "\u001b[0;34m    between the call to `Dataset.from_generator()` and the production of the\u001b[0m\n",
      "\u001b[0;34m    first element from the generator. Mutating global variables or external\u001b[0m\n",
      "\u001b[0;34m    state can cause undefined behavior, and we recommend that you explicitly\u001b[0m\n",
      "\u001b[0;34m    cache any external state in `generator` before calling\u001b[0m\n",
      "\u001b[0;34m    `Dataset.from_generator()`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note: While the `output_signature` parameter makes it possible to yield\u001b[0m\n",
      "\u001b[0;34m    `Dataset` elements, the scope of `Dataset.from_generator()` should be\u001b[0m\n",
      "\u001b[0;34m    limited to logic that cannot be expressed through tf.data operations. Using\u001b[0m\n",
      "\u001b[0;34m    tf.data operations within the generator function is an anti-pattern and may\u001b[0m\n",
      "\u001b[0;34m    result in incremental memory growth.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      generator: A callable object that returns an object that supports the\u001b[0m\n",
      "\u001b[0;34m        `iter()` protocol. If `args` is not specified, `generator` must take no\u001b[0m\n",
      "\u001b[0;34m        arguments; otherwise it must take as many arguments as there are values\u001b[0m\n",
      "\u001b[0;34m        in `args`.\u001b[0m\n",
      "\u001b[0;34m      output_types: (Optional.) A (nested) structure of `tf.DType` objects\u001b[0m\n",
      "\u001b[0;34m        corresponding to each component of an element yielded by `generator`.\u001b[0m\n",
      "\u001b[0;34m      output_shapes: (Optional.) A (nested) structure of `tf.TensorShape`\u001b[0m\n",
      "\u001b[0;34m        objects corresponding to each component of an element yielded by\u001b[0m\n",
      "\u001b[0;34m        `generator`.\u001b[0m\n",
      "\u001b[0;34m      args: (Optional.) A tuple of `tf.Tensor` objects that will be evaluated\u001b[0m\n",
      "\u001b[0;34m        and passed to `generator` as NumPy-array arguments.\u001b[0m\n",
      "\u001b[0;34m      output_signature: (Optional.) A (nested) structure of `tf.TypeSpec`\u001b[0m\n",
      "\u001b[0;34m        objects corresponding to each component of an element yielded by\u001b[0m\n",
      "\u001b[0;34m        `generator`.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operations used by\u001b[0m\n",
      "\u001b[0;34m        `from_generator`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      Dataset: A `Dataset`.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# from_generator_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_generator_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mfrom_generator_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                                             \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                                             \u001b[0moutput_signature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Creates a `Dataset` of a step-separated range of values.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> list(Dataset.range(5).as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [0, 1, 2, 3, 4]\u001b[0m\n",
      "\u001b[0;34m    >>> list(Dataset.range(2, 5).as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [2, 3, 4]\u001b[0m\n",
      "\u001b[0;34m    >>> list(Dataset.range(1, 5, 2).as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [1, 3]\u001b[0m\n",
      "\u001b[0;34m    >>> list(Dataset.range(1, 5, -2).as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    []\u001b[0m\n",
      "\u001b[0;34m    >>> list(Dataset.range(5, 1).as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    []\u001b[0m\n",
      "\u001b[0;34m    >>> list(Dataset.range(5, 1, -2).as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [5, 3]\u001b[0m\n",
      "\u001b[0;34m    >>> list(Dataset.range(2, 5, output_type=tf.int32).as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [2, 3, 4]\u001b[0m\n",
      "\u001b[0;34m    >>> list(Dataset.range(1, 5, 2, output_type=tf.float32).as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [1.0, 3.0]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      *args: follows the same semantics as python's range.\u001b[0m\n",
      "\u001b[0;34m        len(args) == 1 -> start = 0, stop = args[0], step = 1.\u001b[0m\n",
      "\u001b[0;34m        len(args) == 2 -> start = args[0], stop = args[1], step = 1.\u001b[0m\n",
      "\u001b[0;34m        len(args) == 3 -> start = args[0], stop = args[1], step = args[2].\u001b[0m\n",
      "\u001b[0;34m      **kwargs:\u001b[0m\n",
      "\u001b[0;34m        - output_type: Its expected dtype. (Optional, default: `tf.int64`).\u001b[0m\n",
      "\u001b[0;34m        - name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      Dataset: A `RangeDataset`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Raises:\u001b[0m\n",
      "\u001b[0;34m      ValueError: if len(args) == 0.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops -> range_op ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mrange_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Creates a `Dataset` by zipping together the given datasets.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This method has similar semantics to the built-in `zip()` function\u001b[0m\n",
      "\u001b[0;34m    in Python, with the main difference being that the `datasets`\u001b[0m\n",
      "\u001b[0;34m    argument can be a (nested) structure of `Dataset` objects. The supported\u001b[0m\n",
      "\u001b[0;34m    nesting mechanisms are documented\u001b[0m\n",
      "\u001b[0;34m    [here] (https://www.tensorflow.org/guide/data#dataset_structure).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> # The datasets or nested structure of datasets `*args` argument\u001b[0m\n",
      "\u001b[0;34m    >>> # determines the structure of elements in the resulting dataset.\u001b[0m\n",
      "\u001b[0;34m    >>> a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\u001b[0m\n",
      "\u001b[0;34m    >>> b = tf.data.Dataset.range(4, 7)  # ==> [ 4, 5, 6 ]\u001b[0m\n",
      "\u001b[0;34m    >>> ds = tf.data.Dataset.zip(a, b)\u001b[0m\n",
      "\u001b[0;34m    >>> list(ds.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [(1, 4), (2, 5), (3, 6)]\u001b[0m\n",
      "\u001b[0;34m    >>> ds = tf.data.Dataset.zip(b, a)\u001b[0m\n",
      "\u001b[0;34m    >>> list(ds.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [(4, 1), (5, 2), (6, 3)]\u001b[0m\n",
      "\u001b[0;34m    >>>\u001b[0m\n",
      "\u001b[0;34m    >>> # The `datasets` argument may contain an arbitrary number of datasets.\u001b[0m\n",
      "\u001b[0;34m    >>> c = tf.data.Dataset.range(7, 13).batch(2)  # ==> [ [7, 8],\u001b[0m\n",
      "\u001b[0;34m    ...                                            #       [9, 10],\u001b[0m\n",
      "\u001b[0;34m    ...                                            #       [11, 12] ]\u001b[0m\n",
      "\u001b[0;34m    >>> ds = tf.data.Dataset.zip(a, b, c)\u001b[0m\n",
      "\u001b[0;34m    >>> for element in ds.as_numpy_iterator():\u001b[0m\n",
      "\u001b[0;34m    ...   print(element)\u001b[0m\n",
      "\u001b[0;34m    (1, 4, array([7, 8]))\u001b[0m\n",
      "\u001b[0;34m    (2, 5, array([ 9, 10]))\u001b[0m\n",
      "\u001b[0;34m    (3, 6, array([11, 12]))\u001b[0m\n",
      "\u001b[0;34m    >>>\u001b[0m\n",
      "\u001b[0;34m    >>> # The number of elements in the resulting dataset is the same as\u001b[0m\n",
      "\u001b[0;34m    >>> # the size of the smallest dataset in `datasets`.\u001b[0m\n",
      "\u001b[0;34m    >>> d = tf.data.Dataset.range(13, 15)  # ==> [ 13, 14 ]\u001b[0m\n",
      "\u001b[0;34m    >>> ds = tf.data.Dataset.zip(a, d)\u001b[0m\n",
      "\u001b[0;34m    >>> list(ds.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [(1, 13), (2, 14)]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      *args: Datasets or nested structures of datasets to zip together. This\u001b[0m\n",
      "\u001b[0;34m        can't be set if `datasets` is set.\u001b[0m\n",
      "\u001b[0;34m      datasets: A (nested) structure of datasets. This can't be set if `*args`\u001b[0m\n",
      "\u001b[0;34m        is set. Note that this exists only for backwards compatibility and it is\u001b[0m\n",
      "\u001b[0;34m        preferred to use *args.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops -> zip_op ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzip_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must pass at least one dataset to `zip`.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Both `*args` and `datasets` cannot be set.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mzip_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Creates a `Dataset` by concatenating the given dataset with this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\u001b[0m\n",
      "\u001b[0;34m    >>> b = tf.data.Dataset.range(4, 8)  # ==> [ 4, 5, 6, 7 ]\u001b[0m\n",
      "\u001b[0;34m    >>> ds = a.concatenate(b)\u001b[0m\n",
      "\u001b[0;34m    >>> list(ds.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [1, 2, 3, 4, 5, 6, 7]\u001b[0m\n",
      "\u001b[0;34m    >>> # The input dataset and dataset to be concatenated should have\u001b[0m\n",
      "\u001b[0;34m    >>> # compatible element specs.\u001b[0m\n",
      "\u001b[0;34m    >>> c = tf.data.Dataset.zip((a, b))\u001b[0m\n",
      "\u001b[0;34m    >>> a.concatenate(c)\u001b[0m\n",
      "\u001b[0;34m    Traceback (most recent call last):\u001b[0m\n",
      "\u001b[0;34m    TypeError: Two datasets to concatenate have different types\u001b[0m\n",
      "\u001b[0;34m    <dtype: 'int64'> and (tf.int64, tf.int64)\u001b[0m\n",
      "\u001b[0;34m    >>> d = tf.data.Dataset.from_tensor_slices([\"a\", \"b\", \"c\"])\u001b[0m\n",
      "\u001b[0;34m    >>> a.concatenate(d)\u001b[0m\n",
      "\u001b[0;34m    Traceback (most recent call last):\u001b[0m\n",
      "\u001b[0;34m    TypeError: Two datasets to concatenate have different types\u001b[0m\n",
      "\u001b[0;34m    <dtype: 'int64'> and <dtype: 'string'>\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      dataset: `Dataset` to be concatenated.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# concatenate_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconcatenate_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Creates a `Dataset` that counts from `start` in steps of size `step`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Unlike `tf.data.Dataset.range`, which stops at some ending number,\u001b[0m\n",
      "\u001b[0;34m    `tf.data.Dataset.counter` produces elements indefinitely.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.experimental.Counter().take(5)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [0, 1, 2, 3, 4]\u001b[0m\n",
      "\u001b[0;34m    >>> dataset.element_spec\u001b[0m\n",
      "\u001b[0;34m    TensorSpec(shape=(), dtype=tf.int64, name=None)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.experimental.Counter(dtype=tf.int32)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset.element_spec\u001b[0m\n",
      "\u001b[0;34m    TensorSpec(shape=(), dtype=tf.int32, name=None)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.experimental.Counter(start=2).take(5)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [2, 3, 4, 5, 6]\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.experimental.Counter(start=2, step=5).take(5)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [2, 7, 12, 17, 22]\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.experimental.Counter(start=10, step=-1).take(5)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [10, 9, 8, 7, 6]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      start: (Optional.) The starting value for the counter. Defaults to 0.\u001b[0m\n",
      "\u001b[0;34m      step: (Optional.) The step size for the counter. Defaults to 1.\u001b[0m\n",
      "\u001b[0;34m      dtype: (Optional.) The data type for counter elements. Defaults to\u001b[0m\n",
      "\u001b[0;34m        `tf.int64`.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A `Dataset` of scalar `dtype` elements.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops -> counter_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcounter_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mcounter_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mrebatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Creates a `Dataset` that rebatches the elements from this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    `rebatch(N)` is functionally equivalent to `unbatch().batch(N)`, but is\u001b[0m\n",
      "\u001b[0;34m    more efficient, performing one copy instead of two.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> ds = tf.data.Dataset.range(6)\u001b[0m\n",
      "\u001b[0;34m    >>> ds = ds.batch(2)\u001b[0m\n",
      "\u001b[0;34m    >>> ds = ds.rebatch(3)\u001b[0m\n",
      "\u001b[0;34m    >>> list(ds.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [array([0, 1, 2]), array([3, 4, 5])]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> ds = tf.data.Dataset.range(7)\u001b[0m\n",
      "\u001b[0;34m    >>> ds = ds.batch(4)\u001b[0m\n",
      "\u001b[0;34m    >>> ds = ds.rebatch(3)\u001b[0m\n",
      "\u001b[0;34m    >>> list(ds.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [array([0, 1, 2]), array([3, 4, 5]), array([6])]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> ds = tf.data.Dataset.range(7)\u001b[0m\n",
      "\u001b[0;34m    >>> ds = ds.batch(2)\u001b[0m\n",
      "\u001b[0;34m    >>> ds = ds.rebatch(3, drop_remainder=True)\u001b[0m\n",
      "\u001b[0;34m    >>> list(ds.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [array([0, 1, 2]), array([3, 4, 5])]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    If the `batch_size` argument is a list, `rebatch` cycles through the list\u001b[0m\n",
      "\u001b[0;34m    to determine the size of each batch.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> ds = tf.data.Dataset.range(8)\u001b[0m\n",
      "\u001b[0;34m    >>> ds = ds.batch(4)\u001b[0m\n",
      "\u001b[0;34m    >>> ds = ds.rebatch([2, 1, 1])\u001b[0m\n",
      "\u001b[0;34m    >>> list(ds.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [array([0, 1]), array([2]), array([3]), array([4, 5]), array([6]),\u001b[0m\n",
      "\u001b[0;34m    array([7])]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      batch_size: A `tf.int64` scalar or vector, representing the size of\u001b[0m\n",
      "\u001b[0;34m        batches to produce. If this argument is a vector, these values are\u001b[0m\n",
      "\u001b[0;34m        cycled through in round robin fashion.\u001b[0m\n",
      "\u001b[0;34m      drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\u001b[0m\n",
      "\u001b[0;34m        whether the last batch should be dropped in the case it has fewer than\u001b[0m\n",
      "\u001b[0;34m        `batch_size[cycle_index]` elements; the default behavior is not to drop\u001b[0m\n",
      "\u001b[0;34m        the smaller batch.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A `Dataset` of scalar `dtype` elements.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops -> rebatch_op ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# rebatch_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrebatch_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mrebatch_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Creates a `Dataset` that prefetches elements from this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Most dataset input pipelines should end with a call to `prefetch`. This\u001b[0m\n",
      "\u001b[0;34m    allows later elements to be prepared while the current element is being\u001b[0m\n",
      "\u001b[0;34m    processed. This often improves latency and throughput, at the cost of\u001b[0m\n",
      "\u001b[0;34m    using additional memory to store prefetched elements.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note: Like other `Dataset` methods, prefetch operates on the\u001b[0m\n",
      "\u001b[0;34m    elements of the input dataset. It has no concept of examples vs. batches.\u001b[0m\n",
      "\u001b[0;34m    `examples.prefetch(2)` will prefetch two elements (2 examples),\u001b[0m\n",
      "\u001b[0;34m    while `examples.batch(20).prefetch(2)` will prefetch 2 elements\u001b[0m\n",
      "\u001b[0;34m    (2 batches, of 20 examples each).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(3)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.prefetch(2)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [0, 1, 2]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      buffer_size: A `tf.int64` scalar `tf.Tensor`, representing the maximum\u001b[0m\n",
      "\u001b[0;34m        number of elements that will be buffered when prefetching. If the value\u001b[0m\n",
      "\u001b[0;34m        `tf.data.AUTOTUNE` is used, then the buffer size is dynamically tuned.\u001b[0m\n",
      "\u001b[0;34m      name: Optional. A name for the tf.data transformation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mprefetch_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefetch\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mfile_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"A dataset of all files matching one or more glob patterns.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The `file_pattern` argument should be a small number of glob patterns.\u001b[0m\n",
      "\u001b[0;34m    If your filenames have already been globbed, use\u001b[0m\n",
      "\u001b[0;34m    `Dataset.from_tensor_slices(filenames)` instead, as re-globbing every\u001b[0m\n",
      "\u001b[0;34m    filename with `list_files` may result in poor performance with remote\u001b[0m\n",
      "\u001b[0;34m    storage systems.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note: The default behavior of this method is to return filenames in\u001b[0m\n",
      "\u001b[0;34m    a non-deterministic random shuffled order. Pass a `seed` or `shuffle=False`\u001b[0m\n",
      "\u001b[0;34m    to get results in a deterministic order.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Example:\u001b[0m\n",
      "\u001b[0;34m      If we had the following files on our filesystem:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        - /path/to/dir/a.txt\u001b[0m\n",
      "\u001b[0;34m        - /path/to/dir/b.py\u001b[0m\n",
      "\u001b[0;34m        - /path/to/dir/c.py\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m      If we pass \"/path/to/dir/*.py\" as the directory, the dataset\u001b[0m\n",
      "\u001b[0;34m      would produce:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        - /path/to/dir/b.py\u001b[0m\n",
      "\u001b[0;34m        - /path/to/dir/c.py\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      file_pattern: A string, a list of strings, or a `tf.Tensor` of string type\u001b[0m\n",
      "\u001b[0;34m        (scalar or vector), representing the filename glob (i.e. shell wildcard)\u001b[0m\n",
      "\u001b[0;34m        pattern(s) that will be matched.\u001b[0m\n",
      "\u001b[0;34m      shuffle: (Optional.) If `True`, the file names will be shuffled randomly.\u001b[0m\n",
      "\u001b[0;34m        Defaults to `True`.\u001b[0m\n",
      "\u001b[0;34m      seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\u001b[0m\n",
      "\u001b[0;34m        seed that will be used to create the distribution. See\u001b[0m\n",
      "\u001b[0;34m        `tf.random.set_seed` for behavior.\u001b[0m\n",
      "\u001b[0;34m      name: Optional. A name for the tf.data operations used by `list_files`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m     Dataset: A `Dataset` of strings corresponding to file names.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"list_files\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mfile_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mfile_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"file_pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mmatching_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_io_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatching_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# Raise an exception if `file_pattern` does not match any files.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mcondition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                                   \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"match_not_empty\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;34m\"No files matched pattern: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mstring_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_join\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\", \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"message\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0massert_not_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrol_flow_assert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAssert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"assert_not_empty\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massert_not_empty\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmatching_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# TODO(b/240947712): Remove lazy import after this method is factored out.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# from_tensor_slices_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_tensor_slices_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_tensor_slices_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_TensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mmatching_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetV1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetV1Adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# NOTE(mrry): The shuffle buffer size must be greater than zero, but the\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# list of files might be empty.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mbuffer_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Repeats this dataset so each original value is seen `count` times.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.repeat(3)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [1, 2, 3, 1, 2, 3, 1, 2, 3]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note: If the input dataset depends on global state (e.g. a random number\u001b[0m\n",
      "\u001b[0;34m    generator) or its output is non-deterministic (e.g. because of upstream\u001b[0m\n",
      "\u001b[0;34m    `shuffle`), then different repetitions may produce different elements.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      count: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\u001b[0m\n",
      "\u001b[0;34m        number of times the dataset should be repeated. The default behavior (if\u001b[0m\n",
      "\u001b[0;34m        `count` is `None` or `-1`) is for the dataset be repeated indefinitely.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops -> repeat_op ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access,redefined-outer-name\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrepeat_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mrepeat_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access,redefined-outer-name\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Enumerates the elements of this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    It is similar to python's `enumerate`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.enumerate(start=5)\u001b[0m\n",
      "\u001b[0;34m    >>> for element in dataset.as_numpy_iterator():\u001b[0m\n",
      "\u001b[0;34m    ...   print(element)\u001b[0m\n",
      "\u001b[0;34m    (5, 1)\u001b[0m\n",
      "\u001b[0;34m    (6, 2)\u001b[0m\n",
      "\u001b[0;34m    (7, 3)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> # The (nested) structure of the input dataset determines the\u001b[0m\n",
      "\u001b[0;34m    >>> # structure of elements in the resulting dataset.\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices([(7, 8), (9, 10)])\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.enumerate()\u001b[0m\n",
      "\u001b[0;34m    >>> for element in dataset.as_numpy_iterator():\u001b[0m\n",
      "\u001b[0;34m    ...   print(element)\u001b[0m\n",
      "\u001b[0;34m    (0, array([7, 8], dtype=int32))\u001b[0m\n",
      "\u001b[0;34m    (1, array([ 9, 10], dtype=int32))\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      start: A `tf.int64` scalar `tf.Tensor`, representing the start value for\u001b[0m\n",
      "\u001b[0;34m        enumeration.\u001b[0m\n",
      "\u001b[0;34m      name: Optional. A name for the tf.data operations used by `enumerate`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrange_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Replicate the range component so that each split is enumerated\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# independently. This avoids the need for prohibitively expensive\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# cross-split coordination.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrange_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_apply_rewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"replicate_on_split\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshuffle_each_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Randomly shuffles the elements of this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This dataset fills a buffer with `buffer_size` elements, then randomly\u001b[0m\n",
      "\u001b[0;34m    samples elements from this buffer, replacing the selected elements with new\u001b[0m\n",
      "\u001b[0;34m    elements. For perfect shuffling, a buffer size greater than or equal to the\u001b[0m\n",
      "\u001b[0;34m    full size of the dataset is required.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    For instance, if your dataset contains 10,000 elements but `buffer_size` is\u001b[0m\n",
      "\u001b[0;34m    set to 1,000, then `shuffle` will initially select a random element from\u001b[0m\n",
      "\u001b[0;34m    only the first 1,000 elements in the buffer. Once an element is selected,\u001b[0m\n",
      "\u001b[0;34m    its space in the buffer is replaced by the next (i.e. 1,001-st) element,\u001b[0m\n",
      "\u001b[0;34m    maintaining the 1,000 element buffer.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    `reshuffle_each_iteration` controls whether the shuffle order should be\u001b[0m\n",
      "\u001b[0;34m    different for each epoch. In TF 1.X, the idiomatic way to create epochs\u001b[0m\n",
      "\u001b[0;34m    was through the `repeat` transformation:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```python\u001b[0m\n",
      "\u001b[0;34m    dataset = tf.data.Dataset.range(3)\u001b[0m\n",
      "\u001b[0;34m    dataset = dataset.shuffle(3, reshuffle_each_iteration=True)\u001b[0m\n",
      "\u001b[0;34m    dataset = dataset.repeat(2)\u001b[0m\n",
      "\u001b[0;34m    # [1, 0, 2, 1, 2, 0]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    dataset = tf.data.Dataset.range(3)\u001b[0m\n",
      "\u001b[0;34m    dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\u001b[0m\n",
      "\u001b[0;34m    dataset = dataset.repeat(2)\u001b[0m\n",
      "\u001b[0;34m    # [1, 0, 2, 1, 0, 2]\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    In TF 2.0, `tf.data.Dataset` objects are Python iterables which makes it\u001b[0m\n",
      "\u001b[0;34m    possible to also create epochs through Python iteration:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```python\u001b[0m\n",
      "\u001b[0;34m    dataset = tf.data.Dataset.range(3)\u001b[0m\n",
      "\u001b[0;34m    dataset = dataset.shuffle(3, reshuffle_each_iteration=True)\u001b[0m\n",
      "\u001b[0;34m    list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    # [1, 0, 2]\u001b[0m\n",
      "\u001b[0;34m    list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    # [1, 2, 0]\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```python\u001b[0m\n",
      "\u001b[0;34m    dataset = tf.data.Dataset.range(3)\u001b[0m\n",
      "\u001b[0;34m    dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\u001b[0m\n",
      "\u001b[0;34m    list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    # [1, 0, 2]\u001b[0m\n",
      "\u001b[0;34m    list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    # [1, 0, 2]\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    #### Fully shuffling all the data\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    To shuffle an entire dataset, set `buffer_size=dataset.cardinality(). This\u001b[0m\n",
      "\u001b[0;34m    is equivalent to setting the `buffer_size` equal to the number of elements\u001b[0m\n",
      "\u001b[0;34m    in the dataset, resulting in uniform shuffle.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note: `shuffle(dataset.cardinality())` loads the full dataset into memory so\u001b[0m\n",
      "\u001b[0;34m    that it can be shuffled. This will cause a memory overflow (OOM) error if\u001b[0m\n",
      "\u001b[0;34m    the dataset is too large, so full-shuffle should only be used for datasets\u001b[0m\n",
      "\u001b[0;34m    that are known to fit in the memory, such as datasets of filenames or other\u001b[0m\n",
      "\u001b[0;34m    small datasets.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```python\u001b[0m\n",
      "\u001b[0;34m    dataset = tf.data.Dataset.range(20)\u001b[0m\n",
      "\u001b[0;34m    dataset = dataset.shuffle(dataset.cardinality())\u001b[0m\n",
      "\u001b[0;34m    # [18, 4, 9, 2, 17, 8, 5, 10, 0, 6, 16, 3, 19, 7, 14, 11, 15, 13, 12, 1]\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      buffer_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\u001b[0m\n",
      "\u001b[0;34m        elements from this dataset from which the new dataset will sample. To\u001b[0m\n",
      "\u001b[0;34m        uniformly shuffle the entire dataset, use\u001b[0m\n",
      "\u001b[0;34m        `buffer_size=dataset.cardinality()`.\u001b[0m\n",
      "\u001b[0;34m      seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\u001b[0m\n",
      "\u001b[0;34m        seed that will be used to create the distribution. See\u001b[0m\n",
      "\u001b[0;34m        `tf.random.set_seed` for behavior.\u001b[0m\n",
      "\u001b[0;34m      reshuffle_each_iteration: (Optional.) A boolean, which if true indicates\u001b[0m\n",
      "\u001b[0;34m        that the dataset should be pseudorandomly reshuffled each time it is\u001b[0m\n",
      "\u001b[0;34m        iterated over. (Defaults to `True`.)\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mshuffle_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shuffle\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshuffle_each_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Caches the elements in this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The first time the dataset is iterated over, its elements will be cached\u001b[0m\n",
      "\u001b[0;34m    either in the specified file or in memory. Subsequent iterations will\u001b[0m\n",
      "\u001b[0;34m    use the cached data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note: To guarantee that the cache gets finalized, the input dataset must be\u001b[0m\n",
      "\u001b[0;34m    iterated through in its entirety, until it raises StopIteration. Otherwise,\u001b[0m\n",
      "\u001b[0;34m    subsequent iterations may not use cached data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(5)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.map(lambda x: x**2)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.cache()\u001b[0m\n",
      "\u001b[0;34m    >>> # The first time reading through the data will generate the data using\u001b[0m\n",
      "\u001b[0;34m    >>> # `range` and `map`.\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [0, 1, 4, 9, 16]\u001b[0m\n",
      "\u001b[0;34m    >>> # Subsequent iterations read from the cache.\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [0, 1, 4, 9, 16]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    When caching to a file, the cached data will persist across runs. Even the\u001b[0m\n",
      "\u001b[0;34m    first iteration through the data will read from the cache file. Changing\u001b[0m\n",
      "\u001b[0;34m    the input pipeline before the call to `.cache()` will have no effect until\u001b[0m\n",
      "\u001b[0;34m    the cache file is removed or the filename is changed.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```python\u001b[0m\n",
      "\u001b[0;34m    dataset = tf.data.Dataset.range(5)\u001b[0m\n",
      "\u001b[0;34m    dataset = dataset.cache(\"/path/to/file\")\u001b[0m\n",
      "\u001b[0;34m    list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    # [0, 1, 2, 3, 4]\u001b[0m\n",
      "\u001b[0;34m    dataset = tf.data.Dataset.range(10)\u001b[0m\n",
      "\u001b[0;34m    dataset = dataset.cache(\"/path/to/file\")  # Same file!\u001b[0m\n",
      "\u001b[0;34m    list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    # [0, 1, 2, 3, 4]\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note: `cache` will produce exactly the same elements during each iteration\u001b[0m\n",
      "\u001b[0;34m    through the dataset. If you wish to randomize the iteration order, make sure\u001b[0m\n",
      "\u001b[0;34m    to call `shuffle` *after* calling `cache`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      filename: A `tf.string` scalar `tf.Tensor`, representing the name of a\u001b[0m\n",
      "\u001b[0;34m        directory on the filesystem to use for caching elements in this Dataset.\u001b[0m\n",
      "\u001b[0;34m        If a filename is not provided, the dataset will be cached in memory.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops -> cache_op ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcache_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mcache_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Creates a `Dataset` with at most `count` elements from this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(10)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.take(3)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [0, 1, 2]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      count: A `tf.int64` scalar `tf.Tensor`, representing the number of\u001b[0m\n",
      "\u001b[0;34m        elements of this dataset that should be taken to form the new dataset.\u001b[0m\n",
      "\u001b[0;34m        If `count` is -1, or if `count` is greater than the size of this\u001b[0m\n",
      "\u001b[0;34m        dataset, the new dataset will contain all elements of this dataset.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# take_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtake_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mtake_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Creates a `Dataset` that skips `count` elements from this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(10)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.skip(7)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [7, 8, 9]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      count: A `tf.int64` scalar `tf.Tensor`, representing the number of\u001b[0m\n",
      "\u001b[0;34m        elements of this dataset that should be skipped to form the new dataset.\u001b[0m\n",
      "\u001b[0;34m        If `count` is greater than the size of this dataset, the new dataset\u001b[0m\n",
      "\u001b[0;34m        will contain no elements.  If `count` is -1, skips the entire dataset.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# skip_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mskip_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mskip_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mshard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_shards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Creates a `Dataset` that includes only 1/`num_shards` of this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    `shard` is deterministic. The Dataset produced by `A.shard(n, i)` will\u001b[0m\n",
      "\u001b[0;34m    contain all elements of A whose index mod n = i.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> A = tf.data.Dataset.range(10)\u001b[0m\n",
      "\u001b[0;34m    >>> B = A.shard(num_shards=3, index=0)\u001b[0m\n",
      "\u001b[0;34m    >>> list(B.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [0, 3, 6, 9]\u001b[0m\n",
      "\u001b[0;34m    >>> C = A.shard(num_shards=3, index=1)\u001b[0m\n",
      "\u001b[0;34m    >>> list(C.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [1, 4, 7]\u001b[0m\n",
      "\u001b[0;34m    >>> D = A.shard(num_shards=3, index=2)\u001b[0m\n",
      "\u001b[0;34m    >>> list(D.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [2, 5, 8]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This dataset operator is very useful when running distributed training, as\u001b[0m\n",
      "\u001b[0;34m    it allows each worker to read a unique subset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    When reading a single input file, you can shard elements as follows:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```python\u001b[0m\n",
      "\u001b[0;34m    d = tf.data.TFRecordDataset(input_file)\u001b[0m\n",
      "\u001b[0;34m    d = d.shard(num_workers, worker_index)\u001b[0m\n",
      "\u001b[0;34m    d = d.repeat(num_epochs)\u001b[0m\n",
      "\u001b[0;34m    d = d.shuffle(shuffle_buffer_size)\u001b[0m\n",
      "\u001b[0;34m    d = d.map(parser_fn, num_parallel_calls=num_map_threads)\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Important caveats:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    - Be sure to shard before you use any randomizing operator (such as\u001b[0m\n",
      "\u001b[0;34m      shuffle).\u001b[0m\n",
      "\u001b[0;34m    - Generally it is best if the shard operator is used early in the dataset\u001b[0m\n",
      "\u001b[0;34m      pipeline. For example, when reading from a set of TFRecord files, shard\u001b[0m\n",
      "\u001b[0;34m      before converting the dataset to input samples. This avoids reading every\u001b[0m\n",
      "\u001b[0;34m      file on every worker. The following is an example of an efficient\u001b[0m\n",
      "\u001b[0;34m      sharding strategy within a complete pipeline:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```python\u001b[0m\n",
      "\u001b[0;34m    d = Dataset.list_files(pattern, shuffle=False)\u001b[0m\n",
      "\u001b[0;34m    d = d.shard(num_workers, worker_index)\u001b[0m\n",
      "\u001b[0;34m    d = d.repeat(num_epochs)\u001b[0m\n",
      "\u001b[0;34m    d = d.shuffle(shuffle_buffer_size)\u001b[0m\n",
      "\u001b[0;34m    d = d.interleave(tf.data.TFRecordDataset,\u001b[0m\n",
      "\u001b[0;34m                     cycle_length=num_readers, block_length=1)\u001b[0m\n",
      "\u001b[0;34m    d = d.map(parser_fn, num_parallel_calls=num_map_threads)\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      num_shards: A `tf.int64` scalar `tf.Tensor`, representing the number of\u001b[0m\n",
      "\u001b[0;34m        shards operating in parallel.\u001b[0m\n",
      "\u001b[0;34m      index: A `tf.int64` scalar `tf.Tensor`, representing the worker index.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Raises:\u001b[0m\n",
      "\u001b[0;34m      InvalidArgumentError: if `num_shards` or `index` are illegal values.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Note: error checking is done on a best-effort basis, and errors aren't\u001b[0m\n",
      "\u001b[0;34m        guaranteed to be caught upon dataset creation. (e.g. providing in a\u001b[0m\n",
      "\u001b[0;34m        placeholder tensor bypasses the early checking, and will instead result\u001b[0m\n",
      "\u001b[0;34m        in an error during a session.run call.)\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshard_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mshard_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_shards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m           \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m           \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m           \u001b[0mshard_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m           \u001b[0mcheckpoint_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Saves the content of the given dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m      Example usage:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m      >>> import tempfile\u001b[0m\n",
      "\u001b[0;34m      >>> path = os.path.join(tempfile.gettempdir(), \"saved_data\")\u001b[0m\n",
      "\u001b[0;34m      >>> # Save a dataset\u001b[0m\n",
      "\u001b[0;34m      >>> dataset = tf.data.Dataset.range(2)\u001b[0m\n",
      "\u001b[0;34m      >>> dataset.save(path)\u001b[0m\n",
      "\u001b[0;34m      >>> new_dataset = tf.data.Dataset.load(path)\u001b[0m\n",
      "\u001b[0;34m      >>> for elem in new_dataset:\u001b[0m\n",
      "\u001b[0;34m      ...   print(elem)\u001b[0m\n",
      "\u001b[0;34m      tf.Tensor(0, shape=(), dtype=int64)\u001b[0m\n",
      "\u001b[0;34m      tf.Tensor(1, shape=(), dtype=int64)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m      The saved dataset is saved in multiple file \"shards\". By default, the\u001b[0m\n",
      "\u001b[0;34m      dataset output is divided to shards in a round-robin fashion but custom\u001b[0m\n",
      "\u001b[0;34m      sharding can be specified via the `shard_func` function. For example, you\u001b[0m\n",
      "\u001b[0;34m      can save the dataset to using a single shard as follows:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m      ```python\u001b[0m\n",
      "\u001b[0;34m      dataset = make_dataset()\u001b[0m\n",
      "\u001b[0;34m      def custom_shard_func(element):\u001b[0m\n",
      "\u001b[0;34m        return np.int64(0)\u001b[0m\n",
      "\u001b[0;34m      dataset.save(\u001b[0m\n",
      "\u001b[0;34m          path=\"/path/to/data\", ..., shard_func=custom_shard_func)\u001b[0m\n",
      "\u001b[0;34m      ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m      To enable checkpointing, pass in `checkpoint_args` to the `save` method\u001b[0m\n",
      "\u001b[0;34m      as follows:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m      ```python\u001b[0m\n",
      "\u001b[0;34m      dataset = tf.data.Dataset.range(100)\u001b[0m\n",
      "\u001b[0;34m      save_dir = \"...\"\u001b[0m\n",
      "\u001b[0;34m      checkpoint_prefix = \"...\"\u001b[0m\n",
      "\u001b[0;34m      step_counter = tf.Variable(0, trainable=False)\u001b[0m\n",
      "\u001b[0;34m      checkpoint_args = {\u001b[0m\n",
      "\u001b[0;34m        \"checkpoint_interval\": 50,\u001b[0m\n",
      "\u001b[0;34m        \"step_counter\": step_counter,\u001b[0m\n",
      "\u001b[0;34m        \"directory\": checkpoint_prefix,\u001b[0m\n",
      "\u001b[0;34m        \"max_to_keep\": 20,\u001b[0m\n",
      "\u001b[0;34m      }\u001b[0m\n",
      "\u001b[0;34m      dataset.save(dataset, save_dir, checkpoint_args=checkpoint_args)\u001b[0m\n",
      "\u001b[0;34m      ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m      NOTE: The directory layout and file format used for saving the dataset is\u001b[0m\n",
      "\u001b[0;34m      considered an implementation detail and may change. For this reason,\u001b[0m\n",
      "\u001b[0;34m      datasets saved through `tf.data.Dataset.save` should only be consumed\u001b[0m\n",
      "\u001b[0;34m      through `tf.data.Dataset.load`, which is guaranteed to be\u001b[0m\n",
      "\u001b[0;34m      backwards compatible.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m     path: Required. A directory to use for saving the dataset.\u001b[0m\n",
      "\u001b[0;34m     compression: Optional. The algorithm to use to compress data when writing\u001b[0m\n",
      "\u001b[0;34m          it. Supported options are `GZIP` and `NONE`. Defaults to `NONE`.\u001b[0m\n",
      "\u001b[0;34m     shard_func: Optional. A function to control the mapping of dataset\u001b[0m\n",
      "\u001b[0;34m          elements to file shards. The function is expected to map elements of\u001b[0m\n",
      "\u001b[0;34m          the input dataset to int64 shard IDs. If present, the function will be\u001b[0m\n",
      "\u001b[0;34m          traced and executed as graph computation.\u001b[0m\n",
      "\u001b[0;34m     checkpoint_args: Optional args for checkpointing which will be passed into\u001b[0m\n",
      "\u001b[0;34m          the `tf.train.CheckpointManager`. If `checkpoint_args` are not\u001b[0m\n",
      "\u001b[0;34m          specified, then checkpointing will not be performed. The `save()`\u001b[0m\n",
      "\u001b[0;34m          implementation creates a `tf.train.Checkpoint` object internally, so\u001b[0m\n",
      "\u001b[0;34m          users should not set the `checkpoint` argument in `checkpoint_args`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      An operation which when executed performs the save. When writing\u001b[0m\n",
      "\u001b[0;34m      checkpoints, returns None. The return value is useful in unit tests.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Raises:\u001b[0m\n",
      "\u001b[0;34m      ValueError if `checkpoint` is passed into `checkpoint_args`.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops -> save_op ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0msave_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshard_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Loads a previously saved dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Example usage:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> import tempfile\u001b[0m\n",
      "\u001b[0;34m    >>> path = os.path.join(tempfile.gettempdir(), \"saved_data\")\u001b[0m\n",
      "\u001b[0;34m    >>> # Save a dataset\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(2)\u001b[0m\n",
      "\u001b[0;34m    >>> tf.data.Dataset.save(dataset, path)\u001b[0m\n",
      "\u001b[0;34m    >>> new_dataset = tf.data.Dataset.load(path)\u001b[0m\n",
      "\u001b[0;34m    >>> for elem in new_dataset:\u001b[0m\n",
      "\u001b[0;34m    ...   print(elem)\u001b[0m\n",
      "\u001b[0;34m    tf.Tensor(0, shape=(), dtype=int64)\u001b[0m\n",
      "\u001b[0;34m    tf.Tensor(1, shape=(), dtype=int64)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    If the default option of sharding the saved dataset was used, the element\u001b[0m\n",
      "\u001b[0;34m    order of the saved dataset will be preserved when loading it.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The `reader_func` argument can be used to specify a custom order in which\u001b[0m\n",
      "\u001b[0;34m    elements should be loaded from the individual shards. The `reader_func` is\u001b[0m\n",
      "\u001b[0;34m    expected to take a single argument -- a dataset of datasets, each containing\u001b[0m\n",
      "\u001b[0;34m    elements of one of the shards -- and return a dataset of elements. For\u001b[0m\n",
      "\u001b[0;34m    example, the order of shards can be shuffled when loading them as follows:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```python\u001b[0m\n",
      "\u001b[0;34m    def custom_reader_func(datasets):\u001b[0m\n",
      "\u001b[0;34m      datasets = datasets.shuffle(NUM_SHARDS)\u001b[0m\n",
      "\u001b[0;34m      return datasets.interleave(lambda x: x, num_parallel_calls=AUTOTUNE)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    dataset = tf.data.Dataset.load(\u001b[0m\n",
      "\u001b[0;34m        path=\"/path/to/data\", ..., reader_func=custom_reader_func)\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      path: Required. A path pointing to a previously saved dataset.\u001b[0m\n",
      "\u001b[0;34m      element_spec: Optional. A nested structure of `tf.TypeSpec` objects\u001b[0m\n",
      "\u001b[0;34m        matching the structure of an element of the saved dataset and specifying\u001b[0m\n",
      "\u001b[0;34m        the type of individual element components. If not provided, the nested\u001b[0m\n",
      "\u001b[0;34m        structure of `tf.TypeSpec` saved with the saved dataset is used. Note\u001b[0m\n",
      "\u001b[0;34m        that this argument is required in graph mode.\u001b[0m\n",
      "\u001b[0;34m      compression: Optional. The algorithm to use to decompress the data when\u001b[0m\n",
      "\u001b[0;34m        reading it. Supported options are `GZIP` and `NONE`. Defaults to `NONE`.\u001b[0m\n",
      "\u001b[0;34m      reader_func: Optional. A function to control how to read data from shards.\u001b[0m\n",
      "\u001b[0;34m        If present, the function will be traced and executed as graph\u001b[0m\n",
      "\u001b[0;34m        computation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A `tf.data.Dataset` instance.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Raises:\u001b[0m\n",
      "\u001b[0;34m      FileNotFoundError: If `element_spec` is not specified and the saved nested\u001b[0m\n",
      "\u001b[0;34m        structure of `tf.TypeSpec` can not be located with the saved dataset.\u001b[0m\n",
      "\u001b[0;34m      ValueError: If `element_spec` is not specified and the method is executed\u001b[0m\n",
      "\u001b[0;34m        in graph mode.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops -> load_op ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mload_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0melement_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mreader_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreader_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Combines consecutive elements of this dataset into batches.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(8)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.batch(3)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(8)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.batch(3, drop_remainder=True)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [array([0, 1, 2]), array([3, 4, 5])]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The components of the resulting element will have an additional outer\u001b[0m\n",
      "\u001b[0;34m    dimension, which will be `batch_size` (or `N % batch_size` for the last\u001b[0m\n",
      "\u001b[0;34m    element if `batch_size` does not divide the number of input elements `N`\u001b[0m\n",
      "\u001b[0;34m    evenly and `drop_remainder` is `False`). If your program depends on the\u001b[0m\n",
      "\u001b[0;34m    batches having the same outer dimension, you should set the `drop_remainder`\u001b[0m\n",
      "\u001b[0;34m    argument to `True` to prevent the smaller batch from being produced.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note: If your program requires data to have a statically known shape (e.g.,\u001b[0m\n",
      "\u001b[0;34m    when using XLA), you should use `drop_remainder=True`. Without\u001b[0m\n",
      "\u001b[0;34m    `drop_remainder=True` the shape of the output dataset will have an unknown\u001b[0m\n",
      "\u001b[0;34m    leading dimension due to the possibility of a smaller final batch.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      batch_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\u001b[0m\n",
      "\u001b[0;34m        consecutive elements of this dataset to combine in a single batch.\u001b[0m\n",
      "\u001b[0;34m      drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\u001b[0m\n",
      "\u001b[0;34m        whether the last batch should be dropped in the case it has fewer than\u001b[0m\n",
      "\u001b[0;34m        `batch_size` elements; the default behavior is not to drop the smaller\u001b[0m\n",
      "\u001b[0;34m        batch.\u001b[0m\n",
      "\u001b[0;34m      num_parallel_calls: (Optional.) A `tf.int64` scalar `tf.Tensor`,\u001b[0m\n",
      "\u001b[0;34m        representing the number of batches to compute asynchronously in\u001b[0m\n",
      "\u001b[0;34m        parallel.\u001b[0m\n",
      "\u001b[0;34m        If not specified, batches will be computed sequentially. If the value\u001b[0m\n",
      "\u001b[0;34m        `tf.data.AUTOTUNE` is used, then the number of parallel\u001b[0m\n",
      "\u001b[0;34m        calls is set dynamically based on available resources.\u001b[0m\n",
      "\u001b[0;34m      deterministic: (Optional.) When `num_parallel_calls` is specified, if this\u001b[0m\n",
      "\u001b[0;34m        boolean is specified (`True` or `False`), it controls the order in which\u001b[0m\n",
      "\u001b[0;34m        the transformation produces elements. If set to `False`, the\u001b[0m\n",
      "\u001b[0;34m        transformation is allowed to yield elements out of order to trade\u001b[0m\n",
      "\u001b[0;34m        determinism for performance. If not specified, the\u001b[0m\n",
      "\u001b[0;34m        `tf.data.Options.deterministic` option (`True` by default) controls the\u001b[0m\n",
      "\u001b[0;34m        behavior.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops -> batch_op ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access,redefined-outer-name\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatch_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                           \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access,redefined-outer-name\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mpadded_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mpadded_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mpadding_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Combines consecutive elements of this dataset into padded batches.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This transformation combines multiple consecutive elements of the input\u001b[0m\n",
      "\u001b[0;34m    dataset into a single element.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Like `tf.data.Dataset.batch`, the components of the resulting element will\u001b[0m\n",
      "\u001b[0;34m    have an additional outer dimension, which will be `batch_size` (or\u001b[0m\n",
      "\u001b[0;34m    `N % batch_size` for the last element if `batch_size` does not divide the\u001b[0m\n",
      "\u001b[0;34m    number of input elements `N` evenly and `drop_remainder` is `False`). If\u001b[0m\n",
      "\u001b[0;34m    your program depends on the batches having the same outer dimension, you\u001b[0m\n",
      "\u001b[0;34m    should set the `drop_remainder` argument to `True` to prevent the smaller\u001b[0m\n",
      "\u001b[0;34m    batch from being produced.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Unlike `tf.data.Dataset.batch`, the input elements to be batched may have\u001b[0m\n",
      "\u001b[0;34m    different shapes, and this transformation will pad each component to the\u001b[0m\n",
      "\u001b[0;34m    respective shape in `padded_shapes`. The `padded_shapes` argument\u001b[0m\n",
      "\u001b[0;34m    determines the resulting shape for each dimension of each component in an\u001b[0m\n",
      "\u001b[0;34m    output element:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    * If the dimension is a constant, the component will be padded out to that\u001b[0m\n",
      "\u001b[0;34m      length in that dimension.\u001b[0m\n",
      "\u001b[0;34m    * If the dimension is unknown, the component will be padded out to the\u001b[0m\n",
      "\u001b[0;34m      maximum length of all elements in that dimension.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> A = (tf.data.Dataset\u001b[0m\n",
      "\u001b[0;34m    ...      .range(1, 5, output_type=tf.int32)\u001b[0m\n",
      "\u001b[0;34m    ...      .map(lambda x: tf.fill([x], x)))\u001b[0m\n",
      "\u001b[0;34m    >>> # Pad to the smallest per-batch size that fits all elements.\u001b[0m\n",
      "\u001b[0;34m    >>> B = A.padded_batch(2)\u001b[0m\n",
      "\u001b[0;34m    >>> for element in B.as_numpy_iterator():\u001b[0m\n",
      "\u001b[0;34m    ...   print(element)\u001b[0m\n",
      "\u001b[0;34m    [[1 0]\u001b[0m\n",
      "\u001b[0;34m     [2 2]]\u001b[0m\n",
      "\u001b[0;34m    [[3 3 3 0]\u001b[0m\n",
      "\u001b[0;34m     [4 4 4 4]]\u001b[0m\n",
      "\u001b[0;34m    >>> # Pad to a fixed size.\u001b[0m\n",
      "\u001b[0;34m    >>> C = A.padded_batch(2, padded_shapes=5)\u001b[0m\n",
      "\u001b[0;34m    >>> for element in C.as_numpy_iterator():\u001b[0m\n",
      "\u001b[0;34m    ...   print(element)\u001b[0m\n",
      "\u001b[0;34m    [[1 0 0 0 0]\u001b[0m\n",
      "\u001b[0;34m     [2 2 0 0 0]]\u001b[0m\n",
      "\u001b[0;34m    [[3 3 3 0 0]\u001b[0m\n",
      "\u001b[0;34m     [4 4 4 4 0]]\u001b[0m\n",
      "\u001b[0;34m    >>> # Pad with a custom value.\u001b[0m\n",
      "\u001b[0;34m    >>> D = A.padded_batch(2, padded_shapes=5, padding_values=-1)\u001b[0m\n",
      "\u001b[0;34m    >>> for element in D.as_numpy_iterator():\u001b[0m\n",
      "\u001b[0;34m    ...   print(element)\u001b[0m\n",
      "\u001b[0;34m    [[ 1 -1 -1 -1 -1]\u001b[0m\n",
      "\u001b[0;34m     [ 2  2 -1 -1 -1]]\u001b[0m\n",
      "\u001b[0;34m    [[ 3  3  3 -1 -1]\u001b[0m\n",
      "\u001b[0;34m     [ 4  4  4  4 -1]]\u001b[0m\n",
      "\u001b[0;34m    >>> # Components of nested elements can be padded independently.\u001b[0m\n",
      "\u001b[0;34m    >>> elements = [([1, 2, 3], [10]),\u001b[0m\n",
      "\u001b[0;34m    ...             ([4, 5], [11, 12])]\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_generator(\u001b[0m\n",
      "\u001b[0;34m    ...     lambda: iter(elements), (tf.int32, tf.int32))\u001b[0m\n",
      "\u001b[0;34m    >>> # Pad the first component of the tuple to length 4, and the second\u001b[0m\n",
      "\u001b[0;34m    >>> # component to the smallest size that fits.\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.padded_batch(2,\u001b[0m\n",
      "\u001b[0;34m    ...     padded_shapes=([4], [None]),\u001b[0m\n",
      "\u001b[0;34m    ...     padding_values=(-1, 100))\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [(array([[ 1,  2,  3, -1], [ 4,  5, -1, -1]], dtype=int32),\u001b[0m\n",
      "\u001b[0;34m      array([[ 10, 100], [ 11,  12]], dtype=int32))]\u001b[0m\n",
      "\u001b[0;34m    >>> # Pad with a single value and multiple components.\u001b[0m\n",
      "\u001b[0;34m    >>> E = tf.data.Dataset.zip((A, A)).padded_batch(2, padding_values=-1)\u001b[0m\n",
      "\u001b[0;34m    >>> for element in E.as_numpy_iterator():\u001b[0m\n",
      "\u001b[0;34m    ...   print(element)\u001b[0m\n",
      "\u001b[0;34m    (array([[ 1, -1],\u001b[0m\n",
      "\u001b[0;34m           [ 2,  2]], dtype=int32), array([[ 1, -1],\u001b[0m\n",
      "\u001b[0;34m           [ 2,  2]], dtype=int32))\u001b[0m\n",
      "\u001b[0;34m    (array([[ 3,  3,  3, -1],\u001b[0m\n",
      "\u001b[0;34m           [ 4,  4,  4,  4]], dtype=int32), array([[ 3,  3,  3, -1],\u001b[0m\n",
      "\u001b[0;34m           [ 4,  4,  4,  4]], dtype=int32))\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    See also `tf.data.experimental.dense_to_sparse_batch`, which combines\u001b[0m\n",
      "\u001b[0;34m    elements that may have different shapes into a `tf.sparse.SparseTensor`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      batch_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\u001b[0m\n",
      "\u001b[0;34m        consecutive elements of this dataset to combine in a single batch.\u001b[0m\n",
      "\u001b[0;34m      padded_shapes: (Optional.) A (nested) structure of `tf.TensorShape` or\u001b[0m\n",
      "\u001b[0;34m        `tf.int64` vector tensor-like objects representing the shape to which\u001b[0m\n",
      "\u001b[0;34m        the respective component of each input element should be padded prior\u001b[0m\n",
      "\u001b[0;34m        to batching. Any unknown dimensions will be padded to the maximum size\u001b[0m\n",
      "\u001b[0;34m        of that dimension in each batch. If unset, all dimensions of all\u001b[0m\n",
      "\u001b[0;34m        components are padded to the maximum size in the batch. `padded_shapes`\u001b[0m\n",
      "\u001b[0;34m        must be set if any component has an unknown rank.\u001b[0m\n",
      "\u001b[0;34m      padding_values: (Optional.) A (nested) structure of scalar-shaped\u001b[0m\n",
      "\u001b[0;34m        `tf.Tensor`, representing the padding values to use for the respective\u001b[0m\n",
      "\u001b[0;34m        components. None represents that the (nested) structure should be padded\u001b[0m\n",
      "\u001b[0;34m        with default values.  Defaults are `0` for numeric types and the empty\u001b[0m\n",
      "\u001b[0;34m        string for string types. The `padding_values` should have the same\u001b[0m\n",
      "\u001b[0;34m        (nested) structure as the input dataset. If `padding_values` is a single\u001b[0m\n",
      "\u001b[0;34m        element and the input dataset has multiple components, then the same\u001b[0m\n",
      "\u001b[0;34m        `padding_values` will be used to pad every component of the dataset.\u001b[0m\n",
      "\u001b[0;34m        If `padding_values` is a scalar, then its value will be broadcasted\u001b[0m\n",
      "\u001b[0;34m        to match the shape of each component.\u001b[0m\n",
      "\u001b[0;34m      drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\u001b[0m\n",
      "\u001b[0;34m        whether the last batch should be dropped in the case it has fewer than\u001b[0m\n",
      "\u001b[0;34m        `batch_size` elements; the default behavior is not to drop the smaller\u001b[0m\n",
      "\u001b[0;34m        batch.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Raises:\u001b[0m\n",
      "\u001b[0;34m      ValueError: If a component has an unknown rank, and the `padded_shapes`\u001b[0m\n",
      "\u001b[0;34m        argument is not set.\u001b[0m\n",
      "\u001b[0;34m      TypeError: If a component is of an unsupported type. The list of supported\u001b[0m\n",
      "\u001b[0;34m        types is documented in\u001b[0m\n",
      "\u001b[0;34m        https://www.tensorflow.org/guide/data#dataset_structure.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# padded_batch_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpadded_batch_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mpadded_batch_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_padded_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                                         \u001b[0mpadding_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mragged_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mrow_splits_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Combines consecutive elements of this dataset into `tf.RaggedTensor`s.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Like `tf.data.Dataset.batch`, the components of the resulting element will\u001b[0m\n",
      "\u001b[0;34m    have an additional outer dimension, which will be `batch_size` (or\u001b[0m\n",
      "\u001b[0;34m    `N % batch_size` for the last element if `batch_size` does not divide the\u001b[0m\n",
      "\u001b[0;34m    number of input elements `N` evenly and `drop_remainder` is `False`). If\u001b[0m\n",
      "\u001b[0;34m    your program depends on the batches having the same outer dimension, you\u001b[0m\n",
      "\u001b[0;34m    should set the `drop_remainder` argument to `True` to prevent the smaller\u001b[0m\n",
      "\u001b[0;34m    batch from being produced.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Unlike `tf.data.Dataset.batch`, the input elements to be batched may have\u001b[0m\n",
      "\u001b[0;34m    different shapes:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    *  If an input element is a `tf.Tensor` whose static `tf.TensorShape` is\u001b[0m\n",
      "\u001b[0;34m    fully defined, then it is batched as normal.\u001b[0m\n",
      "\u001b[0;34m    *  If an input element is a `tf.Tensor` whose static `tf.TensorShape`\u001b[0m\n",
      "\u001b[0;34m    contains one or more axes with unknown size (i.e., `shape[i]=None`), then\u001b[0m\n",
      "\u001b[0;34m    the output will contain a `tf.RaggedTensor` that is ragged up to any of such\u001b[0m\n",
      "\u001b[0;34m    dimensions.\u001b[0m\n",
      "\u001b[0;34m    *  If an input element is a `tf.RaggedTensor` or any other type, then it is\u001b[0m\n",
      "\u001b[0;34m    batched as normal.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Example:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(6)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.map(lambda x: tf.range(x))\u001b[0m\n",
      "\u001b[0;34m    >>> dataset.element_spec.shape\u001b[0m\n",
      "\u001b[0;34m    TensorShape([None])\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.ragged_batch(2)\u001b[0m\n",
      "\u001b[0;34m    >>> for batch in dataset:\u001b[0m\n",
      "\u001b[0;34m    ...   print(batch)\u001b[0m\n",
      "\u001b[0;34m    <tf.RaggedTensor [[], [0]]>\u001b[0m\n",
      "\u001b[0;34m    <tf.RaggedTensor [[0, 1], [0, 1, 2]]>\u001b[0m\n",
      "\u001b[0;34m    <tf.RaggedTensor [[0, 1, 2, 3], [0, 1, 2, 3, 4]]>\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      batch_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\u001b[0m\n",
      "\u001b[0;34m        consecutive elements of this dataset to combine in a single batch.\u001b[0m\n",
      "\u001b[0;34m      drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\u001b[0m\n",
      "\u001b[0;34m        whether the last batch should be dropped in the case it has fewer than\u001b[0m\n",
      "\u001b[0;34m        `batch_size` elements; the default behavior is not to drop the smaller\u001b[0m\n",
      "\u001b[0;34m        batch.\u001b[0m\n",
      "\u001b[0;34m      row_splits_dtype: The dtype that should be used for the `row_splits` of\u001b[0m\n",
      "\u001b[0;34m        any new ragged tensors.  Existing `tf.RaggedTensor` elements do not have\u001b[0m\n",
      "\u001b[0;34m        their row_splits dtype changed.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A string indicating a name for the `tf.data` operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# ragged_batch_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mragged_batch_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mragged_batch_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ragged_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                                         \u001b[0mrow_splits_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0msparse_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Combines consecutive elements into `tf.sparse.SparseTensor`s.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Like `Dataset.padded_batch()`, this transformation combines multiple\u001b[0m\n",
      "\u001b[0;34m    consecutive elements of the dataset, which might have different\u001b[0m\n",
      "\u001b[0;34m    shapes, into a single element. The resulting element has three\u001b[0m\n",
      "\u001b[0;34m    components (`indices`, `values`, and `dense_shape`), which\u001b[0m\n",
      "\u001b[0;34m    comprise a `tf.sparse.SparseTensor` that represents the same data. The\u001b[0m\n",
      "\u001b[0;34m    `row_shape` represents the dense shape of each row in the\u001b[0m\n",
      "\u001b[0;34m    resulting `tf.sparse.SparseTensor`, to which the effective batch size is\u001b[0m\n",
      "\u001b[0;34m    prepended. For example:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```python\u001b[0m\n",
      "\u001b[0;34m    # NOTE: The following examples use `{ ... }` to represent the\u001b[0m\n",
      "\u001b[0;34m    # contents of a dataset.\u001b[0m\n",
      "\u001b[0;34m    a = { ['a', 'b', 'c'], ['a', 'b'], ['a', 'b', 'c', 'd'] }\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    a.apply(tf.data.experimental.dense_to_sparse_batch(\u001b[0m\n",
      "\u001b[0;34m        batch_size=2, row_shape=[6])) ==\u001b[0m\n",
      "\u001b[0;34m    {\u001b[0m\n",
      "\u001b[0;34m        ([[0, 0], [0, 1], [0, 2], [1, 0], [1, 1]],  # indices\u001b[0m\n",
      "\u001b[0;34m         ['a', 'b', 'c', 'a', 'b'],                 # values\u001b[0m\n",
      "\u001b[0;34m         [2, 6]),                                   # dense_shape\u001b[0m\n",
      "\u001b[0;34m        ([[0, 0], [0, 1], [0, 2], [0, 3]],\u001b[0m\n",
      "\u001b[0;34m         ['a', 'b', 'c', 'd'],\u001b[0m\n",
      "\u001b[0;34m         [1, 6])\u001b[0m\n",
      "\u001b[0;34m    }\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      batch_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\u001b[0m\n",
      "\u001b[0;34m        consecutive elements of this dataset to combine in a single batch.\u001b[0m\n",
      "\u001b[0;34m      row_shape: A `tf.TensorShape` or `tf.int64` vector tensor-like object\u001b[0m\n",
      "\u001b[0;34m        representing the equivalent dense shape of a row in the resulting\u001b[0m\n",
      "\u001b[0;34m        `tf.sparse.SparseTensor`. Each element of this dataset must have the\u001b[0m\n",
      "\u001b[0;34m        same rank as `row_shape`, and must have size less than or equal to\u001b[0m\n",
      "\u001b[0;34m        `row_shape` in each dimension.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A string indicating a name for the `tf.data` operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# sparse_batch_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse_batch_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0msparse_batch_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Maps `map_func` across the elements of this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This transformation applies `map_func` to each element of this dataset, and\u001b[0m\n",
      "\u001b[0;34m    returns a new dataset containing the transformed elements, in the same\u001b[0m\n",
      "\u001b[0;34m    order as they appeared in the input. `map_func` can be used to change both\u001b[0m\n",
      "\u001b[0;34m    the values and the structure of a dataset's elements. Supported structure\u001b[0m\n",
      "\u001b[0;34m    constructs are documented\u001b[0m\n",
      "\u001b[0;34m    [here](https://www.tensorflow.org/guide/data#dataset_structure).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    For example, `map` can be used for adding 1 to each element, or projecting a\u001b[0m\n",
      "\u001b[0;34m    subset of element components.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.map(lambda x: x + 1)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [2, 3, 4, 5, 6]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The input signature of `map_func` is determined by the structure of each\u001b[0m\n",
      "\u001b[0;34m    element in this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = Dataset.range(5)\u001b[0m\n",
      "\u001b[0;34m    >>> # `map_func` takes a single argument of type `tf.Tensor` with the same\u001b[0m\n",
      "\u001b[0;34m    >>> # shape and dtype.\u001b[0m\n",
      "\u001b[0;34m    >>> result = dataset.map(lambda x: x + 1)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> # Each element is a tuple containing two `tf.Tensor` objects.\u001b[0m\n",
      "\u001b[0;34m    >>> elements = [(1, \"foo\"), (2, \"bar\"), (3, \"baz\")]\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_generator(\u001b[0m\n",
      "\u001b[0;34m    ...     lambda: elements, (tf.int32, tf.string))\u001b[0m\n",
      "\u001b[0;34m    >>> # `map_func` takes two arguments of type `tf.Tensor`. This function\u001b[0m\n",
      "\u001b[0;34m    >>> # projects out just the first component.\u001b[0m\n",
      "\u001b[0;34m    >>> result = dataset.map(lambda x_int, y_str: x_int)\u001b[0m\n",
      "\u001b[0;34m    >>> list(result.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [1, 2, 3]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> # Each element is a dictionary mapping strings to `tf.Tensor` objects.\u001b[0m\n",
      "\u001b[0;34m    >>> elements =  ([{\"a\": 1, \"b\": \"foo\"},\u001b[0m\n",
      "\u001b[0;34m    ...               {\"a\": 2, \"b\": \"bar\"},\u001b[0m\n",
      "\u001b[0;34m    ...               {\"a\": 3, \"b\": \"baz\"}])\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_generator(\u001b[0m\n",
      "\u001b[0;34m    ...     lambda: elements, {\"a\": tf.int32, \"b\": tf.string})\u001b[0m\n",
      "\u001b[0;34m    >>> # `map_func` takes a single argument of type `dict` with the same keys\u001b[0m\n",
      "\u001b[0;34m    >>> # as the elements.\u001b[0m\n",
      "\u001b[0;34m    >>> result = dataset.map(lambda d: str(d[\"a\"]) + d[\"b\"])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The value or values returned by `map_func` determine the structure of each\u001b[0m\n",
      "\u001b[0;34m    element in the returned dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(3)\u001b[0m\n",
      "\u001b[0;34m    >>> # `map_func` returns two `tf.Tensor` objects.\u001b[0m\n",
      "\u001b[0;34m    >>> def g(x):\u001b[0m\n",
      "\u001b[0;34m    ...   return tf.constant(37.0), tf.constant([\"Foo\", \"Bar\", \"Baz\"])\u001b[0m\n",
      "\u001b[0;34m    >>> result = dataset.map(g)\u001b[0m\n",
      "\u001b[0;34m    >>> result.element_spec\u001b[0m\n",
      "\u001b[0;34m    (TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(3,), \\\u001b[0m\n",
      "\u001b[0;34mdtype=tf.string, name=None))\u001b[0m\n",
      "\u001b[0;34m    >>> # Python primitives, lists, and NumPy arrays are implicitly converted to\u001b[0m\n",
      "\u001b[0;34m    >>> # `tf.Tensor`.\u001b[0m\n",
      "\u001b[0;34m    >>> def h(x):\u001b[0m\n",
      "\u001b[0;34m    ...   return 37.0, [\"Foo\", \"Bar\"], np.array([1.0, 2.0], dtype=np.float64)\u001b[0m\n",
      "\u001b[0;34m    >>> result = dataset.map(h)\u001b[0m\n",
      "\u001b[0;34m    >>> result.element_spec\u001b[0m\n",
      "\u001b[0;34m    (TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(2,), \\\u001b[0m\n",
      "\u001b[0;34mdtype=tf.string, name=None), TensorSpec(shape=(2,), dtype=tf.float64, \\\u001b[0m\n",
      "\u001b[0;34mname=None))\u001b[0m\n",
      "\u001b[0;34m    >>> # `map_func` can return nested structures.\u001b[0m\n",
      "\u001b[0;34m    >>> def i(x):\u001b[0m\n",
      "\u001b[0;34m    ...   return (37.0, [42, 16]), \"foo\"\u001b[0m\n",
      "\u001b[0;34m    >>> result = dataset.map(i)\u001b[0m\n",
      "\u001b[0;34m    >>> result.element_spec\u001b[0m\n",
      "\u001b[0;34m    ((TensorSpec(shape=(), dtype=tf.float32, name=None),\u001b[0m\n",
      "\u001b[0;34m      TensorSpec(shape=(2,), dtype=tf.int32, name=None)),\u001b[0m\n",
      "\u001b[0;34m     TensorSpec(shape=(), dtype=tf.string, name=None))\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    `map_func` can accept as arguments and return any type of dataset element.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note that irrespective of the context in which `map_func` is defined (eager\u001b[0m\n",
      "\u001b[0;34m    vs. graph), tf.data traces the function and executes it as a graph. To use\u001b[0m\n",
      "\u001b[0;34m    Python code inside of the function you have a few options:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    1) Rely on AutoGraph to convert Python code into an equivalent graph\u001b[0m\n",
      "\u001b[0;34m    computation. The downside of this approach is that AutoGraph can convert\u001b[0m\n",
      "\u001b[0;34m    some but not all Python code.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    2) Use `tf.py_function`, which allows you to write arbitrary Python code but\u001b[0m\n",
      "\u001b[0;34m    will generally result in worse performance than 1). For example:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> d = tf.data.Dataset.from_tensor_slices(['hello', 'world'])\u001b[0m\n",
      "\u001b[0;34m    >>> # transform a string tensor to upper case string using a Python function\u001b[0m\n",
      "\u001b[0;34m    >>> def upper_case_fn(t: tf.Tensor):\u001b[0m\n",
      "\u001b[0;34m    ...   return t.numpy().decode('utf-8').upper()\u001b[0m\n",
      "\u001b[0;34m    >>> d = d.map(lambda x: tf.py_function(func=upper_case_fn,\u001b[0m\n",
      "\u001b[0;34m    ...           inp=[x], Tout=tf.string))\u001b[0m\n",
      "\u001b[0;34m    >>> list(d.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [b'HELLO', b'WORLD']\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    3) Use `tf.numpy_function`, which also allows you to write arbitrary\u001b[0m\n",
      "\u001b[0;34m    Python code. Note that `tf.py_function` accepts `tf.Tensor` whereas\u001b[0m\n",
      "\u001b[0;34m    `tf.numpy_function` accepts numpy arrays and returns only numpy arrays.\u001b[0m\n",
      "\u001b[0;34m    For example:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> d = tf.data.Dataset.from_tensor_slices(['hello', 'world'])\u001b[0m\n",
      "\u001b[0;34m    >>> def upper_case_fn(t: np.ndarray):\u001b[0m\n",
      "\u001b[0;34m    ...   return t.decode('utf-8').upper()\u001b[0m\n",
      "\u001b[0;34m    >>> d = d.map(lambda x: tf.numpy_function(func=upper_case_fn,\u001b[0m\n",
      "\u001b[0;34m    ...           inp=[x], Tout=tf.string))\u001b[0m\n",
      "\u001b[0;34m    >>> list(d.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [b'HELLO', b'WORLD']\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note that the use of `tf.numpy_function` and `tf.py_function`\u001b[0m\n",
      "\u001b[0;34m    in general precludes the possibility of executing user-defined\u001b[0m\n",
      "\u001b[0;34m    transformations in parallel (because of Python GIL).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Performance can often be improved by setting `num_parallel_calls` so that\u001b[0m\n",
      "\u001b[0;34m    `map` will use multiple threads to process elements. If deterministic order\u001b[0m\n",
      "\u001b[0;34m    isn't required, it can also improve performance to set\u001b[0m\n",
      "\u001b[0;34m    `deterministic=False`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.map(lambda x: x + 1,\u001b[0m\n",
      "\u001b[0;34m    ...     num_parallel_calls=tf.data.AUTOTUNE,\u001b[0m\n",
      "\u001b[0;34m    ...     deterministic=False)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The order of elements yielded by this transformation is deterministic if\u001b[0m\n",
      "\u001b[0;34m    `deterministic=True`. If `map_func` contains stateful operations and\u001b[0m\n",
      "\u001b[0;34m    `num_parallel_calls > 1`, the order in which that state is accessed is\u001b[0m\n",
      "\u001b[0;34m    undefined, so the values of output elements may not be deterministic\u001b[0m\n",
      "\u001b[0;34m    regardless of the `deterministic` flag value.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      map_func: A function mapping a dataset element to another dataset element.\u001b[0m\n",
      "\u001b[0;34m      num_parallel_calls: (Optional.) A `tf.int64` scalar `tf.Tensor`,\u001b[0m\n",
      "\u001b[0;34m        representing the number elements to process asynchronously in parallel.\u001b[0m\n",
      "\u001b[0;34m        If not specified, elements will be processed sequentially. If the value\u001b[0m\n",
      "\u001b[0;34m        `tf.data.AUTOTUNE` is used, then the number of parallel\u001b[0m\n",
      "\u001b[0;34m        calls is set dynamically based on available CPU.\u001b[0m\n",
      "\u001b[0;34m      deterministic: (Optional.) When `num_parallel_calls` is specified, if this\u001b[0m\n",
      "\u001b[0;34m        boolean is specified (`True` or `False`), it controls the order in which\u001b[0m\n",
      "\u001b[0;34m        the transformation produces elements. If set to `False`, the\u001b[0m\n",
      "\u001b[0;34m        transformation is allowed to yield elements out of order to trade\u001b[0m\n",
      "\u001b[0;34m        determinism for performance. If not specified, the\u001b[0m\n",
      "\u001b[0;34m        `tf.data.Options.deterministic` option (`True` by default) controls the\u001b[0m\n",
      "\u001b[0;34m        behavior.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmap_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mmap_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The type signature is:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m    def flat_map(\u001b[0m\n",
      "\u001b[0;34m      self: Dataset[T],\u001b[0m\n",
      "\u001b[0;34m      map_func: Callable[[T], Dataset[S]]\u001b[0m\n",
      "\u001b[0;34m    ) -> Dataset[S]\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Use `flat_map` if you want to make sure that the order of your dataset\u001b[0m\n",
      "\u001b[0;34m    stays the same. For example, to flatten a dataset of batches into a\u001b[0m\n",
      "\u001b[0;34m    dataset of their elements:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices(\u001b[0m\n",
      "\u001b[0;34m    ...     [[1, 2, 3], [4, 5, 6], [7, 8, 9]])\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.flat_map(tf.data.Dataset.from_tensor_slices)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [1, 2, 3, 4, 5, 6, 7, 8, 9]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    `tf.data.Dataset.interleave()` is a generalization of `flat_map`, since\u001b[0m\n",
      "\u001b[0;34m    `flat_map` produces the same output as\u001b[0m\n",
      "\u001b[0;34m    `tf.data.Dataset.interleave(cycle_length=1)`\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      map_func: A function mapping a dataset element to a dataset.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops -> flat_map_op ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflat_map_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mflat_map_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mignore_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_warning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Drops elements that cause errors.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices([1., 2., 0., 4.])\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.map(lambda x: tf.debugging.check_numerics(1. / x, \"\"))\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    Traceback (most recent call last):\u001b[0m\n",
      "\u001b[0;34m    ...\u001b[0m\n",
      "\u001b[0;34m    InvalidArgumentError: ... Tensor had Inf values\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.ignore_errors()\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [1.0, 0.5, 0.25]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      log_warning: (Optional.) A bool indicating whether or not ignored errors\u001b[0m\n",
      "\u001b[0;34m        should be logged to stderr. Defaults to `False`.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A string indicating a name for the `tf.data` operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# ignore_errors_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mignore_errors_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mignore_errors_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ignore_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_warning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0minterleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mcycle_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mblock_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Maps `map_func` across this dataset, and interleaves the results.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The type signature is:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m    def interleave(\u001b[0m\n",
      "\u001b[0;34m      self: Dataset[T],\u001b[0m\n",
      "\u001b[0;34m      map_func: Callable[[T], Dataset[S]]\u001b[0m\n",
      "\u001b[0;34m    ) -> Dataset[S]\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    For example, you can use `Dataset.interleave()` to process many input files\u001b[0m\n",
      "\u001b[0;34m    concurrently:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> # Preprocess 4 files concurrently, and interleave blocks of 16 records\u001b[0m\n",
      "\u001b[0;34m    >>> # from each file.\u001b[0m\n",
      "\u001b[0;34m    >>> filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\",\u001b[0m\n",
      "\u001b[0;34m    ...              \"/var/data/file3.txt\", \"/var/data/file4.txt\"]\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices(filenames)\u001b[0m\n",
      "\u001b[0;34m    >>> def parse_fn(filename):\u001b[0m\n",
      "\u001b[0;34m    ...   return tf.data.Dataset.range(10)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.interleave(lambda x:\u001b[0m\n",
      "\u001b[0;34m    ...     tf.data.TextLineDataset(x).map(parse_fn, num_parallel_calls=1),\u001b[0m\n",
      "\u001b[0;34m    ...     cycle_length=4, block_length=16)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The `cycle_length` and `block_length` arguments control the order in which\u001b[0m\n",
      "\u001b[0;34m    elements are produced. `cycle_length` controls the number of input elements\u001b[0m\n",
      "\u001b[0;34m    that are processed concurrently. If you set `cycle_length` to 1, this\u001b[0m\n",
      "\u001b[0;34m    transformation will handle one input element at a time, and will produce\u001b[0m\n",
      "\u001b[0;34m    identical results to `tf.data.Dataset.flat_map`. In general,\u001b[0m\n",
      "\u001b[0;34m    this transformation will apply `map_func` to `cycle_length` input elements,\u001b[0m\n",
      "\u001b[0;34m    open iterators on the returned `Dataset` objects, and cycle through them\u001b[0m\n",
      "\u001b[0;34m    producing `block_length` consecutive elements from each iterator, and\u001b[0m\n",
      "\u001b[0;34m    consuming the next input element each time it reaches the end of an\u001b[0m\n",
      "\u001b[0;34m    iterator.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    For example:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\u001b[0m\n",
      "\u001b[0;34m    >>> # NOTE: New lines indicate \"block\" boundaries.\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.interleave(\u001b[0m\n",
      "\u001b[0;34m    ...     lambda x: Dataset.from_tensors(x).repeat(6),\u001b[0m\n",
      "\u001b[0;34m    ...     cycle_length=2, block_length=4)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [1, 1, 1, 1,\u001b[0m\n",
      "\u001b[0;34m     2, 2, 2, 2,\u001b[0m\n",
      "\u001b[0;34m     1, 1,\u001b[0m\n",
      "\u001b[0;34m     2, 2,\u001b[0m\n",
      "\u001b[0;34m     3, 3, 3, 3,\u001b[0m\n",
      "\u001b[0;34m     4, 4, 4, 4,\u001b[0m\n",
      "\u001b[0;34m     3, 3,\u001b[0m\n",
      "\u001b[0;34m     4, 4,\u001b[0m\n",
      "\u001b[0;34m     5, 5, 5, 5,\u001b[0m\n",
      "\u001b[0;34m     5, 5]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note: The order of elements yielded by this transformation is\u001b[0m\n",
      "\u001b[0;34m    deterministic, as long as `map_func` is a pure function and\u001b[0m\n",
      "\u001b[0;34m    `deterministic=True`. If `map_func` contains any stateful operations, the\u001b[0m\n",
      "\u001b[0;34m    order in which that state is accessed is undefined.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Performance can often be improved by setting `num_parallel_calls` so that\u001b[0m\n",
      "\u001b[0;34m    `interleave` will use multiple threads to fetch elements. If determinism\u001b[0m\n",
      "\u001b[0;34m    isn't required, it can also improve performance to set\u001b[0m\n",
      "\u001b[0;34m    `deterministic=False`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\",\u001b[0m\n",
      "\u001b[0;34m    ...              \"/var/data/file3.txt\", \"/var/data/file4.txt\"]\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices(filenames)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.interleave(lambda x: tf.data.TFRecordDataset(x),\u001b[0m\n",
      "\u001b[0;34m    ...     cycle_length=4, num_parallel_calls=tf.data.AUTOTUNE,\u001b[0m\n",
      "\u001b[0;34m    ...     deterministic=False)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      map_func: A function that takes a dataset element and returns a\u001b[0m\n",
      "\u001b[0;34m        `tf.data.Dataset`.\u001b[0m\n",
      "\u001b[0;34m      cycle_length: (Optional.) The number of input elements that will be\u001b[0m\n",
      "\u001b[0;34m        processed concurrently. If not set, the tf.data runtime decides what it\u001b[0m\n",
      "\u001b[0;34m        should be based on available CPU. If `num_parallel_calls` is set to\u001b[0m\n",
      "\u001b[0;34m        `tf.data.AUTOTUNE`, the `cycle_length` argument identifies\u001b[0m\n",
      "\u001b[0;34m        the maximum degree of parallelism.\u001b[0m\n",
      "\u001b[0;34m      block_length: (Optional.) The number of consecutive elements to produce\u001b[0m\n",
      "\u001b[0;34m        from each input element before cycling to another input element. If not\u001b[0m\n",
      "\u001b[0;34m        set, defaults to 1.\u001b[0m\n",
      "\u001b[0;34m      num_parallel_calls: (Optional.) If specified, the implementation creates a\u001b[0m\n",
      "\u001b[0;34m        threadpool, which is used to fetch inputs from cycle elements\u001b[0m\n",
      "\u001b[0;34m        asynchronously and in parallel. The default behavior is to fetch inputs\u001b[0m\n",
      "\u001b[0;34m        from cycle elements synchronously with no parallelism. If the value\u001b[0m\n",
      "\u001b[0;34m        `tf.data.AUTOTUNE` is used, then the number of parallel\u001b[0m\n",
      "\u001b[0;34m        calls is set dynamically based on available CPU.\u001b[0m\n",
      "\u001b[0;34m      deterministic: (Optional.) When `num_parallel_calls` is specified, if this\u001b[0m\n",
      "\u001b[0;34m        boolean is specified (`True` or `False`), it controls the order in which\u001b[0m\n",
      "\u001b[0;34m        the transformation produces elements. If set to `False`, the\u001b[0m\n",
      "\u001b[0;34m        transformation is allowed to yield elements out of order to trade\u001b[0m\n",
      "\u001b[0;34m        determinism for performance. If not specified, the\u001b[0m\n",
      "\u001b[0;34m        `tf.data.Options.deterministic` option (`True` by default) controls the\u001b[0m\n",
      "\u001b[0;34m        behavior.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# dataset_ops -> interleave_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterleave_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0minterleave_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                                     \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Filters this dataset according to `predicate`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.filter(lambda x: x < 3)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [1, 2]\u001b[0m\n",
      "\u001b[0;34m    >>> # `tf.math.equal(x, y)` is required for equality comparison\u001b[0m\n",
      "\u001b[0;34m    >>> def filter_fn(x):\u001b[0m\n",
      "\u001b[0;34m    ...   return tf.math.equal(x, 1)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.filter(filter_fn)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [1]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      predicate: A function mapping a dataset element to a boolean.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops -> filter_op ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfilter_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mfilter_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformation_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Applies a transformation function to this dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    `apply` enables chaining of custom `Dataset` transformations, which are\u001b[0m\n",
      "\u001b[0;34m    represented as functions that take one `Dataset` argument and return a\u001b[0m\n",
      "\u001b[0;34m    transformed `Dataset`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(100)\u001b[0m\n",
      "\u001b[0;34m    >>> def dataset_fn(ds):\u001b[0m\n",
      "\u001b[0;34m    ...   return ds.filter(lambda x: x < 5)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.apply(dataset_fn)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [0, 1, 2, 3, 4]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      transformation_func: A function that takes one `Dataset` argument and\u001b[0m\n",
      "\u001b[0;34m        returns a `Dataset`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;34mf\"`transformation_func` must return a `tf.data.Dataset` object. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;34mf\"Got {type(dataset)}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Returns a dataset of \"windows\".\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Each \"window\" is a dataset that contains a subset of elements of the\u001b[0m\n",
      "\u001b[0;34m    input dataset. These are finite datasets of size `size` (or possibly fewer\u001b[0m\n",
      "\u001b[0;34m    if there are not enough input elements to fill the window and\u001b[0m\n",
      "\u001b[0;34m    `drop_remainder` evaluates to `False`).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    For example:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(7).window(3)\u001b[0m\n",
      "\u001b[0;34m    >>> for window in dataset:\u001b[0m\n",
      "\u001b[0;34m    ...   print(window)\u001b[0m\n",
      "\u001b[0;34m    <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\u001b[0m\n",
      "\u001b[0;34m    <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\u001b[0m\n",
      "\u001b[0;34m    <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Since windows are datasets, they can be iterated over:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> for window in dataset:\u001b[0m\n",
      "\u001b[0;34m    ...   print(list(window.as_numpy_iterator()))\u001b[0m\n",
      "\u001b[0;34m    [0, 1, 2]\u001b[0m\n",
      "\u001b[0;34m    [3, 4, 5]\u001b[0m\n",
      "\u001b[0;34m    [6]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    #### Shift\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The `shift` argument determines the number of input elements to shift\u001b[0m\n",
      "\u001b[0;34m    between the start of each window. If windows and elements are both numbered\u001b[0m\n",
      "\u001b[0;34m    starting at 0, the first element in window `k` will be element `k * shift`\u001b[0m\n",
      "\u001b[0;34m    of the input dataset. In particular, the first element of the first window\u001b[0m\n",
      "\u001b[0;34m    will always be the first element of the input dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(7).window(3, shift=1,\u001b[0m\n",
      "\u001b[0;34m    ...                                           drop_remainder=True)\u001b[0m\n",
      "\u001b[0;34m    >>> for window in dataset:\u001b[0m\n",
      "\u001b[0;34m    ...   print(list(window.as_numpy_iterator()))\u001b[0m\n",
      "\u001b[0;34m    [0, 1, 2]\u001b[0m\n",
      "\u001b[0;34m    [1, 2, 3]\u001b[0m\n",
      "\u001b[0;34m    [2, 3, 4]\u001b[0m\n",
      "\u001b[0;34m    [3, 4, 5]\u001b[0m\n",
      "\u001b[0;34m    [4, 5, 6]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    #### Stride\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The `stride` argument determines the stride between input elements within a\u001b[0m\n",
      "\u001b[0;34m    window.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(7).window(3, shift=1, stride=2,\u001b[0m\n",
      "\u001b[0;34m    ...                                           drop_remainder=True)\u001b[0m\n",
      "\u001b[0;34m    >>> for window in dataset:\u001b[0m\n",
      "\u001b[0;34m    ...   print(list(window.as_numpy_iterator()))\u001b[0m\n",
      "\u001b[0;34m    [0, 2, 4]\u001b[0m\n",
      "\u001b[0;34m    [1, 3, 5]\u001b[0m\n",
      "\u001b[0;34m    [2, 4, 6]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    #### Nested elements\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    When the `window` transformation is applied to a dataset whos elements are\u001b[0m\n",
      "\u001b[0;34m    nested structures, it produces a dataset where the elements have the same\u001b[0m\n",
      "\u001b[0;34m    nested structure but each leaf is replaced by a window. In other words,\u001b[0m\n",
      "\u001b[0;34m    the nesting is applied outside of the windows as opposed inside of them.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The type signature is:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m    def window(\u001b[0m\n",
      "\u001b[0;34m        self: Dataset[Nest[T]], ...\u001b[0m\n",
      "\u001b[0;34m    ) -> Dataset[Nest[Dataset[T]]]\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Applying `window` to a `Dataset` of tuples gives a tuple of windows:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices(([1, 2, 3, 4, 5],\u001b[0m\n",
      "\u001b[0;34m    ...                                               [6, 7, 8, 9, 10]))\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.window(2)\u001b[0m\n",
      "\u001b[0;34m    >>> windows = next(iter(dataset))\u001b[0m\n",
      "\u001b[0;34m    >>> windows\u001b[0m\n",
      "\u001b[0;34m    (<...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>,\u001b[0m\n",
      "\u001b[0;34m     <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> def to_numpy(ds):\u001b[0m\n",
      "\u001b[0;34m    ...   return list(ds.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    >>>\u001b[0m\n",
      "\u001b[0;34m    >>> for windows in dataset:\u001b[0m\n",
      "\u001b[0;34m    ...   print(to_numpy(windows[0]), to_numpy(windows[1]))\u001b[0m\n",
      "\u001b[0;34m    [1, 2] [6, 7]\u001b[0m\n",
      "\u001b[0;34m    [3, 4] [8, 9]\u001b[0m\n",
      "\u001b[0;34m    [5] [10]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Applying `window` to a `Dataset` of dictionaries gives a dictionary of\u001b[0m\n",
      "\u001b[0;34m    `Datasets`:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices({'a': [1, 2, 3],\u001b[0m\n",
      "\u001b[0;34m    ...                                               'b': [4, 5, 6],\u001b[0m\n",
      "\u001b[0;34m    ...                                               'c': [7, 8, 9]})\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.window(2)\u001b[0m\n",
      "\u001b[0;34m    >>> def to_numpy(ds):\u001b[0m\n",
      "\u001b[0;34m    ...   return list(ds.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    >>>\u001b[0m\n",
      "\u001b[0;34m    >>> for windows in dataset:\u001b[0m\n",
      "\u001b[0;34m    ...   print(tf.nest.map_structure(to_numpy, windows))\u001b[0m\n",
      "\u001b[0;34m    {'a': [1, 2], 'b': [4, 5], 'c': [7, 8]}\u001b[0m\n",
      "\u001b[0;34m    {'a': [3], 'b': [6], 'c': [9]}\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    #### Flatten a dataset of windows\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The `Dataset.flat_map` and `Dataset.interleave` methods can be used to\u001b[0m\n",
      "\u001b[0;34m    flatten a dataset of windows into a single dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The argument to `flat_map` is a function that takes an element from the\u001b[0m\n",
      "\u001b[0;34m    dataset and returns a `Dataset`. `flat_map` chains together the resulting\u001b[0m\n",
      "\u001b[0;34m    datasets sequentially.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    For example, to turn each window into a dense tensor:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(7).window(3, shift=1,\u001b[0m\n",
      "\u001b[0;34m    ...                                           drop_remainder=True)\u001b[0m\n",
      "\u001b[0;34m    >>> batched = dataset.flat_map(lambda x:x.batch(3))\u001b[0m\n",
      "\u001b[0;34m    >>> for batch in batched:\u001b[0m\n",
      "\u001b[0;34m    ...   print(batch.numpy())\u001b[0m\n",
      "\u001b[0;34m    [0 1 2]\u001b[0m\n",
      "\u001b[0;34m    [1 2 3]\u001b[0m\n",
      "\u001b[0;34m    [2 3 4]\u001b[0m\n",
      "\u001b[0;34m    [3 4 5]\u001b[0m\n",
      "\u001b[0;34m    [4 5 6]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      size: A `tf.int64` scalar `tf.Tensor`, representing the number of elements\u001b[0m\n",
      "\u001b[0;34m        of the input dataset to combine into a window. Must be positive.\u001b[0m\n",
      "\u001b[0;34m      shift: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\u001b[0m\n",
      "\u001b[0;34m        number of input elements by which the window moves in each iteration.\u001b[0m\n",
      "\u001b[0;34m        Defaults to `size`. Must be positive.\u001b[0m\n",
      "\u001b[0;34m      stride: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\u001b[0m\n",
      "\u001b[0;34m        stride of the input elements in the sliding window. Must be positive.\u001b[0m\n",
      "\u001b[0;34m        The default value of 1 means \"retain every input element\".\u001b[0m\n",
      "\u001b[0;34m      drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\u001b[0m\n",
      "\u001b[0;34m        whether the last windows should be dropped if their size is smaller than\u001b[0m\n",
      "\u001b[0;34m        `size`.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops -> window_op ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwindow_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mwindow_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Reduces the input dataset to a single element.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The transformation calls `reduce_func` successively on every element of\u001b[0m\n",
      "\u001b[0;34m    the input dataset until the dataset is exhausted, aggregating information in\u001b[0m\n",
      "\u001b[0;34m    its internal state. The `initial_state` argument is used for the initial\u001b[0m\n",
      "\u001b[0;34m    state and the final state is returned as the result.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, _: x + 1).numpy()\u001b[0m\n",
      "\u001b[0;34m    5\u001b[0m\n",
      "\u001b[0;34m    >>> tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, y: x + y).numpy()\u001b[0m\n",
      "\u001b[0;34m    10\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      initial_state: An element representing the initial state of the\u001b[0m\n",
      "\u001b[0;34m        transformation.\u001b[0m\n",
      "\u001b[0;34m      reduce_func: A function that maps `(old_state, input_element)` to\u001b[0m\n",
      "\u001b[0;34m        `new_state`. It must take two arguments and return a new element\u001b[0m\n",
      "\u001b[0;34m        The structure of `new_state` must match the structure of\u001b[0m\n",
      "\u001b[0;34m        `initial_state`.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A dataset element corresponding to the final state of the transformation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"initial_state\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstate_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Iteratively rerun the reduce function until reaching a fixed point on\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# `state_structure`.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mneed_to_rerun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mwhile\u001b[0m \u001b[0mneed_to_rerun\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mwrapped_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructured_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStructuredFunctionWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;34m\"reduce()\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0minput_structure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0madd_to_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# Extract and validate class information from the returned values.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0moutput_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_classes\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mstate_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;32mlambda\u001b[0m \u001b[0mcomponent_spec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcomponent_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_legacy_output_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mstate_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mfor\u001b[0m \u001b[0mnew_state_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m              \u001b[0;34mf\"The element classes for the new state must match the initial \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m              \u001b[0;34mf\"state. Expected {state_classes} but got \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m              \u001b[0;34mf\"{wrapped_func.output_classes}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# Extract and validate type information from the returned values.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0moutput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mstate_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;32mlambda\u001b[0m \u001b[0mcomponent_spec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcomponent_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_legacy_output_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mstate_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mfor\u001b[0m \u001b[0mnew_state_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mnew_state_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mstate_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m              \u001b[0;34mf\"The element types for the new state must match the initial \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m              \u001b[0;34mf\"state. Expected {state_types} but got \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m              \u001b[0;34mf\"{wrapped_func.output_types}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# Extract shape information from the returned values.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0moutput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mstate_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;32mlambda\u001b[0m \u001b[0mcomponent_spec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcomponent_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_legacy_output_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mstate_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mflat_state_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mflat_new_state_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mweakened_state_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0moriginal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;32mfor\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_state_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_new_state_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mneed_to_rerun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mfor\u001b[0m \u001b[0moriginal_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweakened_shape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_state_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                                                \u001b[0mweakened_state_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0moriginal_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mweakened_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0moriginal_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mweakened_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mneed_to_rerun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mneed_to_rerun\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# TODO(b/110122868): Support a \"most specific compatible structure\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# method for combining structures, to avoid using legacy structures\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# here.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstate_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_legacy_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mstate_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweakened_state_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mstate_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreduce_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreduce_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_debug_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_metadata_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_and_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstate_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mreduce_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0moutput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flat_tensor_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flat_tensor_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mget_single_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Returns the single element of the `dataset`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The function enables you to use a `tf.data.Dataset` in a stateless\u001b[0m\n",
      "\u001b[0;34m    \"tensor-in tensor-out\" expression, without creating an iterator.\u001b[0m\n",
      "\u001b[0;34m    This facilitates the ease of data transformation on tensors using the\u001b[0m\n",
      "\u001b[0;34m    optimized `tf.data.Dataset` abstraction on top of them.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    For example, lets consider a `preprocessing_fn` which would take as an\u001b[0m\n",
      "\u001b[0;34m    input the raw features and returns the processed feature along with\u001b[0m\n",
      "\u001b[0;34m    it's label.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```python\u001b[0m\n",
      "\u001b[0;34m    def preprocessing_fn(raw_feature):\u001b[0m\n",
      "\u001b[0;34m      # ... the raw_feature is preprocessed as per the use-case\u001b[0m\n",
      "\u001b[0;34m      return feature\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    raw_features = ...  # input batch of BATCH_SIZE elements.\u001b[0m\n",
      "\u001b[0;34m    dataset = (tf.data.Dataset.from_tensor_slices(raw_features)\u001b[0m\n",
      "\u001b[0;34m              .map(preprocessing_fn, num_parallel_calls=BATCH_SIZE)\u001b[0m\n",
      "\u001b[0;34m              .batch(BATCH_SIZE))\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    processed_features = dataset.get_single_element()\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    In the above example, the `raw_features` tensor of length=BATCH_SIZE\u001b[0m\n",
      "\u001b[0;34m    was converted to a `tf.data.Dataset`. Next, each of the `raw_feature` was\u001b[0m\n",
      "\u001b[0;34m    mapped using the `preprocessing_fn` and the processed features were\u001b[0m\n",
      "\u001b[0;34m    grouped into a single batch. The final `dataset` contains only one element\u001b[0m\n",
      "\u001b[0;34m    which is a batch of all the processed features.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    NOTE: The `dataset` should contain only one element.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Now, instead of creating an iterator for the `dataset` and retrieving the\u001b[0m\n",
      "\u001b[0;34m    batch of features, the `tf.data.get_single_element()` function is used\u001b[0m\n",
      "\u001b[0;34m    to skip the iterator creation process and directly output the batch of\u001b[0m\n",
      "\u001b[0;34m    features.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This can be particularly useful when your tensor transformations are\u001b[0m\n",
      "\u001b[0;34m    expressed as `tf.data.Dataset` operations, and you want to use those\u001b[0m\n",
      "\u001b[0;34m    transformations while serving your model.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    #### Keras\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    model = ... # A pre-built or custom model\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    class PreprocessingModel(tf.keras.Model):\u001b[0m\n",
      "\u001b[0;34m      def __init__(self, model):\u001b[0m\n",
      "\u001b[0;34m        super().__init__(self)\u001b[0m\n",
      "\u001b[0;34m        self.model = model\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m      @tf.function(input_signature=[...])\u001b[0m\n",
      "\u001b[0;34m      def serving_fn(self, data):\u001b[0m\n",
      "\u001b[0;34m        ds = tf.data.Dataset.from_tensor_slices(data)\u001b[0m\n",
      "\u001b[0;34m        ds = ds.map(preprocessing_fn, num_parallel_calls=BATCH_SIZE)\u001b[0m\n",
      "\u001b[0;34m        ds = ds.batch(batch_size=BATCH_SIZE)\u001b[0m\n",
      "\u001b[0;34m        return tf.argmax(self.model(ds.get_single_element()), axis=-1)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    preprocessing_model = PreprocessingModel(model)\u001b[0m\n",
      "\u001b[0;34m    your_exported_model_dir = ... # save the model to this path.\u001b[0m\n",
      "\u001b[0;34m    tf.saved_model.save(preprocessing_model, your_exported_model_dir,\u001b[0m\n",
      "\u001b[0;34m                  signatures={'serving_default': preprocessing_model.serving_fn}\u001b[0m\n",
      "\u001b[0;34m                  )\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    #### Estimator\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    In the case of estimators, you need to generally define a `serving_input_fn`\u001b[0m\n",
      "\u001b[0;34m    which would require the features to be processed by the model while\u001b[0m\n",
      "\u001b[0;34m    inferencing.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```python\u001b[0m\n",
      "\u001b[0;34m    def serving_input_fn():\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m      raw_feature_spec = ... # Spec for the raw_features\u001b[0m\n",
      "\u001b[0;34m      input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\u001b[0m\n",
      "\u001b[0;34m          raw_feature_spec, default_batch_size=None)\u001b[0m\n",
      "\u001b[0;34m      )\u001b[0m\n",
      "\u001b[0;34m      serving_input_receiver = input_fn()\u001b[0m\n",
      "\u001b[0;34m      raw_features = serving_input_receiver.features\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m      def preprocessing_fn(raw_feature):\u001b[0m\n",
      "\u001b[0;34m        # ... the raw_feature is preprocessed as per the use-case\u001b[0m\n",
      "\u001b[0;34m        return feature\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m      dataset = (tf.data.Dataset.from_tensor_slices(raw_features)\u001b[0m\n",
      "\u001b[0;34m                .map(preprocessing_fn, num_parallel_calls=BATCH_SIZE)\u001b[0m\n",
      "\u001b[0;34m                .batch(BATCH_SIZE))\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m      processed_features = dataset.get_single_element()\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m      # Please note that the value of `BATCH_SIZE` should be equal to\u001b[0m\n",
      "\u001b[0;34m      # the size of the leading dimension of `raw_features`. This ensures\u001b[0m\n",
      "\u001b[0;34m      # that `dataset` has only element, which is a pre-requisite for\u001b[0m\n",
      "\u001b[0;34m      # using `dataset.get_single_element()`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m      return tf.estimator.export.ServingInputReceiver(\u001b[0m\n",
      "\u001b[0;34m          processed_features, serving_input_receiver.receiver_tensors)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    estimator = ... # A pre-built or custom estimator\u001b[0m\n",
      "\u001b[0;34m    estimator.export_saved_model(your_exported_model_dir, serving_input_fn)\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A nested structure of `tf.Tensor` objects, corresponding to the single\u001b[0m\n",
      "\u001b[0;34m      element of `dataset`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Raises:\u001b[0m\n",
      "\u001b[0;34m      InvalidArgumentError: (at runtime) if `dataset` does not contain exactly\u001b[0m\n",
      "\u001b[0;34m        one element.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_metadata_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_and_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_to_single_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0munbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Splits elements of a dataset into multiple elements.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    For example, if elements of the dataset are shaped `[B, a0, a1, ...]`,\u001b[0m\n",
      "\u001b[0;34m    where `B` may vary for each input element, then for each element in the\u001b[0m\n",
      "\u001b[0;34m    dataset, the unbatched dataset will contain `B` consecutive elements\u001b[0m\n",
      "\u001b[0;34m    of shape `[a0, a1, ...]`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> elements = [ [1, 2, 3], [1, 2], [1, 2, 3, 4] ]\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_generator(lambda: elements, tf.int64)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.unbatch()\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [1, 2, 3, 1, 2, 1, 2, 3, 4]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note: `unbatch` requires a data copy to slice up the batched tensor into\u001b[0m\n",
      "\u001b[0;34m    smaller, unbatched tensors. When optimizing performance, try to avoid\u001b[0m\n",
      "\u001b[0;34m    unnecessary usage of `unbatch`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# dataset_ops -> unbatch_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munbatch_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0munbatch_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mwith_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Returns a new `tf.data.Dataset` with the given options set.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The options are \"global\" in the sense they apply to the entire dataset.\u001b[0m\n",
      "\u001b[0;34m    If options are set multiple times, they are merged as long as different\u001b[0m\n",
      "\u001b[0;34m    options do not use different non-default values.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> ds = tf.data.Dataset.range(5)\u001b[0m\n",
      "\u001b[0;34m    >>> ds = ds.interleave(lambda x: tf.data.Dataset.range(5),\u001b[0m\n",
      "\u001b[0;34m    ...                    cycle_length=3,\u001b[0m\n",
      "\u001b[0;34m    ...                    num_parallel_calls=3)\u001b[0m\n",
      "\u001b[0;34m    >>> options = tf.data.Options()\u001b[0m\n",
      "\u001b[0;34m    >>> # This will make the interleave order non-deterministic.\u001b[0m\n",
      "\u001b[0;34m    >>> options.deterministic = False\u001b[0m\n",
      "\u001b[0;34m    >>> ds = ds.with_options(options)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      options: A `tf.data.Options` that identifies the options the use.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Raises:\u001b[0m\n",
      "\u001b[0;34m      ValueError: when an option is set more than once to a non-default value\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0m_OptionsDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mcardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Returns the cardinality of the dataset, if known.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    `cardinality` may return `tf.data.INFINITE_CARDINALITY` if the dataset\u001b[0m\n",
      "\u001b[0;34m    contains an infinite number of elements or `tf.data.UNKNOWN_CARDINALITY` if\u001b[0m\n",
      "\u001b[0;34m    the analysis fails to determine the number of elements in the dataset\u001b[0m\n",
      "\u001b[0;34m    (e.g. when the dataset source is a file).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(42)\u001b[0m\n",
      "\u001b[0;34m    >>> print(dataset.cardinality().numpy())\u001b[0m\n",
      "\u001b[0;34m    42\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.repeat()\u001b[0m\n",
      "\u001b[0;34m    >>> cardinality = dataset.cardinality()\u001b[0m\n",
      "\u001b[0;34m    >>> print((cardinality == tf.data.INFINITE_CARDINALITY).numpy())\u001b[0m\n",
      "\u001b[0;34m    True\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.filter(lambda x: True)\u001b[0m\n",
      "\u001b[0;34m    >>> cardinality = dataset.cardinality()\u001b[0m\n",
      "\u001b[0;34m    >>> print((cardinality == tf.data.UNKNOWN_CARDINALITY).numpy())\u001b[0m\n",
      "\u001b[0;34m    True\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A scalar `tf.int64` `Tensor` representing the cardinality of the dataset.\u001b[0m\n",
      "\u001b[0;34m      If the cardinality is infinite or unknown, `cardinality` returns the\u001b[0m\n",
      "\u001b[0;34m      named constants `tf.data.INFINITE_CARDINALITY` and\u001b[0m\n",
      "\u001b[0;34m      `tf.data.UNKNOWN_CARDINALITY` respectively.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mgroup_by_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mkey_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mwindow_size_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Groups windows of elements by key and reduces them.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This transformation maps each consecutive element in a dataset to a key\u001b[0m\n",
      "\u001b[0;34m    using `key_func` and groups the elements by key. It then applies\u001b[0m\n",
      "\u001b[0;34m    `reduce_func` to at most `window_size_func(key)` elements matching the same\u001b[0m\n",
      "\u001b[0;34m    key. All except the final window for each key will contain\u001b[0m\n",
      "\u001b[0;34m    `window_size_func(key)` elements; the final window may be smaller.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    You may provide either a constant `window_size` or a window size determined\u001b[0m\n",
      "\u001b[0;34m    by the key through `window_size_func`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(10)\u001b[0m\n",
      "\u001b[0;34m    >>> window_size = 5\u001b[0m\n",
      "\u001b[0;34m    >>> key_func = lambda x: x%2\u001b[0m\n",
      "\u001b[0;34m    >>> reduce_func = lambda key, dataset: dataset.batch(window_size)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.group_by_window(\u001b[0m\n",
      "\u001b[0;34m    ...           key_func=key_func,\u001b[0m\n",
      "\u001b[0;34m    ...           reduce_func=reduce_func,\u001b[0m\n",
      "\u001b[0;34m    ...           window_size=window_size)\u001b[0m\n",
      "\u001b[0;34m    >>> for elem in dataset.as_numpy_iterator():\u001b[0m\n",
      "\u001b[0;34m    ...   print(elem)\u001b[0m\n",
      "\u001b[0;34m    [0 2 4 6 8]\u001b[0m\n",
      "\u001b[0;34m    [1 3 5 7 9]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      key_func: A function mapping a nested structure of tensors (having shapes\u001b[0m\n",
      "\u001b[0;34m        and types defined by `self.output_shapes` and `self.output_types`) to a\u001b[0m\n",
      "\u001b[0;34m        scalar `tf.int64` tensor.\u001b[0m\n",
      "\u001b[0;34m      reduce_func: A function mapping a key and a dataset of up to `window_size`\u001b[0m\n",
      "\u001b[0;34m        consecutive elements matching that key to another dataset.\u001b[0m\n",
      "\u001b[0;34m      window_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\u001b[0m\n",
      "\u001b[0;34m        consecutive elements matching the same key to combine in a single batch,\u001b[0m\n",
      "\u001b[0;34m        which will be passed to `reduce_func`. Mutually exclusive with\u001b[0m\n",
      "\u001b[0;34m        `window_size_func`.\u001b[0m\n",
      "\u001b[0;34m      window_size_func: A function mapping a key to a `tf.int64` scalar\u001b[0m\n",
      "\u001b[0;34m        `tf.Tensor`, representing the number of consecutive elements matching\u001b[0m\n",
      "\u001b[0;34m        the same key to combine in a single batch, which will be passed to\u001b[0m\n",
      "\u001b[0;34m        `reduce_func`. Mutually exclusive with `window_size`.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Raises:\u001b[0m\n",
      "\u001b[0;34m      ValueError: if neither or both of {`window_size`, `window_size_func`} are\u001b[0m\n",
      "\u001b[0;34m        passed.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# dataset_ops -> group_by_window_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgroup_by_window_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mgroup_by_window_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_by_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mbucket_by_sequence_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0melement_length_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mbucket_boundaries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mbucket_batch_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mpadded_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mpadding_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mpad_to_bucket_boundary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mno_padding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"A transformation that buckets elements in a `Dataset` by length.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Elements of the `Dataset` are grouped together by length and then are padded\u001b[0m\n",
      "\u001b[0;34m    and batched.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This is useful for sequence tasks in which the elements have variable\u001b[0m\n",
      "\u001b[0;34m    length. Grouping together elements that have similar lengths reduces the\u001b[0m\n",
      "\u001b[0;34m    total fraction of padding in a batch which increases training step\u001b[0m\n",
      "\u001b[0;34m    efficiency.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Below is an example to bucketize the input data to the 3 buckets\u001b[0m\n",
      "\u001b[0;34m    \"[0, 3), [3, 5), [5, inf)\" based on sequence length, with batch size 2.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> elements = [\u001b[0m\n",
      "\u001b[0;34m    ...   [0], [1, 2, 3, 4], [5, 6, 7],\u001b[0m\n",
      "\u001b[0;34m    ...   [7, 8, 9, 10, 11], [13, 14, 15, 16, 19, 20], [21, 22]]\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_generator(\u001b[0m\n",
      "\u001b[0;34m    ...     lambda: elements, tf.int64, output_shapes=[None])\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.bucket_by_sequence_length(\u001b[0m\n",
      "\u001b[0;34m    ...         element_length_func=lambda elem: tf.shape(elem)[0],\u001b[0m\n",
      "\u001b[0;34m    ...         bucket_boundaries=[3, 5],\u001b[0m\n",
      "\u001b[0;34m    ...         bucket_batch_sizes=[2, 2, 2])\u001b[0m\n",
      "\u001b[0;34m    >>> for elem in dataset.as_numpy_iterator():\u001b[0m\n",
      "\u001b[0;34m    ...   print(elem)\u001b[0m\n",
      "\u001b[0;34m    [[1 2 3 4]\u001b[0m\n",
      "\u001b[0;34m    [5 6 7 0]]\u001b[0m\n",
      "\u001b[0;34m    [[ 7  8  9 10 11  0]\u001b[0m\n",
      "\u001b[0;34m    [13 14 15 16 19 20]]\u001b[0m\n",
      "\u001b[0;34m    [[ 0  0]\u001b[0m\n",
      "\u001b[0;34m    [21 22]]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      element_length_func: function from element in `Dataset` to `tf.int32`,\u001b[0m\n",
      "\u001b[0;34m        determines the length of the element, which will determine the bucket it\u001b[0m\n",
      "\u001b[0;34m        goes into.\u001b[0m\n",
      "\u001b[0;34m      bucket_boundaries: `list<int>`, upper length boundaries of the buckets.\u001b[0m\n",
      "\u001b[0;34m      bucket_batch_sizes: `list<int>`, batch size per bucket. Length should be\u001b[0m\n",
      "\u001b[0;34m        `len(bucket_boundaries) + 1`.\u001b[0m\n",
      "\u001b[0;34m      padded_shapes: Nested structure of `tf.TensorShape` to pass to\u001b[0m\n",
      "\u001b[0;34m        `tf.data.Dataset.padded_batch`. If not provided, will use\u001b[0m\n",
      "\u001b[0;34m        `dataset.output_shapes`, which will result in variable length dimensions\u001b[0m\n",
      "\u001b[0;34m        being padded out to the maximum length in each batch.\u001b[0m\n",
      "\u001b[0;34m      padding_values: Values to pad with, passed to\u001b[0m\n",
      "\u001b[0;34m        `tf.data.Dataset.padded_batch`. Defaults to padding with 0.\u001b[0m\n",
      "\u001b[0;34m      pad_to_bucket_boundary: bool, if `False`, will pad dimensions with unknown\u001b[0m\n",
      "\u001b[0;34m        size to maximum length in batch. If `True`, will pad dimensions with\u001b[0m\n",
      "\u001b[0;34m        unknown size to bucket boundary minus 1 (i.e., the maximum length in\u001b[0m\n",
      "\u001b[0;34m        each bucket), and caller must ensure that the source `Dataset` does not\u001b[0m\n",
      "\u001b[0;34m        contain any elements with length longer than `max(bucket_boundaries)`.\u001b[0m\n",
      "\u001b[0;34m      no_padding: `bool`, indicates whether to pad the batch features (features\u001b[0m\n",
      "\u001b[0;34m        need to be either of type `tf.sparse.SparseTensor` or of same shape).\u001b[0m\n",
      "\u001b[0;34m      drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\u001b[0m\n",
      "\u001b[0;34m        whether the last batch should be dropped in the case it has fewer than\u001b[0m\n",
      "\u001b[0;34m        `batch_size` elements; the default behavior is not to drop the smaller\u001b[0m\n",
      "\u001b[0;34m        batch.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Raises:\u001b[0m\n",
      "\u001b[0;34m      ValueError: if `len(bucket_batch_sizes) != len(bucket_boundaries) + 1`.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_batch_sizes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_boundaries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;34mf\"`len(bucket_batch_sizes)` must equal `len(bucket_boundaries) + 1` \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;34mf\"but `len(bucket_batch_sizes)={len(bucket_batch_sizes)}` and \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;34mf\"`len(bucket_boundaries)={len(bucket_boundaries)}`.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_batch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0melement_to_bucket_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;34m\"\"\"Return int64 id of the length bucket for this element.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement_length_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mboundaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mbuckets_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mboundaries\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mbuckets_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboundaries\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mconditions_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mless_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuckets_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mless\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuckets_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mbucket_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconditions_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mbucket_id\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mwindow_size_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;31m# The window size is set to the batch size for this bucket\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mwindow_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbucket_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mmake_padded_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_filler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnone_filler\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpadded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mbatching_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrouped_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;34m\"\"\"Batch elements in dataset.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow_size_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mno_padding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mgrouped_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_remainder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mnone_filler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mpad_to_bucket_boundary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"When pad_to_bucket_boundary=True, elements must have \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                   \u001b[0;34m\"length < max(bucket_boundaries).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_less\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mbucket_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_batch_sizes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mboundaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m              \u001b[0mbucket_boundaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mbucket_boundary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboundaries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbucket_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mnone_filler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbucket_boundary\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0minput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_legacy_output_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouped_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_padded_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mpadded_shapes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_filler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnone_filler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mgrouped_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadded_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mshapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mpadding_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_remainder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_by_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mkey_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melement_to_bucket_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatching_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mwindow_size_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow_size_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrerandomize_each_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Creates a `Dataset` of pseudorandom values.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The dataset generates a sequence of uniformly distributed integer values.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    `rerandomize_each_iteration` controls whether the sequence of random number\u001b[0m\n",
      "\u001b[0;34m    generated should be re-randomized for each epoch. The default value is False\u001b[0m\n",
      "\u001b[0;34m    where the dataset generates the same sequence of random numbers for each\u001b[0m\n",
      "\u001b[0;34m    epoch.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> ds1 = tf.data.Dataset.random(seed=4).take(10)\u001b[0m\n",
      "\u001b[0;34m    >>> ds2 = tf.data.Dataset.random(seed=4).take(10)\u001b[0m\n",
      "\u001b[0;34m    >>> print(list(ds1.as_numpy_iterator())==list(ds2.as_numpy_iterator()))\u001b[0m\n",
      "\u001b[0;34m    True\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> ds3 = tf.data.Dataset.random(seed=4).take(10)\u001b[0m\n",
      "\u001b[0;34m    >>> ds3_first_epoch = list(ds3.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    >>> ds3_second_epoch = list(ds3.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    >>> print(ds3_first_epoch == ds3_second_epoch)\u001b[0m\n",
      "\u001b[0;34m    True\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> ds4 = tf.data.Dataset.random(\u001b[0m\n",
      "\u001b[0;34m    ...     seed=4, rerandomize_each_iteration=True).take(10)\u001b[0m\n",
      "\u001b[0;34m    >>> ds4_first_epoch = list(ds4.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    >>> ds4_second_epoch = list(ds4.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    >>> print(ds4_first_epoch == ds4_second_epoch)\u001b[0m\n",
      "\u001b[0;34m    False\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      seed: (Optional) If specified, the dataset produces a deterministic\u001b[0m\n",
      "\u001b[0;34m        sequence of values.\u001b[0m\n",
      "\u001b[0;34m      rerandomize_each_iteration: (Optional) If set to False, the dataset\u001b[0m\n",
      "\u001b[0;34m      generates the same sequence of random numbers for each epoch. If set to\u001b[0m\n",
      "\u001b[0;34m      True, it generates a different deterministic sequence of random numbers\u001b[0m\n",
      "\u001b[0;34m      for each epoch. It is defaulted to False if left unspecified.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      Dataset: A `Dataset`.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# dataset_ops -> random_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mrandom_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mrerandomize_each_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrerandomize_each_iteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0msnapshot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"AUTO\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mreader_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mshard_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"API to persist the output of the input dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The snapshot API allows users to transparently persist the output of their\u001b[0m\n",
      "\u001b[0;34m    preprocessing pipeline to disk, and materialize the pre-processed data on a\u001b[0m\n",
      "\u001b[0;34m    different training run.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This API enables repeated preprocessing steps to be consolidated, and allows\u001b[0m\n",
      "\u001b[0;34m    re-use of already processed data, trading off disk storage and network\u001b[0m\n",
      "\u001b[0;34m    bandwidth for freeing up more valuable CPU resources and accelerator compute\u001b[0m\n",
      "\u001b[0;34m    time.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    https://github.com/tensorflow/community/blob/master/rfcs/20200107-tf-data-snapshot.md\u001b[0m\n",
      "\u001b[0;34m    has detailed design documentation of this feature.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Users can specify various options to control the behavior of snapshot,\u001b[0m\n",
      "\u001b[0;34m    including how snapshots are read from and written to by passing in\u001b[0m\n",
      "\u001b[0;34m    user-defined functions to the `reader_func` and `shard_func` parameters.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    `shard_func` is a user specified function that maps input elements to\u001b[0m\n",
      "\u001b[0;34m    snapshot shards.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Users may want to specify this function to control how snapshot files should\u001b[0m\n",
      "\u001b[0;34m    be written to disk. Below is an example of how a potential `shard_func`\u001b[0m\n",
      "\u001b[0;34m    could be written.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```python\u001b[0m\n",
      "\u001b[0;34m    dataset = ...\u001b[0m\n",
      "\u001b[0;34m    dataset = dataset.enumerate()\u001b[0m\n",
      "\u001b[0;34m    dataset = dataset.snapshot(\"/path/to/snapshot/dir\",\u001b[0m\n",
      "\u001b[0;34m        shard_func=lambda x, y: x % NUM_SHARDS, ...)\u001b[0m\n",
      "\u001b[0;34m    dataset = dataset.map(lambda x, y: y)\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    `reader_func` is a user specified function that accepts a single argument:\u001b[0m\n",
      "\u001b[0;34m    (1) a Dataset of Datasets, each representing a \"split\" of elements of the\u001b[0m\n",
      "\u001b[0;34m    original dataset. The cardinality of the input dataset matches the\u001b[0m\n",
      "\u001b[0;34m    number of the shards specified in the `shard_func` (see above). The function\u001b[0m\n",
      "\u001b[0;34m    should return a Dataset of elements of the original dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Users may want specify this function to control how snapshot files should be\u001b[0m\n",
      "\u001b[0;34m    read from disk, including the amount of shuffling and parallelism.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Here is an example of a standard reader function a user can define. This\u001b[0m\n",
      "\u001b[0;34m    function enables both dataset shuffling and parallel reading of datasets:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```python\u001b[0m\n",
      "\u001b[0;34m    def user_reader_func(datasets):\u001b[0m\n",
      "\u001b[0;34m      # shuffle the datasets splits\u001b[0m\n",
      "\u001b[0;34m      datasets = datasets.shuffle(NUM_CORES)\u001b[0m\n",
      "\u001b[0;34m      # read datasets in parallel and interleave their elements\u001b[0m\n",
      "\u001b[0;34m      return datasets.interleave(lambda x: x, num_parallel_calls=AUTOTUNE)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    dataset = dataset.snapshot(\"/path/to/snapshot/dir\",\u001b[0m\n",
      "\u001b[0;34m        reader_func=user_reader_func)\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    By default, snapshot parallelizes reads by the number of cores available on\u001b[0m\n",
      "\u001b[0;34m    the system, but will not attempt to shuffle the data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      path: Required. A directory to use for storing / loading the snapshot to /\u001b[0m\n",
      "\u001b[0;34m        from.\u001b[0m\n",
      "\u001b[0;34m      compression: Optional. The type of compression to apply to the snapshot\u001b[0m\n",
      "\u001b[0;34m        written to disk. Supported options are `GZIP`, `SNAPPY`, `AUTO` or None.\u001b[0m\n",
      "\u001b[0;34m        Defaults to `AUTO`, which attempts to pick an appropriate compression\u001b[0m\n",
      "\u001b[0;34m        algorithm for the dataset.\u001b[0m\n",
      "\u001b[0;34m      reader_func: Optional. A function to control how to read data from\u001b[0m\n",
      "\u001b[0;34m        snapshot shards.\u001b[0m\n",
      "\u001b[0;34m      shard_func: Optional. A function to control how to shard data when writing\u001b[0m\n",
      "\u001b[0;34m        a snapshot.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# dataset_ops -> snapshot_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msnapshot_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0msnapshot_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_snapshot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshard_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscan_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"A transformation that scans a function across an input dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This transformation is a stateful relative of `tf.data.Dataset.map`.\u001b[0m\n",
      "\u001b[0;34m    In addition to mapping `scan_func` across the elements of the input dataset,\u001b[0m\n",
      "\u001b[0;34m    `scan()` accumulates one or more state tensors, whose initial values are\u001b[0m\n",
      "\u001b[0;34m    `initial_state`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(10)\u001b[0m\n",
      "\u001b[0;34m    >>> initial_state = tf.constant(0, dtype=tf.int64)\u001b[0m\n",
      "\u001b[0;34m    >>> scan_func = lambda state, i: (state + i, state + i)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.scan(initial_state=initial_state, scan_func=scan_func)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [0, 1, 3, 6, 10, 15, 21, 28, 36, 45]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      initial_state: A nested structure of tensors, representing the initial\u001b[0m\n",
      "\u001b[0;34m        state of the accumulator.\u001b[0m\n",
      "\u001b[0;34m      scan_func: A function that maps `(old_state, input_element)` to\u001b[0m\n",
      "\u001b[0;34m        `(new_state, output_element)`. It must take two arguments and return a\u001b[0m\n",
      "\u001b[0;34m        pair of nested structures of tensors. The `new_state` must match the\u001b[0m\n",
      "\u001b[0;34m        structure of `initial_state`.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# scan_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscan_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mscan_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscan_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mtake_while\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"A transformation that stops dataset iteration based on a `predicate`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.range(10)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.take_while(lambda x: x < 5)\u001b[0m\n",
      "\u001b[0;34m    >>> list(dataset.as_numpy_iterator())\u001b[0m\n",
      "\u001b[0;34m    [0, 1, 2, 3, 4]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      predicate: A function that maps a nested structure of tensors (having\u001b[0m\n",
      "\u001b[0;34m        shapes and types defined by `self.output_shapes` and\u001b[0m\n",
      "\u001b[0;34m        `self.output_types`) to a scalar `tf.bool` tensor.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# dataset_ops -> take_while_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtake_while_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mtake_while_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_while\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"A transformation that discards duplicate elements of a `Dataset`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Use this transformation to produce a dataset that contains one instance of\u001b[0m\n",
      "\u001b[0;34m    each unique element in the input. For example:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 37, 2, 37, 2, 1])\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.unique()\u001b[0m\n",
      "\u001b[0;34m    >>> sorted(list(dataset.as_numpy_iterator()))\u001b[0m\n",
      "\u001b[0;34m    [1, 2, 37]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note: This transformation only supports datasets which fit into memory\u001b[0m\n",
      "\u001b[0;34m    and have elements of either `tf.int32`, `tf.int64` or `tf.string` type.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency (dataset_ops -> unique_op ->\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munique_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0munique_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mrejection_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Resamples elements to reach a target distribution.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Note: This implementation can reject **or repeat** elements in order to\u001b[0m\n",
      "\u001b[0;34m    reach the `target_dist`. So, in some cases, the output `Dataset` may be\u001b[0m\n",
      "\u001b[0;34m    larger than the input `Dataset`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> initial_dist = [0.6, 0.4]\u001b[0m\n",
      "\u001b[0;34m    >>> n = 1000\u001b[0m\n",
      "\u001b[0;34m    >>> elems = np.random.choice(len(initial_dist), size=n, p=initial_dist)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = tf.data.Dataset.from_tensor_slices(elems)\u001b[0m\n",
      "\u001b[0;34m    >>> zero, one = np.bincount(list(dataset.as_numpy_iterator())) / n\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Following from `initial_dist`, `zero` is ~0.6 and `one` is ~0.4.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> target_dist = [0.5, 0.5]\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.rejection_resample(\u001b[0m\n",
      "\u001b[0;34m    ...    class_func=lambda x: x,\u001b[0m\n",
      "\u001b[0;34m    ...    target_dist=target_dist,\u001b[0m\n",
      "\u001b[0;34m    ...    initial_dist=initial_dist)\u001b[0m\n",
      "\u001b[0;34m    >>> dataset = dataset.map(lambda class_func_result, data: data)\u001b[0m\n",
      "\u001b[0;34m    >>> zero, one = np.bincount(list(dataset.as_numpy_iterator())) / n\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Following from `target_dist`, `zero` is ~0.5 and `one` is ~0.5.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      class_func: A function mapping an element of the input dataset to a scalar\u001b[0m\n",
      "\u001b[0;34m        `tf.int32` tensor. Values should be in `[0, num_classes)`.\u001b[0m\n",
      "\u001b[0;34m      target_dist: A floating point type tensor, shaped `[num_classes]`.\u001b[0m\n",
      "\u001b[0;34m      initial_dist: (Optional.)  A floating point type tensor, shaped\u001b[0m\n",
      "\u001b[0;34m        `[num_classes]`.  If not provided, the true class distribution is\u001b[0m\n",
      "\u001b[0;34m        estimated live in a streaming fashion.\u001b[0m\n",
      "\u001b[0;34m      seed: (Optional.) Python integer seed for the resampler.\u001b[0m\n",
      "\u001b[0;34m      name: (Optional.) A name for the tf.data operation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# TODO(b/245793127): Consider switching back to the 'v1' implementation.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtarget_dist_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"target_dist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtarget_dist_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dist_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Get initial distribution.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0minitial_dist\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0minitial_dist_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"initial_dist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0minitial_dist_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_dist_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0macceptance_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_of_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0m_calculate_acceptance_probs_with_mixing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_dist_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                                                  \u001b[0mtarget_dist_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0minitial_dist_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0minitial_dist_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0macceptance_dist_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0macceptance_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mprob_of_original_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mprob_of_original\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0minitial_dist_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_estimate_initial_dist_ds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mtarget_dist_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0macceptance_and_original_prob_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_dist_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;32mlambda\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_calculate_acceptance_probs_with_mixing\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# pylint: disable=g-long-lambda\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m              \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dist_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0macceptance_dist_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macceptance_and_original_prob_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;32mlambda\u001b[0m \u001b[0maccept_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maccept_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mprob_of_original_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macceptance_and_original_prob_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;32mlambda\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_original\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprob_original\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfiltered_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_ds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macceptance_dist_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_dist_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                             \u001b[0mclass_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Prefetch filtered dataset for speed.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfiltered_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprob_original_static\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_prob_original_static\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0minitial_dist_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dist_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minitial_dist\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0madd_class_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mclass_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mclass_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mprob_original_static\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_class_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0mprob_original_static\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mfiltered_ds\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_from_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_class_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_ds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprob_of_original_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m          \u001b[0mstop_on_empty_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0msample_from_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mstop_on_empty_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mrerandomize_each_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Samples elements at random from the datasets in `datasets`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Creates a dataset by interleaving elements of `datasets` with `weight[i]`\u001b[0m\n",
      "\u001b[0;34m    probability of picking an element from dataset `i`. Sampling is done without\u001b[0m\n",
      "\u001b[0;34m    replacement. For example, suppose we have 2 datasets:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```python\u001b[0m\n",
      "\u001b[0;34m    dataset1 = tf.data.Dataset.range(0, 3)\u001b[0m\n",
      "\u001b[0;34m    dataset2 = tf.data.Dataset.range(100, 103)\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Suppose that we sample from these 2 datasets with the following weights:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```python\u001b[0m\n",
      "\u001b[0;34m    sample_dataset = tf.data.Dataset.sample_from_datasets(\u001b[0m\n",
      "\u001b[0;34m        [dataset1, dataset2], weights=[0.5, 0.5])\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    One possible outcome of elements in sample_dataset is:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m    print(list(sample_dataset.as_numpy_iterator()))\u001b[0m\n",
      "\u001b[0;34m    # [100, 0, 1, 101, 2, 102]\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      datasets: A non-empty list of `tf.data.Dataset` objects with compatible\u001b[0m\n",
      "\u001b[0;34m        structure.\u001b[0m\n",
      "\u001b[0;34m      weights: (Optional.) A list or Tensor of `len(datasets)` floating-point\u001b[0m\n",
      "\u001b[0;34m        values where `weights[i]` represents the probability to sample from\u001b[0m\n",
      "\u001b[0;34m        `datasets[i]`, or a `tf.data.Dataset` object where each element is such\u001b[0m\n",
      "\u001b[0;34m        a list. Defaults to a uniform distribution across `datasets`.\u001b[0m\n",
      "\u001b[0;34m      seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\u001b[0m\n",
      "\u001b[0;34m        seed that will be used to create the distribution. See\u001b[0m\n",
      "\u001b[0;34m        `tf.random.set_seed` for behavior.\u001b[0m\n",
      "\u001b[0;34m      stop_on_empty_dataset: If `True`, sampling stops if it encounters an empty\u001b[0m\n",
      "\u001b[0;34m        dataset. If `False`, it continues sampling and skips any empty datasets.\u001b[0m\n",
      "\u001b[0;34m        It is recommended to set it to `True`. Otherwise, the distribution of\u001b[0m\n",
      "\u001b[0;34m        samples starts off as the user intends, but may change as input datasets\u001b[0m\n",
      "\u001b[0;34m        become empty. This can be difficult to detect since the dataset starts\u001b[0m\n",
      "\u001b[0;34m        off looking correct. Default to `False` for backward compatibility.\u001b[0m\n",
      "\u001b[0;34m      rerandomize_each_iteration: An optional `bool`. The boolean argument\u001b[0m\n",
      "\u001b[0;34m      controls whether the sequence of random numbers used to determine which\u001b[0m\n",
      "\u001b[0;34m      dataset to sample from will be rerandomized each epoch. That is, it\u001b[0m\n",
      "\u001b[0;34m      determinies whether datasets will be sampled in the same order across\u001b[0m\n",
      "\u001b[0;34m      different epochs (the default behavior) or not.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A dataset that interleaves elements from `datasets` at random, according\u001b[0m\n",
      "\u001b[0;34m      to `weights` if provided, otherwise with uniform probability.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Raises:\u001b[0m\n",
      "\u001b[0;34m      TypeError: If the `datasets` or `weights` arguments have the wrong type.\u001b[0m\n",
      "\u001b[0;34m      ValueError:\u001b[0m\n",
      "\u001b[0;34m        - If `datasets` is empty, or\u001b[0m\n",
      "\u001b[0;34m        - If `weights` is specified and does not match the length of `datasets`.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# (dataset_ops -> sample_from_datasets_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msample_from_datasets_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0msample_from_datasets_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_from_datasets\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstop_on_empty_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mrerandomize_each_iteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mchoose_from_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m      \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoice_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_on_empty_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m  \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetV2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Creates a dataset that deterministically chooses elements from `datasets`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    For example, given the following datasets:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```python\u001b[0m\n",
      "\u001b[0;34m    datasets = [tf.data.Dataset.from_tensors(\"foo\").repeat(),\u001b[0m\n",
      "\u001b[0;34m                tf.data.Dataset.from_tensors(\"bar\").repeat(),\u001b[0m\n",
      "\u001b[0;34m                tf.data.Dataset.from_tensors(\"baz\").repeat()]\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    # Define a dataset containing `[0, 1, 2, 0, 1, 2, 0, 1, 2]`.\u001b[0m\n",
      "\u001b[0;34m    choice_dataset = tf.data.Dataset.range(3).repeat(3)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    result = tf.data.Dataset.choose_from_datasets(datasets, choice_dataset)\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The elements of `result` will be:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m    \"foo\", \"bar\", \"baz\", \"foo\", \"bar\", \"baz\", \"foo\", \"bar\", \"baz\"\u001b[0m\n",
      "\u001b[0;34m    ```\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      datasets: A non-empty list of `tf.data.Dataset` objects with compatible\u001b[0m\n",
      "\u001b[0;34m        structure.\u001b[0m\n",
      "\u001b[0;34m      choice_dataset: A `tf.data.Dataset` of scalar `tf.int64` tensors between\u001b[0m\n",
      "\u001b[0;34m        `0` and `len(datasets) - 1`.\u001b[0m\n",
      "\u001b[0;34m      stop_on_empty_dataset: If `True`, selection stops if it encounters an\u001b[0m\n",
      "\u001b[0;34m        empty dataset. If `False`, it skips empty datasets. It is recommended to\u001b[0m\n",
      "\u001b[0;34m        set it to `True`. Otherwise, the selected elements start off as the user\u001b[0m\n",
      "\u001b[0;34m        intends, but may change as input datasets become empty. This can be\u001b[0m\n",
      "\u001b[0;34m        difficult to detect since the dataset starts off looking correct.\u001b[0m\n",
      "\u001b[0;34m        Defaults to `True`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns:\u001b[0m\n",
      "\u001b[0;34m      A new `Dataset` with the transformation applied as described above.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Raises:\u001b[0m\n",
      "\u001b[0;34m      TypeError: If `datasets` or `choice_dataset` has the wrong type.\u001b[0m\n",
      "\u001b[0;34m      ValueError: If `datasets` is empty.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Loaded lazily due to a circular dependency\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# (dataset_ops -> choose_from_datasets_op -> dataset_ops).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchoose_from_datasets_op\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mchoose_from_datasets_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_choose_from_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoice_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_on_empty_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     DatasetV1, DatasetSource, UnaryDataset, _VariantDataset, TFRecordDatasetV2, _PerDeviceGenerator, _ReincarnatedPerDeviceGenerator"
     ]
    }
   ],
   "source": [
    "tf.data.Dataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case, we have two data sets separting cheetah and lions images\n",
    "\n",
    "cheetah_folder = \"./images/Cheetahs\"\n",
    "lion_folder = \"./images/Lions\"\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        if os.path.isfile(img_path):\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is not None:\n",
    "                images.append(image)\n",
    "                labels.append(folder.split('/')[-1])  # Assuming folder name is the label\n",
    "    return images, labels\n",
    "\n",
    "cheetah_images, cheetah_labels = load_images_from_folder(cheetah_folder)\n",
    "lion_images, lion_labels = load_images_from_folder(lion_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 15,  76,  72],\n",
       "         [ 38,  99,  95],\n",
       "         [ 37, 103,  98],\n",
       "         ...,\n",
       "         [  0,  64,  45],\n",
       "         [  0,  60,  49],\n",
       "         [  0,  59,  49]],\n",
       " \n",
       "        [[ 40, 111, 101],\n",
       "         [ 56, 123, 114],\n",
       "         [ 52, 115, 105],\n",
       "         ...,\n",
       "         [  4,  65,  45],\n",
       "         [  1,  60,  46],\n",
       "         [  2,  58,  47]],\n",
       " \n",
       "        [[ 15,  73,  62],\n",
       "         [ 11,  69,  58],\n",
       "         [  6,  67,  53],\n",
       "         ...,\n",
       "         [  4,  63,  43],\n",
       "         [  0,  57,  42],\n",
       "         [  2,  56,  43]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 94, 148, 159],\n",
       "         [ 78, 131, 144],\n",
       "         [ 70, 122, 135],\n",
       "         ...,\n",
       "         [ 75, 125, 137],\n",
       "         [ 87, 136, 146],\n",
       "         [ 70, 117, 125]],\n",
       " \n",
       "        [[ 94, 144, 162],\n",
       "         [ 82, 130, 148],\n",
       "         [ 72, 119, 140],\n",
       "         ...,\n",
       "         [ 86, 132, 150],\n",
       "         [ 91, 138, 152],\n",
       "         [ 80, 125, 139]],\n",
       " \n",
       "        [[ 92, 142, 162],\n",
       "         [ 84, 131, 153],\n",
       "         [ 75, 119, 142],\n",
       "         ...,\n",
       "         [ 85, 131, 149],\n",
       "         [ 86, 132, 150],\n",
       "         [ 78, 121, 140]]], dtype=uint8),\n",
       " array([[[ 23,  33,  43],\n",
       "         [ 22,  32,  42],\n",
       "         [ 20,  31,  39],\n",
       "         ...,\n",
       "         [ 91, 102, 100],\n",
       "         [ 92, 103, 100],\n",
       "         [ 94, 105, 102]],\n",
       " \n",
       "        [[ 22,  34,  44],\n",
       "         [ 21,  33,  43],\n",
       "         [ 20,  33,  41],\n",
       "         ...,\n",
       "         [ 93, 104, 102],\n",
       "         [ 95, 106, 103],\n",
       "         [ 98, 109, 106]],\n",
       " \n",
       "        [[ 24,  39,  48],\n",
       "         [ 22,  37,  46],\n",
       "         [ 22,  37,  46],\n",
       "         ...,\n",
       "         [ 93, 104, 101],\n",
       "         [ 98, 110, 104],\n",
       "         [102, 114, 108]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 93, 101, 101],\n",
       "         [ 91,  99,  99],\n",
       "         [ 85,  93,  93],\n",
       "         ...,\n",
       "         [ 62, 115, 112],\n",
       "         [ 86, 140, 135],\n",
       "         [ 92, 143, 139]],\n",
       " \n",
       "        [[ 99, 107, 107],\n",
       "         [ 94, 102, 102],\n",
       "         [ 92, 100, 100],\n",
       "         ...,\n",
       "         [ 46, 105, 101],\n",
       "         [ 81, 138, 135],\n",
       "         [ 93, 150, 147]],\n",
       " \n",
       "        [[ 94, 102, 102],\n",
       "         [ 93, 101, 101],\n",
       "         [ 94,  99, 100],\n",
       "         ...,\n",
       "         [ 57, 116, 112],\n",
       "         [ 83, 142, 138],\n",
       "         [116, 175, 171]]], dtype=uint8),\n",
       " array([[[  3,  71,  54],\n",
       "         [  4,  69,  53],\n",
       "         [  2,  70,  53],\n",
       "         ...,\n",
       "         [  1,  72,  55],\n",
       "         [  1,  69,  52],\n",
       "         [  1,  71,  54]],\n",
       " \n",
       "        [[  3,  71,  54],\n",
       "         [  0,  68,  51],\n",
       "         [  2,  70,  53],\n",
       "         ...,\n",
       "         [  2,  73,  56],\n",
       "         [  2,  73,  56],\n",
       "         [  2,  72,  55]],\n",
       " \n",
       "        [[  0,  69,  52],\n",
       "         [  1,  71,  54],\n",
       "         [  1,  71,  54],\n",
       "         ...,\n",
       "         [  1,  74,  58],\n",
       "         [  2,  76,  58],\n",
       "         [  3,  71,  54]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 17, 148, 115],\n",
       "         [ 43, 165, 129],\n",
       "         [ 35, 156, 122],\n",
       "         ...,\n",
       "         [  0,  56,  35],\n",
       "         [  2,  47,  30],\n",
       "         [  1,  42,  27]],\n",
       " \n",
       "        [[ 42, 161, 130],\n",
       "         [ 45, 165, 131],\n",
       "         [ 34, 154, 123],\n",
       "         ...,\n",
       "         [  1,  57,  36],\n",
       "         [  1,  51,  33],\n",
       "         [  0,  51,  34]],\n",
       " \n",
       "        [[ 38, 158, 127],\n",
       "         [ 44, 163, 132],\n",
       "         [ 33, 143, 117],\n",
       "         ...,\n",
       "         [  1,  62,  42],\n",
       "         [  1,  64,  44],\n",
       "         [  4,  69,  48]]], dtype=uint8),\n",
       " array([[[ 9, 24, 20],\n",
       "         [13, 28, 24],\n",
       "         [13, 26, 24],\n",
       "         ...,\n",
       "         [ 8, 17, 20],\n",
       "         [12, 21, 25],\n",
       "         [ 9, 21, 25]],\n",
       " \n",
       "        [[ 7, 18, 16],\n",
       "         [ 8, 19, 17],\n",
       "         [ 8, 18, 18],\n",
       "         ...,\n",
       "         [12, 19, 28],\n",
       "         [15, 22, 31],\n",
       "         [13, 23, 33]],\n",
       " \n",
       "        [[15, 22, 25],\n",
       "         [13, 20, 23],\n",
       "         [11, 16, 19],\n",
       "         ...,\n",
       "         [11, 17, 28],\n",
       "         [11, 19, 32],\n",
       "         [11, 20, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0, 29, 60],\n",
       "         [ 2, 31, 62],\n",
       "         [ 8, 38, 65],\n",
       "         ...,\n",
       "         [12, 14, 24],\n",
       "         [14, 16, 26],\n",
       "         [11, 17, 28]],\n",
       " \n",
       "        [[ 0, 33, 63],\n",
       "         [ 3, 37, 67],\n",
       "         [ 7, 39, 68],\n",
       "         ...,\n",
       "         [16, 16, 30],\n",
       "         [18, 17, 33],\n",
       "         [14, 17, 32]],\n",
       " \n",
       "        [[10, 46, 76],\n",
       "         [15, 49, 79],\n",
       "         [15, 47, 76],\n",
       "         ...,\n",
       "         [21, 19, 38],\n",
       "         [23, 21, 40],\n",
       "         [17, 18, 38]]], dtype=uint8),\n",
       " array([[[ 39,  75,  53],\n",
       "         [ 59,  95,  73],\n",
       "         [ 71, 104,  83],\n",
       "         ...,\n",
       "         [ 51,  93,  68],\n",
       "         [ 60, 104,  81],\n",
       "         [ 69, 113,  90]],\n",
       " \n",
       "        [[ 43,  79,  57],\n",
       "         [ 63,  99,  77],\n",
       "         [ 75, 108,  87],\n",
       "         ...,\n",
       "         [ 61, 103,  78],\n",
       "         [ 69, 111,  88],\n",
       "         [ 73, 117,  94]],\n",
       " \n",
       "        [[ 41,  76,  56],\n",
       "         [ 61,  96,  76],\n",
       "         [ 74, 106,  87],\n",
       "         ...,\n",
       "         [ 71, 113,  88],\n",
       "         [ 74, 116,  93],\n",
       "         [ 74, 116,  93]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 89, 191, 150],\n",
       "         [ 94, 196, 155],\n",
       "         [100, 202, 161],\n",
       "         ...,\n",
       "         [110, 201, 176],\n",
       "         [106, 200, 176],\n",
       "         [113, 208, 187]],\n",
       " \n",
       "        [[ 87, 186, 146],\n",
       "         [ 93, 192, 152],\n",
       "         [ 99, 201, 160],\n",
       "         ...,\n",
       "         [118, 209, 176],\n",
       "         [117, 207, 177],\n",
       "         [124, 216, 187]],\n",
       " \n",
       "        [[ 86, 183, 143],\n",
       "         [ 92, 191, 151],\n",
       "         [100, 202, 161],\n",
       "         ...,\n",
       "         [125, 215, 179],\n",
       "         [124, 214, 179],\n",
       "         [131, 220, 187]]], dtype=uint8),\n",
       " array([[[113, 153, 178],\n",
       "         [119, 159, 184],\n",
       "         [124, 165, 190],\n",
       "         ...,\n",
       "         [ 81, 133, 145],\n",
       "         [101, 144, 161],\n",
       "         [107, 147, 165]],\n",
       " \n",
       "        [[110, 150, 175],\n",
       "         [115, 155, 180],\n",
       "         [122, 163, 188],\n",
       "         ...,\n",
       "         [ 86, 136, 148],\n",
       "         [ 98, 141, 156],\n",
       "         [100, 141, 156]],\n",
       " \n",
       "        [[113, 154, 179],\n",
       "         [111, 152, 177],\n",
       "         [125, 166, 191],\n",
       "         ...,\n",
       "         [ 84, 134, 146],\n",
       "         [ 93, 137, 150],\n",
       "         [ 96, 135, 149]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[114, 144, 161],\n",
       "         [134, 164, 181],\n",
       "         [ 93, 126, 141],\n",
       "         ...,\n",
       "         [109, 139, 164],\n",
       "         [ 46,  74,  98],\n",
       "         [ 72, 100, 124]],\n",
       " \n",
       "        [[ 98, 126, 143],\n",
       "         [170, 203, 219],\n",
       "         [162, 198, 214],\n",
       "         ...,\n",
       "         [ 73, 103, 128],\n",
       "         [ 80, 111, 134],\n",
       "         [ 88, 119, 142]],\n",
       " \n",
       "        [[ 89, 117, 134],\n",
       "         [ 99, 132, 148],\n",
       "         [170, 209, 224],\n",
       "         ...,\n",
       "         [181, 211, 236],\n",
       "         [158, 190, 213],\n",
       "         [132, 164, 187]]], dtype=uint8),\n",
       " array([[[ 19,  28,  37],\n",
       "         [ 18,  30,  42],\n",
       "         [ 21,  30,  43],\n",
       "         ...,\n",
       "         [ 85,  77,  77],\n",
       "         [ 87,  80,  77],\n",
       "         [ 87,  78,  74]],\n",
       " \n",
       "        [[ 19,  26,  35],\n",
       "         [ 20,  28,  41],\n",
       "         [ 20,  28,  41],\n",
       "         ...,\n",
       "         [ 89,  79,  79],\n",
       "         [ 94,  83,  79],\n",
       "         [ 93,  79,  73]],\n",
       " \n",
       "        [[ 22,  28,  35],\n",
       "         [ 21,  27,  40],\n",
       "         [ 23,  31,  44],\n",
       "         ...,\n",
       "         [ 98,  83,  80],\n",
       "         [ 96,  82,  76],\n",
       "         [ 97,  84,  76]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  70,  78],\n",
       "         [ 72,  83,  91],\n",
       "         [ 91, 100, 113],\n",
       "         ...,\n",
       "         [ 22,  39,  66],\n",
       "         [ 22,  36,  64],\n",
       "         [ 20,  34,  62]],\n",
       " \n",
       "        [[ 57,  71,  83],\n",
       "         [ 76,  92, 109],\n",
       "         [ 86,  97, 117],\n",
       "         ...,\n",
       "         [ 19,  36,  63],\n",
       "         [ 19,  36,  62],\n",
       "         [ 24,  38,  66]],\n",
       " \n",
       "        [[ 62,  76,  95],\n",
       "         [ 84,  99, 125],\n",
       "         [ 86,  98, 122],\n",
       "         ...,\n",
       "         [ 23,  39,  68],\n",
       "         [ 22,  36,  64],\n",
       "         [ 22,  36,  65]]], dtype=uint8),\n",
       " array([[[ 41,  46,  14],\n",
       "         [ 36,  41,  10],\n",
       "         [ 33,  38,  11],\n",
       "         ...,\n",
       "         [ 82,  98, 104],\n",
       "         [ 76,  95, 102],\n",
       "         [ 72,  94, 100]],\n",
       " \n",
       "        [[ 42,  41,  13],\n",
       "         [ 37,  36,  10],\n",
       "         [ 31,  34,   9],\n",
       "         ...,\n",
       "         [ 78,  95,  98],\n",
       "         [ 68,  87,  92],\n",
       "         [ 61,  81,  86]],\n",
       " \n",
       "        [[ 71,  65,  42],\n",
       "         [ 57,  50,  30],\n",
       "         [ 41,  37,  18],\n",
       "         ...,\n",
       "         [ 84, 102, 101],\n",
       "         [ 68,  89,  87],\n",
       "         [ 56,  78,  76]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 85,  96,  93],\n",
       "         [ 78,  89,  86],\n",
       "         [ 77,  92,  88],\n",
       "         ...,\n",
       "         [ 87, 173, 113],\n",
       "         [ 89, 170, 107],\n",
       "         [ 92, 171, 108]],\n",
       " \n",
       "        [[ 98, 120, 115],\n",
       "         [ 96, 118, 113],\n",
       "         [ 93, 119, 113],\n",
       "         ...,\n",
       "         [ 86, 170, 111],\n",
       "         [ 88, 169, 106],\n",
       "         [ 93, 170, 108]],\n",
       " \n",
       "        [[105, 136, 129],\n",
       "         [114, 145, 138],\n",
       "         [117, 151, 144],\n",
       "         ...,\n",
       "         [ 80, 162, 103],\n",
       "         [ 84, 161,  99],\n",
       "         [ 93, 166, 104]]], dtype=uint8),\n",
       " array([[[159, 238, 211],\n",
       "         [142, 226, 198],\n",
       "         [120, 213, 184],\n",
       "         ...,\n",
       "         [ 83, 152, 109],\n",
       "         [ 77, 149, 103],\n",
       "         [ 73, 145,  99]],\n",
       " \n",
       "        [[158, 241, 216],\n",
       "         [144, 231, 205],\n",
       "         [127, 220, 193],\n",
       "         ...,\n",
       "         [ 83, 152, 109],\n",
       "         [ 77, 150, 104],\n",
       "         [ 72, 145,  99]],\n",
       " \n",
       "        [[162, 244, 221],\n",
       "         [150, 236, 212],\n",
       "         [136, 227, 204],\n",
       "         ...,\n",
       "         [ 80, 152, 106],\n",
       "         [ 73, 148, 102],\n",
       "         [ 67, 142,  96]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  7,   5,   4],\n",
       "         [  7,   5,   4],\n",
       "         [  8,   6,   5],\n",
       "         ...,\n",
       "         [ 54,  85,  58],\n",
       "         [ 64,  95,  68],\n",
       "         [ 74, 103,  77]],\n",
       " \n",
       "        [[  2,   0,   0],\n",
       "         [  4,   2,   1],\n",
       "         [  8,   6,   5],\n",
       "         ...,\n",
       "         [ 45,  80,  53],\n",
       "         [ 52,  87,  61],\n",
       "         [ 59,  91,  66]],\n",
       " \n",
       "        [[  8,   9,   7],\n",
       "         [  1,   2,   0],\n",
       "         [  0,   1,   0],\n",
       "         ...,\n",
       "         [ 39,  77,  49],\n",
       "         [ 44,  81,  55],\n",
       "         [ 48,  83,  57]]], dtype=uint8),\n",
       " array([[[250, 247, 249],\n",
       "         [251, 248, 250],\n",
       "         [253, 247, 248],\n",
       "         ...,\n",
       "         [249, 248, 244],\n",
       "         [248, 247, 243],\n",
       "         [248, 247, 243]],\n",
       " \n",
       "        [[250, 248, 248],\n",
       "         [250, 248, 248],\n",
       "         [252, 247, 248],\n",
       "         ...,\n",
       "         [249, 248, 244],\n",
       "         [249, 248, 244],\n",
       "         [249, 248, 244]],\n",
       " \n",
       "        [[251, 249, 249],\n",
       "         [250, 248, 248],\n",
       "         [252, 247, 248],\n",
       "         ...,\n",
       "         [250, 247, 243],\n",
       "         [248, 247, 243],\n",
       "         [250, 249, 245]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 26,  89,  80],\n",
       "         [ 27,  87,  81],\n",
       "         [ 29,  95,  84],\n",
       "         ...,\n",
       "         [ 27,  95,  78],\n",
       "         [ 28, 107,  86],\n",
       "         [ 11,  85,  67]],\n",
       " \n",
       "        [[ 41, 100,  96],\n",
       "         [ 37,  90,  87],\n",
       "         [ 29,  90,  80],\n",
       "         ...,\n",
       "         [ 20,  86,  67],\n",
       "         [ 18,  94,  70],\n",
       "         [ 19,  96,  69]],\n",
       " \n",
       "        [[ 67, 123, 124],\n",
       "         [ 49,  97,  98],\n",
       "         [ 29,  81,  74],\n",
       "         ...,\n",
       "         [ 14,  74,  56],\n",
       "         [ 17,  85,  60],\n",
       "         [ 20, 102,  67]]], dtype=uint8),\n",
       " array([[[213, 199, 180],\n",
       "         [214, 200, 181],\n",
       "         [214, 200, 181],\n",
       "         ...,\n",
       "         [214, 200, 182],\n",
       "         [214, 200, 182],\n",
       "         [214, 200, 182]],\n",
       " \n",
       "        [[213, 199, 180],\n",
       "         [214, 200, 181],\n",
       "         [214, 200, 181],\n",
       "         ...,\n",
       "         [214, 200, 182],\n",
       "         [214, 200, 182],\n",
       "         [214, 200, 182]],\n",
       " \n",
       "        [[213, 199, 180],\n",
       "         [214, 200, 181],\n",
       "         [214, 200, 181],\n",
       "         ...,\n",
       "         [214, 200, 182],\n",
       "         [214, 200, 182],\n",
       "         [214, 200, 182]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 51,  87, 127],\n",
       "         [ 54,  90, 130],\n",
       "         [ 59,  95, 135],\n",
       "         ...,\n",
       "         [194, 198, 187],\n",
       "         [194, 198, 187],\n",
       "         [194, 198, 187]],\n",
       " \n",
       "        [[ 61,  97, 137],\n",
       "         [ 65, 101, 141],\n",
       "         [ 69, 105, 145],\n",
       "         ...,\n",
       "         [194, 198, 187],\n",
       "         [194, 198, 187],\n",
       "         [194, 198, 187]],\n",
       " \n",
       "        [[ 72, 108, 148],\n",
       "         [ 76, 112, 152],\n",
       "         [ 80, 116, 156],\n",
       "         ...,\n",
       "         [194, 198, 187],\n",
       "         [194, 198, 187],\n",
       "         [194, 198, 187]]], dtype=uint8),\n",
       " array([[[ 33,  49,  66],\n",
       "         [ 29,  45,  62],\n",
       "         [ 27,  44,  63],\n",
       "         ...,\n",
       "         [ 99, 122, 100],\n",
       "         [ 97, 118,  96],\n",
       "         [ 90, 111,  89]],\n",
       " \n",
       "        [[ 31,  47,  64],\n",
       "         [ 24,  42,  59],\n",
       "         [ 24,  41,  60],\n",
       "         ...,\n",
       "         [ 89, 112,  90],\n",
       "         [ 92, 113,  91],\n",
       "         [ 88, 110,  86]],\n",
       " \n",
       "        [[ 24,  42,  59],\n",
       "         [ 26,  44,  61],\n",
       "         [ 28,  45,  64],\n",
       "         ...,\n",
       "         [ 64,  88,  64],\n",
       "         [ 53,  77,  53],\n",
       "         [ 71,  96,  70]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[131, 130, 140],\n",
       "         [113, 115, 123],\n",
       "         [ 86,  89,  93],\n",
       "         ...,\n",
       "         [ 34,  37,  35],\n",
       "         [ 28,  31,  29],\n",
       "         [ 24,  27,  25]],\n",
       " \n",
       "        [[122, 121, 131],\n",
       "         [104, 103, 112],\n",
       "         [ 77,  77,  83],\n",
       "         ...,\n",
       "         [ 28,  30,  30],\n",
       "         [ 25,  27,  27],\n",
       "         [ 22,  24,  24]],\n",
       " \n",
       "        [[106, 103, 112],\n",
       "         [ 88,  87,  96],\n",
       "         [ 78,  78,  84],\n",
       "         ...,\n",
       "         [ 23,  25,  26],\n",
       "         [ 24,  23,  25],\n",
       "         [ 22,  21,  23]]], dtype=uint8),\n",
       " array([[[137, 146, 150],\n",
       "         [122, 131, 135],\n",
       "         [119, 130, 134],\n",
       "         ...,\n",
       "         [166, 175, 179],\n",
       "         [138, 141, 145],\n",
       "         [253, 248, 250]],\n",
       " \n",
       "        [[147, 156, 160],\n",
       "         [114, 125, 129],\n",
       "         [101, 112, 116],\n",
       "         ...,\n",
       "         [157, 166, 170],\n",
       "         [132, 135, 139],\n",
       "         [247, 242, 244]],\n",
       " \n",
       "        [[102, 113, 117],\n",
       "         [ 69,  80,  84],\n",
       "         [ 54,  65,  69],\n",
       "         ...,\n",
       "         [152, 161, 165],\n",
       "         [133, 136, 140],\n",
       "         [249, 244, 246]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 69,  69,  69],\n",
       "         [ 69,  69,  69],\n",
       "         [ 69,  69,  69],\n",
       "         ...,\n",
       "         [ 69,  69,  69],\n",
       "         [ 69,  69,  69],\n",
       "         [ 69,  69,  69]],\n",
       " \n",
       "        [[ 69,  69,  69],\n",
       "         [ 69,  69,  69],\n",
       "         [ 69,  69,  69],\n",
       "         ...,\n",
       "         [ 69,  69,  69],\n",
       "         [ 69,  69,  69],\n",
       "         [ 69,  69,  69]],\n",
       " \n",
       "        [[ 69,  69,  69],\n",
       "         [ 69,  69,  69],\n",
       "         [ 69,  69,  69],\n",
       "         ...,\n",
       "         [ 69,  69,  69],\n",
       "         [ 69,  69,  69],\n",
       "         [ 69,  69,  69]]], dtype=uint8),\n",
       " array([[[203, 189, 200],\n",
       "         [204, 190, 201],\n",
       "         [192, 178, 190],\n",
       "         ...,\n",
       "         [ 55,  81,  68],\n",
       "         [ 56,  82,  69],\n",
       "         [ 93, 119, 106]],\n",
       " \n",
       "        [[204, 190, 201],\n",
       "         [203, 189, 200],\n",
       "         [195, 181, 193],\n",
       "         ...,\n",
       "         [ 56,  82,  69],\n",
       "         [ 57,  83,  70],\n",
       "         [ 89, 115, 102]],\n",
       " \n",
       "        [[207, 194, 202],\n",
       "         [205, 192, 200],\n",
       "         [201, 187, 198],\n",
       "         ...,\n",
       "         [ 58,  84,  71],\n",
       "         [ 58,  86,  73],\n",
       "         [ 70,  98,  85]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[126, 148, 143],\n",
       "         [132, 154, 149],\n",
       "         [140, 162, 157],\n",
       "         ...,\n",
       "         [128, 162, 168],\n",
       "         [122, 158, 166],\n",
       "         [107, 143, 151]],\n",
       " \n",
       "        [[133, 154, 151],\n",
       "         [135, 157, 152],\n",
       "         [140, 161, 158],\n",
       "         ...,\n",
       "         [115, 148, 157],\n",
       "         [117, 152, 162],\n",
       "         [115, 150, 160]],\n",
       " \n",
       "        [[140, 161, 159],\n",
       "         [139, 160, 157],\n",
       "         [142, 163, 161],\n",
       "         ...,\n",
       "         [103, 136, 145],\n",
       "         [106, 140, 153],\n",
       "         [110, 144, 157]]], dtype=uint8),\n",
       " array([[[ 48,  82, 176],\n",
       "         [ 46,  85, 177],\n",
       "         [ 44,  91, 177],\n",
       "         ...,\n",
       "         [ 38,  76, 124],\n",
       "         [  8,  33,  73],\n",
       "         [  4,  23,  60]],\n",
       " \n",
       "        [[ 42,  70, 164],\n",
       "         [ 42,  76, 166],\n",
       "         [ 40,  83, 170],\n",
       "         ...,\n",
       "         [ 23,  56, 102],\n",
       "         [  0,  17,  57],\n",
       "         [  0,  12,  48]],\n",
       " \n",
       "        [[ 25,  43, 132],\n",
       "         [ 27,  49, 137],\n",
       "         [ 31,  64, 150],\n",
       "         ...,\n",
       "         [ 13,  38,  82],\n",
       "         [  0,  17,  57],\n",
       "         [  0,  16,  51]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 38, 126, 190],\n",
       "         [ 22, 103, 170],\n",
       "         [ 19,  84, 158],\n",
       "         ...,\n",
       "         [  7,  40,  85],\n",
       "         [ 16,  53, 109],\n",
       "         [ 25,  66, 128]],\n",
       " \n",
       "        [[ 42, 125, 187],\n",
       "         [ 45, 123, 189],\n",
       "         [ 52, 118, 189],\n",
       "         ...,\n",
       "         [  8,  41,  86],\n",
       "         [ 12,  50, 108],\n",
       "         [ 22,  63, 126]],\n",
       " \n",
       "        [[ 31, 111, 172],\n",
       "         [ 57, 134, 196],\n",
       "         [ 79, 150, 217],\n",
       "         ...,\n",
       "         [  9,  40,  85],\n",
       "         [  7,  47, 105],\n",
       "         [ 15,  61, 125]]], dtype=uint8),\n",
       " array([[[ 20,  63,  26],\n",
       "         [ 20,  63,  26],\n",
       "         [ 26,  66,  31],\n",
       "         ...,\n",
       "         [ 12,  51,  26],\n",
       "         [ 17,  53,  31],\n",
       "         [ 17,  53,  31]],\n",
       " \n",
       "        [[ 22,  66,  30],\n",
       "         [ 21,  65,  29],\n",
       "         [ 25,  67,  32],\n",
       "         ...,\n",
       "         [ 11,  50,  25],\n",
       "         [ 17,  53,  31],\n",
       "         [ 17,  53,  31]],\n",
       " \n",
       "        [[ 23,  69,  33],\n",
       "         [ 22,  68,  32],\n",
       "         [ 25,  68,  35],\n",
       "         ...,\n",
       "         [ 11,  50,  24],\n",
       "         [ 17,  53,  29],\n",
       "         [ 18,  54,  30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[222, 250, 221],\n",
       "         [226, 254, 225],\n",
       "         [221, 252, 221],\n",
       "         ...,\n",
       "         [ 55,  54,  58],\n",
       "         [ 58,  57,  61],\n",
       "         [ 58,  57,  61]],\n",
       " \n",
       "        [[220, 247, 221],\n",
       "         [222, 249, 223],\n",
       "         [217, 248, 219],\n",
       "         ...,\n",
       "         [ 58,  55,  57],\n",
       "         [ 60,  57,  59],\n",
       "         [ 60,  57,  59]],\n",
       " \n",
       "        [[223, 252, 226],\n",
       "         [222, 251, 225],\n",
       "         [218, 249, 220],\n",
       "         ...,\n",
       "         [ 58,  55,  57],\n",
       "         [ 61,  58,  60],\n",
       "         [ 61,  58,  60]]], dtype=uint8),\n",
       " array([[[119, 176, 215],\n",
       "         [110, 167, 206],\n",
       "         [122, 182, 218],\n",
       "         ...,\n",
       "         [ 20,  12,   0],\n",
       "         [ 18,  12,   1],\n",
       "         [ 20,  14,   3]],\n",
       " \n",
       "        [[106, 172, 207],\n",
       "         [100, 165, 203],\n",
       "         [123, 188, 226],\n",
       "         ...,\n",
       "         [ 25,  14,   0],\n",
       "         [ 21,  14,   0],\n",
       "         [ 19,  12,   0]],\n",
       " \n",
       "        [[103, 175, 205],\n",
       "         [ 98, 166, 201],\n",
       "         [125, 192, 231],\n",
       "         ...,\n",
       "         [ 17,   5,   0],\n",
       "         [ 19,  11,   4],\n",
       "         [ 18,   9,   5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 22,  13,   3],\n",
       "         [ 22,  13,   3],\n",
       "         [ 21,  12,   3],\n",
       "         ...,\n",
       "         [ 23,  15,   2],\n",
       "         [ 25,  17,   4],\n",
       "         [ 25,  17,   4]],\n",
       " \n",
       "        [[ 22,  14,   1],\n",
       "         [ 21,  13,   0],\n",
       "         [ 21,  12,   2],\n",
       "         ...,\n",
       "         [ 24,  16,   3],\n",
       "         [ 26,  18,   5],\n",
       "         [ 25,  17,   4]],\n",
       " \n",
       "        [[ 22,  14,   1],\n",
       "         [ 21,  13,   0],\n",
       "         [ 21,  12,   2],\n",
       "         ...,\n",
       "         [ 24,  15,   1],\n",
       "         [ 25,  16,   3],\n",
       "         [ 24,  15,   2]]], dtype=uint8),\n",
       " array([[[ 85, 151,  80],\n",
       "         [ 81, 147,  76],\n",
       "         [ 80, 142,  72],\n",
       "         ...,\n",
       "         [111, 160, 116],\n",
       "         [ 99, 150, 106],\n",
       "         [ 94, 145, 101]],\n",
       " \n",
       "        [[ 86, 152,  81],\n",
       "         [ 83, 149,  78],\n",
       "         [ 83, 145,  75],\n",
       "         ...,\n",
       "         [110, 159, 115],\n",
       "         [102, 151, 107],\n",
       "         [ 96, 147, 103]],\n",
       " \n",
       "        [[ 87, 153,  82],\n",
       "         [ 84, 150,  79],\n",
       "         [ 86, 148,  78],\n",
       "         ...,\n",
       "         [108, 157, 113],\n",
       "         [103, 151, 109],\n",
       "         [101, 149, 107]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 73, 139,  67],\n",
       "         [ 91, 154,  85],\n",
       "         [112, 165, 108],\n",
       "         ...,\n",
       "         [108, 123, 132],\n",
       "         [ 98, 114, 126],\n",
       "         [ 91, 107, 119]],\n",
       " \n",
       "        [[ 60, 130,  53],\n",
       "         [ 78, 144,  72],\n",
       "         [102, 159,  98],\n",
       "         ...,\n",
       "         [112, 127, 136],\n",
       "         [101, 118, 127],\n",
       "         [ 93, 112, 120]],\n",
       " \n",
       "        [[ 67, 140,  60],\n",
       "         [ 84, 151,  76],\n",
       "         [103, 160,  99],\n",
       "         ...,\n",
       "         [119, 134, 143],\n",
       "         [103, 120, 129],\n",
       "         [ 92, 111, 119]]], dtype=uint8),\n",
       " array([[[ 94, 105, 109],\n",
       "         [102, 113, 117],\n",
       "         [130, 141, 145],\n",
       "         ...,\n",
       "         [ 55,  67,  73],\n",
       "         [ 57,  69,  75],\n",
       "         [ 60,  72,  78]],\n",
       " \n",
       "        [[ 98, 109, 113],\n",
       "         [107, 118, 122],\n",
       "         [127, 138, 142],\n",
       "         ...,\n",
       "         [ 59,  71,  77],\n",
       "         [ 68,  80,  86],\n",
       "         [ 76,  88,  94]],\n",
       " \n",
       "        [[ 97, 108, 112],\n",
       "         [108, 119, 123],\n",
       "         [123, 134, 138],\n",
       "         ...,\n",
       "         [ 64,  76,  82],\n",
       "         [ 77,  89,  95],\n",
       "         [ 88, 100, 106]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[192, 212, 229],\n",
       "         [186, 209, 225],\n",
       "         [182, 202, 219],\n",
       "         ...,\n",
       "         [155, 174, 187],\n",
       "         [153, 172, 185],\n",
       "         [152, 171, 184]],\n",
       " \n",
       "        [[198, 221, 237],\n",
       "         [196, 219, 235],\n",
       "         [195, 218, 234],\n",
       "         ...,\n",
       "         [139, 158, 171],\n",
       "         [140, 159, 172],\n",
       "         [139, 158, 171]],\n",
       " \n",
       "        [[200, 225, 241],\n",
       "         [201, 226, 242],\n",
       "         [205, 228, 244],\n",
       "         ...,\n",
       "         [129, 148, 161],\n",
       "         [133, 152, 165],\n",
       "         [131, 150, 163]]], dtype=uint8),\n",
       " array([[[ 82, 125,  98],\n",
       "         [ 81, 124,  97],\n",
       "         [ 82, 125,  98],\n",
       "         ...,\n",
       "         [ 17,  22,  20],\n",
       "         [ 17,  22,  21],\n",
       "         [ 20,  23,  21]],\n",
       " \n",
       "        [[ 76, 121,  95],\n",
       "         [ 78, 123,  97],\n",
       "         [ 79, 124,  98],\n",
       "         ...,\n",
       "         [ 15,  22,  15],\n",
       "         [ 13,  20,  15],\n",
       "         [ 20,  26,  21]],\n",
       " \n",
       "        [[ 71, 119,  91],\n",
       "         [ 74, 121,  95],\n",
       "         [ 75, 123,  97],\n",
       "         ...,\n",
       "         [ 16,  28,  16],\n",
       "         [ 18,  26,  16],\n",
       "         [ 18,  25,  18]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 24,  24,  24],\n",
       "         [ 24,  26,  26],\n",
       "         [ 23,  27,  28],\n",
       "         ...,\n",
       "         [ 39,  57,  56],\n",
       "         [ 40,  57,  54],\n",
       "         [ 42,  59,  56]],\n",
       " \n",
       "        [[ 24,  24,  24],\n",
       "         [ 21,  23,  24],\n",
       "         [ 20,  24,  25],\n",
       "         ...,\n",
       "         [ 45,  66,  64],\n",
       "         [ 48,  66,  65],\n",
       "         [ 48,  66,  65]],\n",
       " \n",
       "        [[ 26,  26,  26],\n",
       "         [ 19,  21,  22],\n",
       "         [ 18,  20,  21],\n",
       "         ...,\n",
       "         [ 54,  77,  69],\n",
       "         [ 57,  78,  70],\n",
       "         [ 57,  78,  69]]], dtype=uint8),\n",
       " array([[[ 17,  26,  35],\n",
       "         [ 43,  52,  61],\n",
       "         [ 69,  75,  82],\n",
       "         ...,\n",
       "         [ 87, 145, 167],\n",
       "         [149, 209, 231],\n",
       "         [121, 181, 203]],\n",
       " \n",
       "        [[134, 143, 152],\n",
       "         [108, 117, 126],\n",
       "         [ 79,  87,  94],\n",
       "         ...,\n",
       "         [ 72, 130, 152],\n",
       "         [122, 182, 204],\n",
       "         [ 95, 155, 177]],\n",
       " \n",
       "        [[ 28,  39,  47],\n",
       "         [ 14,  23,  32],\n",
       "         [  9,  18,  27],\n",
       "         ...,\n",
       "         [109, 167, 189],\n",
       "         [ 62, 120, 142],\n",
       "         [ 75, 133, 155]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 96, 130, 176],\n",
       "         [108, 142, 188],\n",
       "         [120, 154, 200],\n",
       "         ...,\n",
       "         [102, 131, 175],\n",
       "         [100, 129, 173],\n",
       "         [101, 130, 174]],\n",
       " \n",
       "        [[100, 135, 179],\n",
       "         [108, 143, 187],\n",
       "         [117, 152, 196],\n",
       "         ...,\n",
       "         [ 77, 102, 144],\n",
       "         [ 73,  98, 140],\n",
       "         [ 77, 101, 143]],\n",
       " \n",
       "        [[127, 162, 206],\n",
       "         [127, 162, 206],\n",
       "         [126, 161, 205],\n",
       "         ...,\n",
       "         [ 40,  65, 107],\n",
       "         [ 39,  61, 103],\n",
       "         [ 42,  64, 106]]], dtype=uint8),\n",
       " array([[[ 83,  96,  64],\n",
       "         [101, 112,  80],\n",
       "         [106, 118,  82],\n",
       "         ...,\n",
       "         [108,  61,  47],\n",
       "         [102,  57,  36],\n",
       "         [ 97,  53,  30]],\n",
       " \n",
       "        [[ 80,  97,  70],\n",
       "         [ 89, 107,  78],\n",
       "         [ 95, 112,  79],\n",
       "         ...,\n",
       "         [103,  54,  44],\n",
       "         [101,  54,  40],\n",
       "         [103,  57,  40]],\n",
       " \n",
       "        [[ 79,  92,  60],\n",
       "         [ 86, 102,  68],\n",
       "         [ 92, 111,  72],\n",
       "         ...,\n",
       "         [101,  53,  49],\n",
       "         [102,  55,  47],\n",
       "         [106,  59,  51]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[176, 170, 151],\n",
       "         [ 98,  92,  73],\n",
       "         [ 91,  84,  64],\n",
       "         ...,\n",
       "         [220, 213, 220],\n",
       "         [188, 175, 189],\n",
       "         [211, 195, 212]],\n",
       " \n",
       "        [[166, 167, 151],\n",
       "         [154, 152, 134],\n",
       "         [104,  98,  79],\n",
       "         ...,\n",
       "         [184, 170, 182],\n",
       "         [214, 201, 217],\n",
       "         [217, 203, 221]],\n",
       " \n",
       "        [[102, 106,  94],\n",
       "         [167, 166, 152],\n",
       "         [130, 122, 105],\n",
       "         ...,\n",
       "         [198, 181, 194],\n",
       "         [224, 210, 228],\n",
       "         [191, 179, 199]]], dtype=uint8),\n",
       " array([[[174, 235, 231],\n",
       "         [177, 236, 232],\n",
       "         [177, 234, 231],\n",
       "         ...,\n",
       "         [ 21,  53,  72],\n",
       "         [ 24,  54,  71],\n",
       "         [ 18,  48,  65]],\n",
       " \n",
       "        [[182, 243, 239],\n",
       "         [187, 246, 242],\n",
       "         [190, 245, 242],\n",
       "         ...,\n",
       "         [ 17,  49,  68],\n",
       "         [ 19,  49,  66],\n",
       "         [ 17,  47,  64]],\n",
       " \n",
       "        [[181, 243, 237],\n",
       "         [188, 248, 242],\n",
       "         [199, 249, 247],\n",
       "         ...,\n",
       "         [ 17,  49,  68],\n",
       "         [ 15,  47,  66],\n",
       "         [ 15,  47,  66]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 21,  43,  49],\n",
       "         [ 24,  46,  52],\n",
       "         [ 26,  45,  52],\n",
       "         ...,\n",
       "         [ 34,  66,  65],\n",
       "         [ 44,  75,  74],\n",
       "         [ 51,  84,  80]],\n",
       " \n",
       "        [[ 22,  44,  50],\n",
       "         [ 24,  46,  52],\n",
       "         [ 26,  45,  52],\n",
       "         ...,\n",
       "         [ 33,  64,  61],\n",
       "         [ 36,  69,  65],\n",
       "         [ 39,  72,  68]],\n",
       " \n",
       "        [[ 24,  46,  52],\n",
       "         [ 25,  47,  53],\n",
       "         [ 24,  46,  52],\n",
       "         ...,\n",
       "         [ 33,  66,  62],\n",
       "         [ 32,  67,  63],\n",
       "         [ 27,  65,  59]]], dtype=uint8),\n",
       " array([[[  0,  32,  25],\n",
       "         [  3,  37,  27],\n",
       "         [  7,  36,  27],\n",
       "         ...,\n",
       "         [117, 153, 139],\n",
       "         [119, 158, 143],\n",
       "         [119, 158, 143]],\n",
       " \n",
       "        [[  4,  37,  30],\n",
       "         [  5,  39,  29],\n",
       "         [  9,  39,  28],\n",
       "         ...,\n",
       "         [109, 148, 133],\n",
       "         [111, 150, 135],\n",
       "         [108, 149, 134]],\n",
       " \n",
       "        [[  3,  37,  27],\n",
       "         [  1,  35,  25],\n",
       "         [  8,  38,  27],\n",
       "         ...,\n",
       "         [102, 143, 128],\n",
       "         [102, 143, 128],\n",
       "         [ 98, 141, 126]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[115, 146, 155],\n",
       "         [122, 153, 162],\n",
       "         [ 83, 111, 118],\n",
       "         ...,\n",
       "         [130, 157, 148],\n",
       "         [119, 145, 132],\n",
       "         [ 76, 103,  87]],\n",
       " \n",
       "        [[ 87, 109, 120],\n",
       "         [104, 124, 135],\n",
       "         [ 80, 101, 109],\n",
       "         ...,\n",
       "         [120, 149, 140],\n",
       "         [131, 157, 143],\n",
       "         [102, 129, 113]],\n",
       " \n",
       "        [[ 72,  84,  96],\n",
       "         [ 88, 100, 112],\n",
       "         [ 79,  91, 101],\n",
       "         ...,\n",
       "         [114, 144, 133],\n",
       "         [141, 167, 153],\n",
       "         [126, 153, 137]]], dtype=uint8),\n",
       " array([[[242, 213, 174],\n",
       "         [242, 213, 174],\n",
       "         [241, 212, 173],\n",
       "         ...,\n",
       "         [246, 219, 182],\n",
       "         [245, 219, 182],\n",
       "         [244, 218, 181]],\n",
       " \n",
       "        [[245, 216, 177],\n",
       "         [243, 214, 175],\n",
       "         [239, 210, 171],\n",
       "         ...,\n",
       "         [250, 223, 186],\n",
       "         [246, 219, 182],\n",
       "         [240, 213, 176]],\n",
       " \n",
       "        [[244, 215, 176],\n",
       "         [241, 212, 173],\n",
       "         [238, 209, 170],\n",
       "         ...,\n",
       "         [249, 223, 183],\n",
       "         [246, 220, 180],\n",
       "         [242, 216, 176]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 22,  41,  44],\n",
       "         [ 33,  58,  60],\n",
       "         [ 33,  74,  76],\n",
       "         ...,\n",
       "         [ 74, 141, 120],\n",
       "         [ 90, 155, 139],\n",
       "         [ 91, 153, 139]],\n",
       " \n",
       "        [[ 32,  54,  52],\n",
       "         [ 33,  61,  61],\n",
       "         [ 32,  72,  71],\n",
       "         ...,\n",
       "         [ 80, 148, 125],\n",
       "         [ 95, 158, 142],\n",
       "         [ 87, 149, 135]],\n",
       " \n",
       "        [[ 57,  84,  80],\n",
       "         [ 49,  80,  77],\n",
       "         [ 30,  71,  73],\n",
       "         ...,\n",
       "         [101, 165, 143],\n",
       "         [109, 171, 153],\n",
       "         [ 91, 153, 137]]], dtype=uint8),\n",
       " array([[[243, 197,  89],\n",
       "         [242, 196,  88],\n",
       "         [242, 196,  88],\n",
       "         ...,\n",
       "         [241, 190,  96],\n",
       "         [243, 191, 101],\n",
       "         [245, 192, 105]],\n",
       " \n",
       "        [[243, 197,  89],\n",
       "         [243, 197,  89],\n",
       "         [242, 196,  88],\n",
       "         ...,\n",
       "         [241, 190,  96],\n",
       "         [243, 191, 101],\n",
       "         [245, 192, 105]],\n",
       " \n",
       "        [[243, 197,  89],\n",
       "         [243, 197,  89],\n",
       "         [243, 197,  89],\n",
       "         ...,\n",
       "         [241, 190,  96],\n",
       "         [243, 191, 101],\n",
       "         [245, 192, 105]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 50,  87,  71],\n",
       "         [ 49,  85,  71],\n",
       "         [ 49,  81,  70],\n",
       "         ...,\n",
       "         [ 71,  97,  97],\n",
       "         [ 78, 100,  98],\n",
       "         [ 81, 102, 100]],\n",
       " \n",
       "        [[ 51,  88,  72],\n",
       "         [ 56,  91,  77],\n",
       "         [ 60,  90,  79],\n",
       "         ...,\n",
       "         [ 76, 101, 103],\n",
       "         [ 84, 105, 106],\n",
       "         [ 88, 109, 107]],\n",
       " \n",
       "        [[ 49,  84,  70],\n",
       "         [ 59,  94,  80],\n",
       "         [ 70, 100,  89],\n",
       "         ...,\n",
       "         [ 80, 105, 107],\n",
       "         [ 87, 111, 111],\n",
       "         [ 92, 113, 114]]], dtype=uint8),\n",
       " array([[[44, 42, 42],\n",
       "         [48, 44, 43],\n",
       "         [49, 45, 44],\n",
       "         ...,\n",
       "         [29, 29, 29],\n",
       "         [28, 28, 28],\n",
       "         [30, 28, 28]],\n",
       " \n",
       "        [[46, 42, 41],\n",
       "         [47, 43, 42],\n",
       "         [48, 43, 44],\n",
       "         ...,\n",
       "         [29, 29, 29],\n",
       "         [28, 28, 28],\n",
       "         [32, 30, 30]],\n",
       " \n",
       "        [[48, 43, 44],\n",
       "         [50, 45, 46],\n",
       "         [48, 43, 44],\n",
       "         ...,\n",
       "         [29, 29, 29],\n",
       "         [30, 30, 30],\n",
       "         [33, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[41, 39, 39],\n",
       "         [40, 38, 38],\n",
       "         [40, 38, 37],\n",
       "         ...,\n",
       "         [31, 29, 29],\n",
       "         [30, 28, 28],\n",
       "         [30, 28, 28]],\n",
       " \n",
       "        [[40, 38, 38],\n",
       "         [39, 37, 37],\n",
       "         [39, 37, 36],\n",
       "         ...,\n",
       "         [28, 28, 28],\n",
       "         [28, 28, 28],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        [[41, 39, 39],\n",
       "         [39, 37, 37],\n",
       "         [40, 38, 37],\n",
       "         ...,\n",
       "         [27, 27, 27],\n",
       "         [26, 26, 26],\n",
       "         [28, 28, 28]]], dtype=uint8),\n",
       " array([[[104, 100,  82],\n",
       "         [101,  99,  81],\n",
       "         [104,  99,  84],\n",
       "         ...,\n",
       "         [ 67,  71,  59],\n",
       "         [ 66,  70,  58],\n",
       "         [ 68,  72,  60]],\n",
       " \n",
       "        [[101,  99,  81],\n",
       "         [101,  99,  81],\n",
       "         [103,  98,  83],\n",
       "         ...,\n",
       "         [ 67,  71,  59],\n",
       "         [ 68,  72,  60],\n",
       "         [ 66,  70,  58]],\n",
       " \n",
       "        [[ 99,  96,  81],\n",
       "         [ 98,  98,  82],\n",
       "         [100,  97,  82],\n",
       "         ...,\n",
       "         [ 67,  71,  59],\n",
       "         [ 67,  71,  59],\n",
       "         [ 66,  70,  58]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 92, 124, 153],\n",
       "         [ 96, 129, 155],\n",
       "         [113, 144, 169],\n",
       "         ...,\n",
       "         [  8,  81,  71],\n",
       "         [  9,  80,  70],\n",
       "         [  8,  81,  71]],\n",
       " \n",
       "        [[ 90, 122, 151],\n",
       "         [ 94, 124, 153],\n",
       "         [107, 137, 162],\n",
       "         ...,\n",
       "         [  7,  80,  70],\n",
       "         [ 10,  81,  71],\n",
       "         [  9,  79,  72]],\n",
       " \n",
       "        [[ 88, 116, 146],\n",
       "         [ 92, 124, 153],\n",
       "         [107, 137, 162],\n",
       "         ...,\n",
       "         [  7,  81,  69],\n",
       "         [ 10,  82,  70],\n",
       "         [ 10,  83,  73]]], dtype=uint8),\n",
       " array([[[199, 201, 202],\n",
       "         [200, 202, 203],\n",
       "         [201, 203, 204],\n",
       "         ...,\n",
       "         [229, 218, 220],\n",
       "         [228, 217, 219],\n",
       "         [227, 216, 218]],\n",
       " \n",
       "        [[200, 202, 203],\n",
       "         [201, 203, 204],\n",
       "         [202, 204, 205],\n",
       "         ...,\n",
       "         [229, 218, 220],\n",
       "         [228, 217, 219],\n",
       "         [228, 217, 219]],\n",
       " \n",
       "        [[201, 203, 204],\n",
       "         [202, 204, 205],\n",
       "         [203, 205, 206],\n",
       "         ...,\n",
       "         [227, 219, 220],\n",
       "         [228, 217, 219],\n",
       "         [228, 217, 219]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[190, 186, 185],\n",
       "         [191, 187, 186],\n",
       "         [191, 187, 186],\n",
       "         ...,\n",
       "         [207, 198, 195],\n",
       "         [206, 197, 194],\n",
       "         [206, 197, 194]],\n",
       " \n",
       "        [[190, 186, 185],\n",
       "         [191, 187, 186],\n",
       "         [191, 187, 186],\n",
       "         ...,\n",
       "         [207, 198, 195],\n",
       "         [208, 196, 194],\n",
       "         [207, 198, 195]],\n",
       " \n",
       "        [[189, 185, 184],\n",
       "         [190, 186, 185],\n",
       "         [191, 187, 186],\n",
       "         ...,\n",
       "         [210, 198, 196],\n",
       "         [209, 196, 194],\n",
       "         [207, 195, 193]]], dtype=uint8),\n",
       " array([[[ 75, 118, 169],\n",
       "         [ 75, 118, 169],\n",
       "         [ 78, 125, 176],\n",
       "         ...,\n",
       "         [114, 158, 221],\n",
       "         [111, 158, 220],\n",
       "         [115, 162, 224]],\n",
       " \n",
       "        [[ 72, 117, 168],\n",
       "         [ 70, 113, 164],\n",
       "         [ 72, 119, 171],\n",
       "         ...,\n",
       "         [110, 157, 219],\n",
       "         [113, 160, 222],\n",
       "         [116, 160, 223]],\n",
       " \n",
       "        [[ 68, 111, 162],\n",
       "         [ 65, 108, 157],\n",
       "         [ 63, 110, 162],\n",
       "         ...,\n",
       "         [112, 156, 219],\n",
       "         [115, 162, 224],\n",
       "         [113, 160, 222]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 15,  17,  27],\n",
       "         [ 14,  17,  25],\n",
       "         [ 14,  17,  25],\n",
       "         ...,\n",
       "         [ 91, 107, 136],\n",
       "         [ 81,  95, 123],\n",
       "         [ 71,  85, 113]],\n",
       " \n",
       "        [[ 14,  21,  30],\n",
       "         [ 13,  20,  29],\n",
       "         [ 14,  19,  28],\n",
       "         ...,\n",
       "         [ 99, 123, 153],\n",
       "         [ 94, 115, 146],\n",
       "         [ 89, 110, 141]],\n",
       " \n",
       "        [[ 16,  25,  35],\n",
       "         [ 17,  25,  38],\n",
       "         [ 17,  23,  34],\n",
       "         ...,\n",
       "         [ 74,  95, 116],\n",
       "         [ 78,  96, 119],\n",
       "         [ 71,  92, 114]]], dtype=uint8),\n",
       " array([[[ 47, 139, 110],\n",
       "         [ 25, 120,  99],\n",
       "         [ 21, 122, 100],\n",
       "         ...,\n",
       "         [201, 240, 242],\n",
       "         [199, 238, 240],\n",
       "         [191, 235, 236]],\n",
       " \n",
       "        [[ 80, 154, 124],\n",
       "         [ 62, 147, 125],\n",
       "         [ 59, 149, 126],\n",
       "         ...,\n",
       "         [198, 239, 241],\n",
       "         [195, 236, 238],\n",
       "         [192, 233, 235]],\n",
       " \n",
       "        [[124, 181, 160],\n",
       "         [131, 200, 185],\n",
       "         [125, 177, 170],\n",
       "         ...,\n",
       "         [196, 237, 239],\n",
       "         [191, 235, 236],\n",
       "         [183, 229, 230]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[114,  96, 103],\n",
       "         [102,  88,  70],\n",
       "         [153, 146, 121],\n",
       "         ...,\n",
       "         [190, 166, 174],\n",
       "         [124, 111, 127],\n",
       "         [157, 134, 156]],\n",
       " \n",
       "        [[169, 158, 144],\n",
       "         [163, 146, 133],\n",
       "         [115, 106,  93],\n",
       "         ...,\n",
       "         [103,  96, 111],\n",
       "         [106, 101, 116],\n",
       "         [ 92,  86,  97]],\n",
       " \n",
       "        [[107,  96,  92],\n",
       "         [132, 121, 117],\n",
       "         [137, 125, 123],\n",
       "         ...,\n",
       "         [ 49,  43,  54],\n",
       "         [ 27,  23,  34],\n",
       "         [ 46,  39,  54]]], dtype=uint8),\n",
       " array([[[31, 40, 53],\n",
       "         [31, 40, 53],\n",
       "         [30, 40, 50],\n",
       "         ...,\n",
       "         [25, 37, 41],\n",
       "         [24, 36, 40],\n",
       "         [25, 37, 41]],\n",
       " \n",
       "        [[31, 40, 53],\n",
       "         [30, 39, 52],\n",
       "         [29, 39, 49],\n",
       "         ...,\n",
       "         [26, 38, 42],\n",
       "         [25, 37, 41],\n",
       "         [25, 37, 41]],\n",
       " \n",
       "        [[31, 40, 53],\n",
       "         [30, 40, 50],\n",
       "         [29, 39, 49],\n",
       "         ...,\n",
       "         [25, 37, 41],\n",
       "         [27, 39, 43],\n",
       "         [25, 37, 41]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[75, 87, 93],\n",
       "         [74, 86, 92],\n",
       "         [76, 88, 94],\n",
       "         ...,\n",
       "         [59, 83, 89],\n",
       "         [61, 85, 91],\n",
       "         [62, 86, 92]],\n",
       " \n",
       "        [[77, 89, 95],\n",
       "         [78, 90, 96],\n",
       "         [79, 91, 97],\n",
       "         ...,\n",
       "         [54, 76, 82],\n",
       "         [56, 78, 84],\n",
       "         [58, 80, 86]],\n",
       " \n",
       "        [[79, 91, 97],\n",
       "         [78, 90, 96],\n",
       "         [80, 92, 98],\n",
       "         ...,\n",
       "         [51, 70, 77],\n",
       "         [52, 71, 78],\n",
       "         [53, 72, 79]]], dtype=uint8),\n",
       " array([[[217, 185, 162],\n",
       "         [218, 185, 166],\n",
       "         [221, 183, 178],\n",
       "         ...,\n",
       "         [ 50,  81,  96],\n",
       "         [ 57,  78,  93],\n",
       "         [ 52,  70,  87]],\n",
       " \n",
       "        [[218, 182, 164],\n",
       "         [227, 188, 174],\n",
       "         [217, 186, 183],\n",
       "         ...,\n",
       "         [ 59,  85, 102],\n",
       "         [ 54,  78,  96],\n",
       "         [ 49,  69,  87]],\n",
       " \n",
       "        [[217, 189, 158],\n",
       "         [218, 185, 166],\n",
       "         [213, 183, 178],\n",
       "         ...,\n",
       "         [ 57,  81, 101],\n",
       "         [ 48,  74,  91],\n",
       "         [ 51,  69,  86]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[132, 158, 228],\n",
       "         [126, 158, 229],\n",
       "         [120, 161, 230],\n",
       "         ...,\n",
       "         [ 22,  34,  38],\n",
       "         [ 23,  36,  38],\n",
       "         [ 22,  34,  38]],\n",
       " \n",
       "        [[121, 160, 228],\n",
       "         [119, 158, 233],\n",
       "         [124, 165, 234],\n",
       "         ...,\n",
       "         [ 16,  33,  36],\n",
       "         [ 23,  38,  40],\n",
       "         [ 25,  39,  45]],\n",
       " \n",
       "        [[115, 150, 223],\n",
       "         [115, 153, 235],\n",
       "         [115, 155, 230],\n",
       "         ...,\n",
       "         [ 21,  36,  45],\n",
       "         [ 19,  36,  39],\n",
       "         [ 17,  36,  39]]], dtype=uint8),\n",
       " array([[[ 29,  40,  37],\n",
       "         [ 30,  41,  38],\n",
       "         [ 36,  45,  42],\n",
       "         ...,\n",
       "         [ 35,  36,  32],\n",
       "         [ 36,  37,  33],\n",
       "         [ 37,  38,  34]],\n",
       " \n",
       "        [[ 33,  44,  41],\n",
       "         [ 29,  40,  37],\n",
       "         [ 36,  45,  42],\n",
       "         ...,\n",
       "         [ 37,  38,  34],\n",
       "         [ 37,  38,  34],\n",
       "         [ 38,  39,  35]],\n",
       " \n",
       "        [[ 31,  42,  39],\n",
       "         [ 28,  39,  36],\n",
       "         [ 37,  46,  43],\n",
       "         ...,\n",
       "         [ 37,  38,  34],\n",
       "         [ 36,  37,  33],\n",
       "         [ 37,  38,  34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[218, 217, 213],\n",
       "         [214, 216, 210],\n",
       "         [214, 215, 211],\n",
       "         ...,\n",
       "         [ 23,  47,  99],\n",
       "         [ 20,  44,  96],\n",
       "         [ 20,  44,  96]],\n",
       " \n",
       "        [[221, 221, 215],\n",
       "         [214, 216, 210],\n",
       "         [208, 212, 206],\n",
       "         ...,\n",
       "         [ 22,  49,  99],\n",
       "         [ 20,  45,  95],\n",
       "         [ 23,  48,  98]],\n",
       " \n",
       "        [[212, 213, 209],\n",
       "         [212, 213, 209],\n",
       "         [205, 209, 204],\n",
       "         ...,\n",
       "         [ 18,  44,  91],\n",
       "         [ 20,  44,  90],\n",
       "         [ 22,  47,  91]]], dtype=uint8),\n",
       " array([[[ 44,  66,  71],\n",
       "         [ 42,  72,  77],\n",
       "         [ 47,  79,  85],\n",
       "         ...,\n",
       "         [  8,  19,  16],\n",
       "         [ 10,  21,  19],\n",
       "         [ 12,  20,  19]],\n",
       " \n",
       "        [[ 49,  83,  82],\n",
       "         [ 46,  84,  88],\n",
       "         [ 52,  89,  97],\n",
       "         ...,\n",
       "         [  9,  20,  17],\n",
       "         [ 13,  22,  19],\n",
       "         [ 12,  21,  18]],\n",
       " \n",
       "        [[ 56,  98,  97],\n",
       "         [ 61, 106, 109],\n",
       "         [ 62, 107, 118],\n",
       "         ...,\n",
       "         [  8,  19,  16],\n",
       "         [  9,  20,  17],\n",
       "         [  9,  19,  19]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 36,  65,  69],\n",
       "         [ 31,  57,  63],\n",
       "         [ 26,  51,  61],\n",
       "         ...,\n",
       "         [ 11,  23,  27],\n",
       "         [ 16,  30,  29],\n",
       "         [ 21,  36,  32]],\n",
       " \n",
       "        [[ 16,  32,  39],\n",
       "         [ 23,  41,  48],\n",
       "         [ 26,  45,  58],\n",
       "         ...,\n",
       "         [ 10,  20,  20],\n",
       "         [ 15,  22,  25],\n",
       "         [ 20,  29,  32]],\n",
       " \n",
       "        [[ 18,  30,  34],\n",
       "         [ 33,  51,  50],\n",
       "         [ 28,  47,  52],\n",
       "         ...,\n",
       "         [ 12,  21,  25],\n",
       "         [ 17,  18,  28],\n",
       "         [ 17,  26,  35]]], dtype=uint8),\n",
       " array([[[ 41,  74,  70],\n",
       "         [ 30,  63,  59],\n",
       "         [ 16,  48,  47],\n",
       "         ...,\n",
       "         [ 13,  23,  30],\n",
       "         [ 20,  28,  35],\n",
       "         [ 18,  25,  34]],\n",
       " \n",
       "        [[ 38,  69,  70],\n",
       "         [ 26,  57,  58],\n",
       "         [ 11,  44,  40],\n",
       "         ...,\n",
       "         [ 13,  26,  28],\n",
       "         [ 16,  27,  31],\n",
       "         [ 16,  27,  31]],\n",
       " \n",
       "        [[ 31,  66,  70],\n",
       "         [ 22,  55,  58],\n",
       "         [  8,  43,  39],\n",
       "         ...,\n",
       "         [ 18,  35,  32],\n",
       "         [ 16,  32,  31],\n",
       "         [ 17,  33,  32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 32,  59,  63],\n",
       "         [ 44,  73,  78],\n",
       "         [ 66,  99, 108],\n",
       "         ...,\n",
       "         [ 26,  45,  48],\n",
       "         [ 34,  55,  57],\n",
       "         [ 37,  59,  64]],\n",
       " \n",
       "        [[ 42,  77,  81],\n",
       "         [ 55,  91,  99],\n",
       "         [ 79, 119, 131],\n",
       "         ...,\n",
       "         [ 29,  48,  45],\n",
       "         [ 31,  53,  51],\n",
       "         [ 33,  55,  53]],\n",
       " \n",
       "        [[ 54,  92,  97],\n",
       "         [ 65, 104, 113],\n",
       "         [ 87, 131, 144],\n",
       "         ...,\n",
       "         [ 31,  51,  46],\n",
       "         [ 32,  53,  50],\n",
       "         [ 31,  54,  50]]], dtype=uint8),\n",
       " array([[[  8,   6,   6],\n",
       "         [  8,   6,   6],\n",
       "         [  7,   5,   5],\n",
       "         ...,\n",
       "         [230, 206, 176],\n",
       "         [228, 205, 173],\n",
       "         [226, 203, 171]],\n",
       " \n",
       "        [[  9,   7,   7],\n",
       "         [  9,   7,   7],\n",
       "         [  9,   7,   7],\n",
       "         ...,\n",
       "         [199, 179, 138],\n",
       "         [193, 174, 131],\n",
       "         [190, 171, 128]],\n",
       " \n",
       "        [[ 11,   9,   9],\n",
       "         [ 10,   8,   8],\n",
       "         [  9,   7,   7],\n",
       "         ...,\n",
       "         [155, 140,  78],\n",
       "         [149, 134,  71],\n",
       "         [145, 130,  67]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  8,   9,  23],\n",
       "         [  7,   8,  22],\n",
       "         [  6,   7,  21],\n",
       "         ...,\n",
       "         [123, 103, 115],\n",
       "         [121, 101, 113],\n",
       "         [119,  99, 111]],\n",
       " \n",
       "        [[  8,   9,  23],\n",
       "         [  7,   8,  22],\n",
       "         [  6,   7,  21],\n",
       "         ...,\n",
       "         [125, 105, 118],\n",
       "         [123, 103, 116],\n",
       "         [122, 102, 115]],\n",
       " \n",
       "        [[  7,   8,  22],\n",
       "         [  7,   8,  22],\n",
       "         [  6,   7,  21],\n",
       "         ...,\n",
       "         [126, 106, 119],\n",
       "         [124, 104, 117],\n",
       "         [123, 103, 116]]], dtype=uint8),\n",
       " array([[[120, 135, 144],\n",
       "         [119, 134, 143],\n",
       "         [119, 135, 142],\n",
       "         ...,\n",
       "         [157, 167, 191],\n",
       "         [153, 164, 186],\n",
       "         [154, 165, 187]],\n",
       " \n",
       "        [[124, 139, 148],\n",
       "         [125, 140, 149],\n",
       "         [125, 141, 148],\n",
       "         ...,\n",
       "         [153, 163, 187],\n",
       "         [147, 158, 180],\n",
       "         [154, 165, 187]],\n",
       " \n",
       "        [[120, 135, 144],\n",
       "         [123, 138, 147],\n",
       "         [122, 137, 146],\n",
       "         ...,\n",
       "         [152, 163, 185],\n",
       "         [151, 162, 184],\n",
       "         [153, 164, 186]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[152, 168, 184],\n",
       "         [158, 174, 190],\n",
       "         [165, 180, 196],\n",
       "         ...,\n",
       "         [166, 184, 195],\n",
       "         [172, 188, 200],\n",
       "         [171, 187, 199]],\n",
       " \n",
       "        [[150, 166, 182],\n",
       "         [153, 169, 185],\n",
       "         [161, 176, 192],\n",
       "         ...,\n",
       "         [173, 191, 202],\n",
       "         [163, 179, 191],\n",
       "         [173, 189, 201]],\n",
       " \n",
       "        [[149, 168, 183],\n",
       "         [147, 166, 181],\n",
       "         [157, 173, 189],\n",
       "         ...,\n",
       "         [165, 183, 194],\n",
       "         [167, 183, 195],\n",
       "         [173, 189, 201]]], dtype=uint8),\n",
       " array([[[178, 210, 229],\n",
       "         [177, 209, 228],\n",
       "         [177, 209, 228],\n",
       "         ...,\n",
       "         [133, 174, 213],\n",
       "         [126, 166, 208],\n",
       "         [122, 162, 204]],\n",
       " \n",
       "        [[177, 209, 228],\n",
       "         [177, 209, 228],\n",
       "         [177, 209, 228],\n",
       "         ...,\n",
       "         [134, 175, 214],\n",
       "         [128, 168, 210],\n",
       "         [123, 163, 205]],\n",
       " \n",
       "        [[177, 209, 228],\n",
       "         [177, 209, 228],\n",
       "         [176, 208, 227],\n",
       "         ...,\n",
       "         [136, 177, 216],\n",
       "         [129, 169, 211],\n",
       "         [125, 165, 207]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 16,  43,  64],\n",
       "         [ 15,  42,  63],\n",
       "         [ 14,  41,  62],\n",
       "         ...,\n",
       "         [149, 180, 213],\n",
       "         [150, 182, 217],\n",
       "         [150, 182, 217]],\n",
       " \n",
       "        [[ 14,  41,  62],\n",
       "         [ 14,  41,  62],\n",
       "         [ 14,  41,  62],\n",
       "         ...,\n",
       "         [147, 178, 211],\n",
       "         [152, 184, 219],\n",
       "         [155, 187, 222]],\n",
       " \n",
       "        [[ 12,  39,  60],\n",
       "         [ 13,  40,  61],\n",
       "         [ 14,  41,  62],\n",
       "         ...,\n",
       "         [144, 175, 208],\n",
       "         [153, 185, 220],\n",
       "         [159, 191, 226]]], dtype=uint8),\n",
       " array([[[108, 117, 127],\n",
       "         [ 95,  96, 106],\n",
       "         [ 75,  74,  83],\n",
       "         ...,\n",
       "         [ 34,  32,  98],\n",
       "         [ 33,  33,  97],\n",
       "         [ 35,  30,  99]],\n",
       " \n",
       "        [[106, 112, 119],\n",
       "         [ 93,  99, 106],\n",
       "         [ 77,  79,  89],\n",
       "         ...,\n",
       "         [ 34,  33, 101],\n",
       "         [ 32,  30, 100],\n",
       "         [ 35,  32, 101]],\n",
       " \n",
       "        [[101, 104, 112],\n",
       "         [ 94, 100, 111],\n",
       "         [ 85,  90,  99],\n",
       "         ...,\n",
       "         [ 35,  34,  98],\n",
       "         [ 36,  32, 103],\n",
       "         [ 37,  34, 103]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[112, 139, 130],\n",
       "         [109, 136, 127],\n",
       "         [102, 128, 128],\n",
       "         ...,\n",
       "         [114, 114, 130],\n",
       "         [108, 112, 130],\n",
       "         [ 97, 101, 112]],\n",
       " \n",
       "        [[113, 133, 128],\n",
       "         [ 95, 118, 110],\n",
       "         [ 96, 118, 116],\n",
       "         ...,\n",
       "         [118, 123, 138],\n",
       "         [124, 134, 152],\n",
       "         [118, 125, 142]],\n",
       " \n",
       "        [[ 86, 100,  99],\n",
       "         [102, 121, 118],\n",
       "         [101, 125, 123],\n",
       "         ...,\n",
       "         [122, 134, 146],\n",
       "         [143, 155, 167],\n",
       "         [128, 141, 149]]], dtype=uint8),\n",
       " array([[[124, 126, 134],\n",
       "         [124, 127, 135],\n",
       "         [122, 128, 135],\n",
       "         ...,\n",
       "         [ 24,  24,  64],\n",
       "         [ 22,  24,  59],\n",
       "         [ 20,  21,  55]],\n",
       " \n",
       "        [[120, 127, 130],\n",
       "         [122, 129, 132],\n",
       "         [118, 129, 133],\n",
       "         ...,\n",
       "         [ 27,  29,  70],\n",
       "         [ 27,  28,  62],\n",
       "         [ 23,  22,  54]],\n",
       " \n",
       "        [[114, 128, 126],\n",
       "         [118, 132, 130],\n",
       "         [115, 131, 130],\n",
       "         ...,\n",
       "         [ 24,  34,  81],\n",
       "         [ 23,  32,  70],\n",
       "         [ 15,  23,  60]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 45,  72,  98],\n",
       "         [ 49,  73, 101],\n",
       "         [ 52,  76, 104],\n",
       "         ...,\n",
       "         [148, 143, 144],\n",
       "         [144, 142, 142],\n",
       "         [140, 140, 140]],\n",
       " \n",
       "        [[ 47,  68, 100],\n",
       "         [ 52,  72, 103],\n",
       "         [ 55,  71, 100],\n",
       "         ...,\n",
       "         [148, 143, 144],\n",
       "         [146, 143, 145],\n",
       "         [143, 142, 144]],\n",
       " \n",
       "        [[ 41,  60,  97],\n",
       "         [ 51,  68, 101],\n",
       "         [ 56,  68,  96],\n",
       "         ...,\n",
       "         [144, 139, 141],\n",
       "         [146, 143, 145],\n",
       "         [142, 141, 145]]], dtype=uint8),\n",
       " array([[[ 57,  56,  52],\n",
       "         [ 44,  43,  39],\n",
       "         [ 32,  29,  25],\n",
       "         ...,\n",
       "         [ 96, 157, 153],\n",
       "         [ 95, 159, 154],\n",
       "         [ 93, 159, 154]],\n",
       " \n",
       "        [[ 39,  45,  40],\n",
       "         [ 44,  50,  45],\n",
       "         [ 49,  55,  50],\n",
       "         ...,\n",
       "         [ 94, 155, 151],\n",
       "         [ 92, 156, 151],\n",
       "         [ 90, 156, 151]],\n",
       " \n",
       "        [[ 26,  47,  39],\n",
       "         [ 50,  71,  63],\n",
       "         [ 73,  91,  84],\n",
       "         ...,\n",
       "         [ 94, 154, 148],\n",
       "         [ 92, 154, 148],\n",
       "         [ 89, 153, 147]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 62,  57,  66],\n",
       "         [ 67,  65,  71],\n",
       "         [ 77,  74,  83],\n",
       "         ...,\n",
       "         [ 42,  41,  51],\n",
       "         [ 45,  44,  54],\n",
       "         [ 45,  44,  54]],\n",
       " \n",
       "        [[ 61,  56,  65],\n",
       "         [ 64,  59,  68],\n",
       "         [ 68,  63,  72],\n",
       "         ...,\n",
       "         [ 41,  40,  50],\n",
       "         [ 44,  43,  53],\n",
       "         [ 43,  42,  52]],\n",
       " \n",
       "        [[ 61,  53,  64],\n",
       "         [ 60,  52,  63],\n",
       "         [ 57,  49,  60],\n",
       "         ...,\n",
       "         [ 41,  40,  50],\n",
       "         [ 43,  42,  52],\n",
       "         [ 42,  41,  51]]], dtype=uint8),\n",
       " array([[[ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 1,  1,  1]],\n",
       " \n",
       "        [[ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 1,  1,  1]],\n",
       " \n",
       "        [[ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 1,  1,  1],\n",
       "         [ 0,  0,  0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [19, 24, 27],\n",
       "         [20, 23, 28],\n",
       "         [23, 26, 31]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         ...,\n",
       "         [19, 22, 26],\n",
       "         [19, 22, 27],\n",
       "         [20, 23, 28]],\n",
       " \n",
       "        [[ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         ...,\n",
       "         [21, 24, 28],\n",
       "         [19, 22, 26],\n",
       "         [19, 22, 26]]], dtype=uint8),\n",
       " array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[107, 107, 107],\n",
       "         [107, 107, 107],\n",
       "         [105, 105, 105],\n",
       "         ...,\n",
       "         [104, 104, 104],\n",
       "         [103, 103, 103],\n",
       "         [103, 103, 103]],\n",
       " \n",
       "        [[106, 106, 106],\n",
       "         [105, 105, 105],\n",
       "         [104, 104, 104],\n",
       "         ...,\n",
       "         [103, 103, 103],\n",
       "         [102, 102, 102],\n",
       "         [102, 102, 102]],\n",
       " \n",
       "        [[105, 105, 105],\n",
       "         [104, 104, 104],\n",
       "         [103, 103, 103],\n",
       "         ...,\n",
       "         [102, 102, 102],\n",
       "         [101, 101, 101],\n",
       "         [101, 101, 101]]], dtype=uint8),\n",
       " array([[[192, 178, 172],\n",
       "         [206, 181, 177],\n",
       "         [243, 225, 218],\n",
       "         ...,\n",
       "         [254, 242, 230],\n",
       "         [252, 242, 232],\n",
       "         [254, 241, 233]],\n",
       " \n",
       "        [[ 97,  82,  73],\n",
       "         [137, 115, 104],\n",
       "         [153, 134, 126],\n",
       "         ...,\n",
       "         [254, 242, 230],\n",
       "         [252, 242, 232],\n",
       "         [254, 241, 233]],\n",
       " \n",
       "        [[162, 143, 128],\n",
       "         [224, 210, 188],\n",
       "         [135, 113, 102],\n",
       "         ...,\n",
       "         [252, 242, 232],\n",
       "         [252, 242, 232],\n",
       "         [254, 241, 233]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 83, 168, 164],\n",
       "         [ 81, 171, 166],\n",
       "         [ 86, 170, 168],\n",
       "         ...,\n",
       "         [ 71, 173, 161],\n",
       "         [ 74, 172, 160],\n",
       "         [ 72, 170, 158]],\n",
       " \n",
       "        [[ 86, 167, 164],\n",
       "         [ 84, 169, 165],\n",
       "         [ 85, 170, 166],\n",
       "         ...,\n",
       "         [ 69, 174, 161],\n",
       "         [ 71, 173, 161],\n",
       "         [ 72, 172, 160]],\n",
       " \n",
       "        [[ 90, 167, 164],\n",
       "         [ 85, 169, 165],\n",
       "         [ 84, 168, 164],\n",
       "         ...,\n",
       "         [ 67, 173, 160],\n",
       "         [ 68, 173, 160],\n",
       "         [ 70, 170, 158]]], dtype=uint8),\n",
       " array([[[217, 157,  97],\n",
       "         [216, 156,  96],\n",
       "         [219, 158,  96],\n",
       "         ...,\n",
       "         [200, 128,  74],\n",
       "         [201, 129,  75],\n",
       "         [202, 130,  76]],\n",
       " \n",
       "        [[218, 158,  98],\n",
       "         [218, 158,  98],\n",
       "         [220, 159,  97],\n",
       "         ...,\n",
       "         [201, 129,  75],\n",
       "         [202, 130,  76],\n",
       "         [202, 130,  76]],\n",
       " \n",
       "        [[218, 158,  98],\n",
       "         [217, 157,  97],\n",
       "         [220, 159,  97],\n",
       "         ...,\n",
       "         [202, 131,  74],\n",
       "         [202, 131,  74],\n",
       "         [201, 130,  73]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[109, 138, 153],\n",
       "         [106, 135, 150],\n",
       "         [104, 135, 150],\n",
       "         ...,\n",
       "         [ 56,  45,  31],\n",
       "         [ 58,  48,  31],\n",
       "         [ 60,  50,  33]],\n",
       " \n",
       "        [[114, 143, 157],\n",
       "         [108, 137, 151],\n",
       "         [114, 143, 157],\n",
       "         ...,\n",
       "         [ 55,  44,  30],\n",
       "         [ 58,  48,  31],\n",
       "         [ 60,  50,  33]],\n",
       " \n",
       "        [[102, 131, 145],\n",
       "         [105, 134, 148],\n",
       "         [ 98, 127, 141],\n",
       "         ...,\n",
       "         [ 55,  44,  30],\n",
       "         [ 57,  47,  30],\n",
       "         [ 60,  50,  33]]], dtype=uint8),\n",
       " array([[[ 41, 106,  90],\n",
       "         [ 51, 116, 100],\n",
       "         [ 65, 131, 112],\n",
       "         ...,\n",
       "         [ 87, 128,  96],\n",
       "         [ 86, 127,  95],\n",
       "         [ 86, 127,  95]],\n",
       " \n",
       "        [[ 36, 105,  85],\n",
       "         [ 44, 113,  93],\n",
       "         [ 59, 126, 105],\n",
       "         ...,\n",
       "         [ 85, 126,  94],\n",
       "         [ 85, 126,  94],\n",
       "         [ 85, 126,  94]],\n",
       " \n",
       "        [[ 35, 107,  85],\n",
       "         [ 40, 112,  90],\n",
       "         [ 52, 122,  99],\n",
       "         ...,\n",
       "         [ 86, 125,  93],\n",
       "         [ 86, 125,  93],\n",
       "         [ 87, 126,  94]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[104, 114, 121],\n",
       "         [111, 121, 128],\n",
       "         [114, 126, 130],\n",
       "         ...,\n",
       "         [ 77,  94,  80],\n",
       "         [ 65,  82,  69],\n",
       "         [ 60,  74,  62]],\n",
       " \n",
       "        [[ 89,  99, 106],\n",
       "         [ 96, 106, 113],\n",
       "         [103, 115, 119],\n",
       "         ...,\n",
       "         [ 87, 104,  91],\n",
       "         [ 79,  88,  78],\n",
       "         [ 68,  75,  68]],\n",
       " \n",
       "        [[ 86,  96, 103],\n",
       "         [ 89,  99, 106],\n",
       "         [ 92, 103, 107],\n",
       "         ...,\n",
       "         [100, 116, 105],\n",
       "         [ 90,  96,  91],\n",
       "         [ 77,  78,  76]]], dtype=uint8),\n",
       " array([[[ 26,  52,  64],\n",
       "         [ 22,  48,  60],\n",
       "         [ 16,  42,  56],\n",
       "         ...,\n",
       "         [ 28,  50,  48],\n",
       "         [ 28,  49,  50],\n",
       "         [ 25,  46,  47]],\n",
       " \n",
       "        [[ 25,  51,  63],\n",
       "         [ 21,  47,  59],\n",
       "         [ 14,  40,  54],\n",
       "         ...,\n",
       "         [ 27,  49,  47],\n",
       "         [ 27,  48,  49],\n",
       "         [ 24,  45,  46]],\n",
       " \n",
       "        [[ 27,  54,  64],\n",
       "         [ 21,  48,  58],\n",
       "         [ 14,  40,  52],\n",
       "         ...,\n",
       "         [ 26,  48,  46],\n",
       "         [ 26,  47,  48],\n",
       "         [ 23,  44,  45]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[117, 169, 209],\n",
       "         [109, 162, 199],\n",
       "         [103, 157, 192],\n",
       "         ...,\n",
       "         [ 51, 113, 137],\n",
       "         [ 43, 107, 131],\n",
       "         [ 38, 102, 126]],\n",
       " \n",
       "        [[129, 181, 221],\n",
       "         [113, 165, 205],\n",
       "         [ 98, 153, 190],\n",
       "         ...,\n",
       "         [ 54, 117, 138],\n",
       "         [ 44, 109, 130],\n",
       "         [ 37, 102, 123]],\n",
       " \n",
       "        [[138, 190, 230],\n",
       "         [119, 171, 211],\n",
       "         [101, 156, 193],\n",
       "         ...,\n",
       "         [ 55, 118, 138],\n",
       "         [ 45, 111, 130],\n",
       "         [ 39, 105, 124]]], dtype=uint8),\n",
       " array([[[168, 177, 204],\n",
       "         [195, 205, 229],\n",
       "         [167, 174, 199],\n",
       "         ...,\n",
       "         [ 76, 107,  98],\n",
       "         [ 86, 120, 110],\n",
       "         [ 97, 131, 121]],\n",
       " \n",
       "        [[177, 186, 213],\n",
       "         [197, 207, 231],\n",
       "         [171, 178, 203],\n",
       "         ...,\n",
       "         [ 75, 106,  97],\n",
       "         [ 76, 107,  98],\n",
       "         [ 77, 111, 101]],\n",
       " \n",
       "        [[184, 193, 220],\n",
       "         [200, 210, 234],\n",
       "         [176, 183, 208],\n",
       "         ...,\n",
       "         [ 86, 117, 108],\n",
       "         [ 80, 111, 102],\n",
       "         [ 75, 106,  97]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 65,  53,  53],\n",
       "         [ 65,  53,  53],\n",
       "         [ 65,  53,  53],\n",
       "         ...,\n",
       "         [ 29,  36,  31],\n",
       "         [ 29,  36,  31],\n",
       "         [ 29,  36,  31]],\n",
       " \n",
       "        [[ 62,  50,  50],\n",
       "         [ 63,  51,  51],\n",
       "         [ 63,  51,  51],\n",
       "         ...,\n",
       "         [ 30,  37,  32],\n",
       "         [ 28,  35,  30],\n",
       "         [ 28,  35,  30]],\n",
       " \n",
       "        [[ 61,  49,  49],\n",
       "         [ 61,  49,  49],\n",
       "         [ 62,  50,  50],\n",
       "         ...,\n",
       "         [ 31,  38,  33],\n",
       "         [ 30,  37,  32],\n",
       "         [ 29,  36,  31]]], dtype=uint8),\n",
       " array([[[ 3,  8,  7],\n",
       "         [ 3,  8,  7],\n",
       "         [ 3,  7,  8],\n",
       "         ...,\n",
       "         [ 4, 57, 47],\n",
       "         [ 7, 59, 52],\n",
       "         [14, 64, 60]],\n",
       " \n",
       "        [[ 2,  7,  5],\n",
       "         [ 2,  7,  6],\n",
       "         [ 2,  7,  6],\n",
       "         ...,\n",
       "         [10, 59, 45],\n",
       "         [11, 55, 42],\n",
       "         [13, 57, 44]],\n",
       " \n",
       "        [[ 1,  7,  2],\n",
       "         [ 1,  7,  2],\n",
       "         [ 1,  6,  4],\n",
       "         ...,\n",
       "         [29, 63, 46],\n",
       "         [41, 69, 49],\n",
       "         [49, 77, 54]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4, 30, 12],\n",
       "         [ 5, 32, 12],\n",
       "         [ 5, 31, 13],\n",
       "         ...,\n",
       "         [ 7, 23,  6],\n",
       "         [ 5, 23,  6],\n",
       "         [ 2, 14, 16]],\n",
       " \n",
       "        [[ 3, 28, 14],\n",
       "         [ 4, 30, 12],\n",
       "         [ 5, 31, 15],\n",
       "         ...,\n",
       "         [ 6, 21,  7],\n",
       "         [ 3, 20,  7],\n",
       "         [ 2, 13, 17]],\n",
       " \n",
       "        [[ 1, 25, 15],\n",
       "         [ 4, 29, 15],\n",
       "         [ 4, 29, 15],\n",
       "         ...,\n",
       "         [ 2, 19,  6],\n",
       "         [ 1, 17,  6],\n",
       "         [ 3, 12, 21]]], dtype=uint8),\n",
       " array([[[ 54,  77, 133],\n",
       "         [ 56,  79, 135],\n",
       "         [ 59,  82, 138],\n",
       "         ...,\n",
       "         [ 45,  64, 125],\n",
       "         [ 47,  67, 125],\n",
       "         [ 47,  67, 125]],\n",
       " \n",
       "        [[ 57,  80, 136],\n",
       "         [ 57,  80, 136],\n",
       "         [ 57,  80, 136],\n",
       "         ...,\n",
       "         [ 44,  65, 126],\n",
       "         [ 45,  66, 127],\n",
       "         [ 45,  66, 127]],\n",
       " \n",
       "        [[ 57,  82, 138],\n",
       "         [ 56,  81, 137],\n",
       "         [ 54,  79, 135],\n",
       "         ...,\n",
       "         [ 44,  65, 126],\n",
       "         [ 45,  66, 127],\n",
       "         [ 45,  66, 127]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 31,  46,  92],\n",
       "         [ 35,  50,  96],\n",
       "         [ 36,  51,  97],\n",
       "         ...,\n",
       "         [ 16,  26,  60],\n",
       "         [ 20,  29,  66],\n",
       "         [ 24,  33,  70]],\n",
       " \n",
       "        [[ 26,  41,  87],\n",
       "         [ 27,  42,  88],\n",
       "         [ 29,  44,  90],\n",
       "         ...,\n",
       "         [ 15,  27,  61],\n",
       "         [ 18,  30,  66],\n",
       "         [ 22,  34,  70]],\n",
       " \n",
       "        [[ 22,  37,  83],\n",
       "         [ 19,  34,  80],\n",
       "         [ 22,  37,  83],\n",
       "         ...,\n",
       "         [ 11,  28,  61],\n",
       "         [ 14,  30,  66],\n",
       "         [ 17,  33,  69]]], dtype=uint8),\n",
       " array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]]], dtype=uint8),\n",
       " array([[[ 18,  60,  37],\n",
       "         [ 17,  59,  36],\n",
       "         [ 16,  58,  35],\n",
       "         ...,\n",
       "         [ 11,  27,  16],\n",
       "         [ 13,  29,  18],\n",
       "         [ 15,  31,  20]],\n",
       " \n",
       "        [[ 15,  57,  34],\n",
       "         [ 14,  56,  33],\n",
       "         [ 12,  54,  31],\n",
       "         ...,\n",
       "         [ 10,  26,  15],\n",
       "         [ 12,  28,  17],\n",
       "         [ 13,  29,  18]],\n",
       " \n",
       "        [[ 13,  55,  32],\n",
       "         [ 12,  54,  31],\n",
       "         [ 10,  52,  29],\n",
       "         ...,\n",
       "         [  9,  25,  14],\n",
       "         [ 10,  26,  15],\n",
       "         [ 11,  27,  16]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 14,  20,  19],\n",
       "         [ 12,  20,  19],\n",
       "         [ 16,  22,  21],\n",
       "         ...,\n",
       "         [ 82, 110, 134],\n",
       "         [ 80, 106, 130],\n",
       "         [ 78, 104, 128]],\n",
       " \n",
       "        [[ 12,  18,  17],\n",
       "         [ 12,  18,  17],\n",
       "         [ 14,  20,  19],\n",
       "         ...,\n",
       "         [ 95, 124, 145],\n",
       "         [ 93, 120, 141],\n",
       "         [ 91, 118, 139]],\n",
       " \n",
       "        [[ 10,  16,  15],\n",
       "         [ 10,  16,  15],\n",
       "         [ 12,  18,  17],\n",
       "         ...,\n",
       "         [106, 135, 156],\n",
       "         [104, 131, 152],\n",
       "         [102, 129, 150]]], dtype=uint8),\n",
       " array([[[ 70, 103, 112],\n",
       "         [ 76, 109, 118],\n",
       "         [ 83, 115, 126],\n",
       "         ...,\n",
       "         [ 74, 112, 112],\n",
       "         [ 68,  98,  99],\n",
       "         [ 91, 119, 120]],\n",
       " \n",
       "        [[ 66,  98, 109],\n",
       "         [ 74, 106, 117],\n",
       "         [ 83, 115, 126],\n",
       "         ...,\n",
       "         [ 77, 113, 113],\n",
       "         [ 66,  96,  97],\n",
       "         [ 84, 110, 110]],\n",
       " \n",
       "        [[ 68, 100, 113],\n",
       "         [ 72, 104, 117],\n",
       "         [ 81, 113, 126],\n",
       "         ...,\n",
       "         [ 78, 110, 109],\n",
       "         [ 73,  99,  99],\n",
       "         [ 96, 120, 118]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[149, 187, 205],\n",
       "         [159, 197, 215],\n",
       "         [149, 187, 205],\n",
       "         ...,\n",
       "         [ 99, 144, 165],\n",
       "         [ 92, 137, 158],\n",
       "         [ 90, 135, 156]],\n",
       " \n",
       "        [[153, 191, 209],\n",
       "         [162, 200, 218],\n",
       "         [153, 191, 209],\n",
       "         ...,\n",
       "         [101, 147, 165],\n",
       "         [ 99, 142, 163],\n",
       "         [101, 144, 165]],\n",
       " \n",
       "        [[161, 199, 217],\n",
       "         [169, 207, 225],\n",
       "         [159, 197, 215],\n",
       "         ...,\n",
       "         [ 62, 108, 126],\n",
       "         [ 64, 107, 128],\n",
       "         [ 68, 111, 132]]], dtype=uint8),\n",
       " array([[[ 69,  96, 122],\n",
       "         [ 76, 102, 126],\n",
       "         [ 62,  90, 107],\n",
       "         ...,\n",
       "         [ 63, 104, 149],\n",
       "         [ 69, 108, 153],\n",
       "         [ 62, 100, 148]],\n",
       " \n",
       "        [[ 92, 117, 137],\n",
       "         [ 98, 123, 143],\n",
       "         [ 78, 105, 126],\n",
       "         ...,\n",
       "         [ 66, 107, 152],\n",
       "         [ 66, 108, 151],\n",
       "         [ 65, 104, 148]],\n",
       " \n",
       "        [[ 81, 107, 123],\n",
       "         [ 82, 108, 124],\n",
       "         [ 82, 108, 125],\n",
       "         ...,\n",
       "         [ 71, 116, 160],\n",
       "         [ 65, 111, 152],\n",
       "         [ 68, 112, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 11,  23,  51],\n",
       "         [ 11,  23,  51],\n",
       "         [ 12,  24,  52],\n",
       "         ...,\n",
       "         [ 10,  31,  53],\n",
       "         [ 10,  30,  55],\n",
       "         [ 10,  27,  53]],\n",
       " \n",
       "        [[ 11,  24,  50],\n",
       "         [ 12,  25,  51],\n",
       "         [ 12,  24,  52],\n",
       "         ...,\n",
       "         [ 17,  39,  64],\n",
       "         [ 15,  35,  60],\n",
       "         [ 12,  31,  58]],\n",
       " \n",
       "        [[ 12,  24,  52],\n",
       "         [ 12,  24,  52],\n",
       "         [ 12,  24,  52],\n",
       "         ...,\n",
       "         [ 21,  46,  72],\n",
       "         [ 22,  44,  72],\n",
       "         [ 21,  43,  71]]], dtype=uint8),\n",
       " array([[[148, 198, 228],\n",
       "         [144, 194, 224],\n",
       "         [140, 190, 220],\n",
       "         ...,\n",
       "         [121, 180, 219],\n",
       "         [121, 180, 219],\n",
       "         [120, 179, 218]],\n",
       " \n",
       "        [[155, 205, 233],\n",
       "         [154, 204, 232],\n",
       "         [152, 202, 230],\n",
       "         ...,\n",
       "         [130, 189, 228],\n",
       "         [129, 188, 227],\n",
       "         [128, 187, 226]],\n",
       " \n",
       "        [[157, 206, 232],\n",
       "         [159, 208, 234],\n",
       "         [159, 208, 234],\n",
       "         ...,\n",
       "         [136, 194, 230],\n",
       "         [136, 194, 230],\n",
       "         [135, 193, 229]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[126, 171, 198],\n",
       "         [117, 162, 189],\n",
       "         [132, 176, 200],\n",
       "         ...,\n",
       "         [109, 150, 175],\n",
       "         [ 97, 138, 163],\n",
       "         [ 82, 123, 148]],\n",
       " \n",
       "        [[ 75, 120, 147],\n",
       "         [ 72, 117, 144],\n",
       "         [ 81, 125, 149],\n",
       "         ...,\n",
       "         [ 51,  88, 114],\n",
       "         [ 55,  92, 118],\n",
       "         [ 55,  92, 118]],\n",
       " \n",
       "        [[ 56,  99, 126],\n",
       "         [ 53,  96, 123],\n",
       "         [ 48,  89, 114],\n",
       "         ...,\n",
       "         [ 18,  53,  79],\n",
       "         [ 21,  56,  82],\n",
       "         [ 13,  48,  74]]], dtype=uint8),\n",
       " array([[[191, 221, 226],\n",
       "         [191, 221, 226],\n",
       "         [192, 222, 227],\n",
       "         ...,\n",
       "         [203, 231, 238],\n",
       "         [203, 231, 238],\n",
       "         [203, 231, 238]],\n",
       " \n",
       "        [[191, 221, 226],\n",
       "         [191, 221, 226],\n",
       "         [192, 222, 227],\n",
       "         ...,\n",
       "         [203, 231, 238],\n",
       "         [203, 231, 238],\n",
       "         [203, 231, 238]],\n",
       " \n",
       "        [[191, 221, 226],\n",
       "         [191, 221, 226],\n",
       "         [192, 222, 227],\n",
       "         ...,\n",
       "         [203, 231, 238],\n",
       "         [203, 231, 238],\n",
       "         [203, 231, 238]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[188, 217, 224],\n",
       "         [188, 217, 224],\n",
       "         [188, 217, 224],\n",
       "         ...,\n",
       "         [201, 228, 238],\n",
       "         [200, 227, 237],\n",
       "         [200, 227, 237]],\n",
       " \n",
       "        [[188, 217, 224],\n",
       "         [188, 217, 224],\n",
       "         [188, 217, 224],\n",
       "         ...,\n",
       "         [201, 228, 238],\n",
       "         [200, 227, 237],\n",
       "         [200, 227, 237]],\n",
       " \n",
       "        [[188, 217, 224],\n",
       "         [188, 217, 224],\n",
       "         [188, 217, 224],\n",
       "         ...,\n",
       "         [200, 227, 237],\n",
       "         [200, 227, 237],\n",
       "         [200, 227, 237]]], dtype=uint8),\n",
       " array([[[131, 137, 120],\n",
       "         [131, 137, 120],\n",
       "         [132, 138, 121],\n",
       "         ...,\n",
       "         [105, 169, 139],\n",
       "         [113, 172, 141],\n",
       "         [107, 164, 133]],\n",
       " \n",
       "        [[131, 137, 120],\n",
       "         [132, 138, 121],\n",
       "         [132, 138, 121],\n",
       "         ...,\n",
       "         [ 94, 158, 128],\n",
       "         [102, 161, 130],\n",
       "         [103, 160, 129]],\n",
       " \n",
       "        [[132, 137, 122],\n",
       "         [132, 137, 122],\n",
       "         [132, 137, 122],\n",
       "         ...,\n",
       "         [ 79, 146, 115],\n",
       "         [ 91, 151, 120],\n",
       "         [103, 162, 131]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 63, 137, 107],\n",
       "         [ 62, 136, 108],\n",
       "         [ 62, 132, 109],\n",
       "         ...,\n",
       "         [  8,   6,   6],\n",
       "         [  8,   6,   6],\n",
       "         [  8,   6,   6]],\n",
       " \n",
       "        [[ 67, 141, 111],\n",
       "         [ 65, 139, 111],\n",
       "         [ 65, 135, 112],\n",
       "         ...,\n",
       "         [  8,   6,   6],\n",
       "         [  8,   6,   6],\n",
       "         [  8,   6,   6]],\n",
       " \n",
       "        [[ 67, 141, 111],\n",
       "         [ 66, 140, 112],\n",
       "         [ 66, 136, 113],\n",
       "         ...,\n",
       "         [  8,   6,   6],\n",
       "         [  8,   6,   6],\n",
       "         [  8,   6,   6]]], dtype=uint8),\n",
       " array([[[ 98, 128,  99],\n",
       "         [ 99, 128, 102],\n",
       "         [100, 127, 101],\n",
       "         ...,\n",
       "         [130, 136, 111],\n",
       "         [131, 137, 112],\n",
       "         [130, 136, 111]],\n",
       " \n",
       "        [[100, 128,  99],\n",
       "         [101, 128, 102],\n",
       "         [100, 127, 101],\n",
       "         ...,\n",
       "         [130, 136, 111],\n",
       "         [130, 136, 111],\n",
       "         [128, 134, 109]],\n",
       " \n",
       "        [[ 99, 126, 100],\n",
       "         [ 99, 126, 100],\n",
       "         [100, 126, 102],\n",
       "         ...,\n",
       "         [128, 134, 109],\n",
       "         [128, 134, 111],\n",
       "         [127, 133, 110]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 79, 106,  62],\n",
       "         [ 79, 106,  62],\n",
       "         [ 80, 105,  61],\n",
       "         ...,\n",
       "         [ 95, 118,  90],\n",
       "         [ 95, 118,  90],\n",
       "         [ 93, 115,  90]],\n",
       " \n",
       "        [[ 78, 105,  62],\n",
       "         [ 78, 105,  62],\n",
       "         [ 78, 105,  61],\n",
       "         ...,\n",
       "         [ 96, 120,  90],\n",
       "         [ 95, 118,  90],\n",
       "         [ 93, 116,  88]],\n",
       " \n",
       "        [[ 80, 104,  62],\n",
       "         [ 79, 103,  61],\n",
       "         [ 79, 104,  60],\n",
       "         ...,\n",
       "         [ 97, 119,  90],\n",
       "         [ 93, 116,  88],\n",
       "         [ 93, 116,  88]]], dtype=uint8),\n",
       " array([[[ 76,  60,  48],\n",
       "         [ 73,  57,  45],\n",
       "         [ 77,  59,  48],\n",
       "         ...,\n",
       "         [ 32,  54, 112],\n",
       "         [ 32,  56, 114],\n",
       "         [ 33,  60, 117]],\n",
       " \n",
       "        [[ 65,  50,  41],\n",
       "         [ 65,  50,  41],\n",
       "         [ 71,  54,  45],\n",
       "         ...,\n",
       "         [ 29,  54, 110],\n",
       "         [ 29,  56, 113],\n",
       "         [ 31,  60, 117]],\n",
       " \n",
       "        [[ 50,  38,  32],\n",
       "         [ 52,  40,  34],\n",
       "         [ 58,  44,  38],\n",
       "         ...,\n",
       "         [ 31,  58, 114],\n",
       "         [ 29,  58, 115],\n",
       "         [ 26,  56, 115]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 51,  83, 106],\n",
       "         [ 36,  68,  91],\n",
       "         [ 78, 110, 129],\n",
       "         ...,\n",
       "         [ 68, 149, 146],\n",
       "         [ 77, 151, 151],\n",
       "         [ 72, 144, 144]],\n",
       " \n",
       "        [[ 48,  81,  97],\n",
       "         [ 43,  78,  92],\n",
       "         [ 68, 107, 116],\n",
       "         ...,\n",
       "         [ 57, 134, 131],\n",
       "         [ 75, 148, 146],\n",
       "         [ 99, 166, 167]],\n",
       " \n",
       "        [[ 36,  71,  85],\n",
       "         [ 30,  68,  80],\n",
       "         [ 13,  54,  63],\n",
       "         ...,\n",
       "         [ 41, 117, 116],\n",
       "         [ 57, 129, 129],\n",
       "         [ 95, 162, 165]]], dtype=uint8),\n",
       " array([[[ 85,  87, 111],\n",
       "         [ 86,  89, 110],\n",
       "         [ 88,  91, 112],\n",
       "         ...,\n",
       "         [166, 144, 149],\n",
       "         [164, 141, 145],\n",
       "         [161, 139, 141]],\n",
       " \n",
       "        [[ 86,  87, 107],\n",
       "         [ 86,  87, 107],\n",
       "         [ 88,  89, 109],\n",
       "         ...,\n",
       "         [108, 113, 104],\n",
       "         [107, 114, 107],\n",
       "         [109, 113, 107]],\n",
       " \n",
       "        [[ 85,  86, 106],\n",
       "         [ 85,  86, 106],\n",
       "         [ 86,  87, 107],\n",
       "         ...,\n",
       "         [104, 117, 101],\n",
       "         [102, 115,  99],\n",
       "         [102, 115, 101]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59, 112, 133],\n",
       "         [ 53, 109, 126],\n",
       "         [ 51, 108, 123],\n",
       "         ...,\n",
       "         [ 30,  95,  74],\n",
       "         [ 25,  90,  69],\n",
       "         [ 21,  86,  65]],\n",
       " \n",
       "        [[ 73, 108, 152],\n",
       "         [ 55, 102, 133],\n",
       "         [ 40,  99, 114],\n",
       "         ...,\n",
       "         [ 27,  94,  73],\n",
       "         [ 23,  90,  69],\n",
       "         [ 20,  87,  66]],\n",
       " \n",
       "        [[ 75,  96, 158],\n",
       "         [ 67, 106, 150],\n",
       "         [ 41, 105, 123],\n",
       "         ...,\n",
       "         [ 22,  91,  70],\n",
       "         [ 19,  88,  67],\n",
       "         [ 16,  85,  64]]], dtype=uint8),\n",
       " array([[[ 74,  90,  66],\n",
       "         [ 84, 100,  77],\n",
       "         [ 93, 103,  86],\n",
       "         ...,\n",
       "         [ 31,  46,  42],\n",
       "         [ 32,  47,  43],\n",
       "         [ 33,  48,  44]],\n",
       " \n",
       "        [[ 73,  89,  65],\n",
       "         [ 83,  99,  76],\n",
       "         [118, 128, 111],\n",
       "         ...,\n",
       "         [ 31,  46,  42],\n",
       "         [ 31,  46,  42],\n",
       "         [ 31,  46,  42]],\n",
       " \n",
       "        [[ 82,  98,  74],\n",
       "         [ 91, 107,  84],\n",
       "         [138, 148, 131],\n",
       "         ...,\n",
       "         [ 34,  51,  48],\n",
       "         [ 33,  50,  47],\n",
       "         [ 32,  49,  46]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 71, 105,  65],\n",
       "         [ 82, 116,  75],\n",
       "         [ 93, 127,  87],\n",
       "         ...,\n",
       "         [ 85, 111,  65],\n",
       "         [ 77, 100,  55],\n",
       "         [ 79, 100,  55]],\n",
       " \n",
       "        [[ 74, 108,  71],\n",
       "         [ 83, 118,  78],\n",
       "         [ 91, 125,  88],\n",
       "         ...,\n",
       "         [ 84, 109,  65],\n",
       "         [ 79, 102,  58],\n",
       "         [ 88, 111,  67]],\n",
       " \n",
       "        [[ 77, 111,  74],\n",
       "         [ 82, 116,  79],\n",
       "         [ 86, 120,  83],\n",
       "         ...,\n",
       "         [ 88, 115,  71],\n",
       "         [ 84, 107,  63],\n",
       "         [ 75,  98,  54]]], dtype=uint8),\n",
       " array([[[252, 234, 217],\n",
       "         [252, 234, 217],\n",
       "         [252, 234, 217],\n",
       "         ...,\n",
       "         [ 78,  81,  86],\n",
       "         [ 60,  63,  68],\n",
       "         [ 38,  41,  45]],\n",
       " \n",
       "        [[252, 234, 217],\n",
       "         [252, 234, 217],\n",
       "         [252, 234, 217],\n",
       "         ...,\n",
       "         [ 74,  77,  82],\n",
       "         [ 62,  65,  70],\n",
       "         [ 61,  64,  68]],\n",
       " \n",
       "        [[252, 234, 217],\n",
       "         [252, 234, 217],\n",
       "         [252, 234, 217],\n",
       "         ...,\n",
       "         [ 79,  82,  87],\n",
       "         [ 68,  71,  76],\n",
       "         [ 81,  84,  88]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 74,  92, 109],\n",
       "         [ 82, 100, 117],\n",
       "         [ 91, 109, 126],\n",
       "         ...,\n",
       "         [101, 243, 244],\n",
       "         [108, 245, 247],\n",
       "         [121, 251, 251]],\n",
       " \n",
       "        [[ 71,  91, 108],\n",
       "         [ 80, 100, 117],\n",
       "         [ 90, 110, 127],\n",
       "         ...,\n",
       "         [ 93, 239, 239],\n",
       "         [ 98, 240, 241],\n",
       "         [113, 247, 247]],\n",
       " \n",
       "        [[ 72,  92, 109],\n",
       "         [ 80, 100, 117],\n",
       "         [ 91, 111, 128],\n",
       "         ...,\n",
       "         [ 87, 235, 235],\n",
       "         [ 91, 235, 236],\n",
       "         [106, 242, 241]]], dtype=uint8),\n",
       " array([[[ 14,  17,  15],\n",
       "         [ 15,  18,  16],\n",
       "         [ 14,  17,  15],\n",
       "         ...,\n",
       "         [ 72, 163, 140],\n",
       "         [ 72, 158, 140],\n",
       "         [ 78, 159, 144]],\n",
       " \n",
       "        [[ 15,  18,  16],\n",
       "         [ 14,  17,  15],\n",
       "         [ 13,  16,  14],\n",
       "         ...,\n",
       "         [ 76, 175, 155],\n",
       "         [ 73, 167, 150],\n",
       "         [ 76, 167, 152]],\n",
       " \n",
       "        [[ 14,  17,  15],\n",
       "         [ 13,  16,  14],\n",
       "         [ 12,  15,  13],\n",
       "         ...,\n",
       "         [ 86, 187, 166],\n",
       "         [ 82, 177, 156],\n",
       "         [ 83, 176, 155]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 40,  99,  91],\n",
       "         [ 37,  97,  87],\n",
       "         [ 56, 117, 103],\n",
       "         ...,\n",
       "         [204, 214, 224],\n",
       "         [200, 212, 224],\n",
       "         [196, 208, 220]],\n",
       " \n",
       "        [[ 67, 121, 116],\n",
       "         [ 63, 117, 110],\n",
       "         [ 72, 127, 118],\n",
       "         ...,\n",
       "         [201, 213, 225],\n",
       "         [197, 211, 223],\n",
       "         [193, 206, 220]],\n",
       " \n",
       "        [[101, 156, 153],\n",
       "         [103, 158, 155],\n",
       "         [ 95, 149, 142],\n",
       "         ...,\n",
       "         [201, 213, 225],\n",
       "         [196, 209, 223],\n",
       "         [192, 205, 219]]], dtype=uint8),\n",
       " array([[[ 91, 106, 115],\n",
       "         [108, 124, 131],\n",
       "         [153, 169, 176],\n",
       "         ...,\n",
       "         [ 79, 115, 133],\n",
       "         [ 48,  84, 102],\n",
       "         [ 34,  63,  90]],\n",
       " \n",
       "        [[204, 212, 219],\n",
       "         [207, 215, 222],\n",
       "         [228, 234, 241],\n",
       "         ...,\n",
       "         [ 70, 105, 125],\n",
       "         [ 50,  85, 105],\n",
       "         [ 35,  66,  87]],\n",
       " \n",
       "        [[253, 253, 255],\n",
       "         [253, 254, 255],\n",
       "         [253, 254, 255],\n",
       "         ...,\n",
       "         [ 58,  90, 113],\n",
       "         [ 51,  83, 106],\n",
       "         [ 66,  98, 117]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[210, 217, 255],\n",
       "         [202, 214, 254],\n",
       "         [197, 218, 250],\n",
       "         ...,\n",
       "         [ 73,  95, 120],\n",
       "         [ 57,  78, 105],\n",
       "         [ 46,  66,  91]],\n",
       " \n",
       "        [[124, 130, 183],\n",
       "         [126, 139, 191],\n",
       "         [123, 143, 191],\n",
       "         ...,\n",
       "         [ 60,  78, 107],\n",
       "         [ 50,  68,  97],\n",
       "         [ 43,  60,  86]],\n",
       " \n",
       "        [[ 98, 111, 163],\n",
       "         [ 93, 108, 164],\n",
       "         [ 69,  92, 148],\n",
       "         ...,\n",
       "         [ 53,  71, 102],\n",
       "         [ 54,  72, 103],\n",
       "         [ 51,  66,  92]]], dtype=uint8),\n",
       " array([[[103, 118, 120],\n",
       "         [104, 121, 124],\n",
       "         [105, 124, 129],\n",
       "         ...,\n",
       "         [ 24,  67,  40],\n",
       "         [ 37,  77,  52],\n",
       "         [ 32,  72,  47]],\n",
       " \n",
       "        [[107, 122, 125],\n",
       "         [107, 122, 125],\n",
       "         [110, 126, 132],\n",
       "         ...,\n",
       "         [ 25,  70,  43],\n",
       "         [ 29,  72,  45],\n",
       "         [ 26,  66,  41]],\n",
       " \n",
       "        [[115, 127, 133],\n",
       "         [110, 122, 128],\n",
       "         [108, 122, 128],\n",
       "         ...,\n",
       "         [ 26,  72,  43],\n",
       "         [ 25,  68,  41],\n",
       "         [ 25,  67,  42]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[164, 163, 173],\n",
       "         [180, 180, 198],\n",
       "         [168, 172, 196],\n",
       "         ...,\n",
       "         [ 78,  78, 108],\n",
       "         [ 99, 126, 163],\n",
       "         [166, 178, 218]],\n",
       " \n",
       "        [[175, 172, 187],\n",
       "         [163, 169, 188],\n",
       "         [139, 149, 173],\n",
       "         ...,\n",
       "         [172, 189, 208],\n",
       "         [129, 155, 185],\n",
       "         [164, 156, 193]],\n",
       " \n",
       "        [[178, 183, 204],\n",
       "         [155, 167, 191],\n",
       "         [153, 163, 187],\n",
       "         ...,\n",
       "         [228, 236, 236],\n",
       "         [206, 206, 222],\n",
       "         [117, 100, 127]]], dtype=uint8),\n",
       " array([[[ 78, 115, 105],\n",
       "         [ 77, 114, 104],\n",
       "         [ 77, 114, 104],\n",
       "         ...,\n",
       "         [118, 150, 169],\n",
       "         [120, 151, 172],\n",
       "         [120, 151, 174]],\n",
       " \n",
       "        [[ 82, 117, 107],\n",
       "         [ 81, 116, 106],\n",
       "         [ 80, 115, 105],\n",
       "         ...,\n",
       "         [118, 150, 169],\n",
       "         [119, 150, 171],\n",
       "         [119, 150, 173]],\n",
       " \n",
       "        [[ 84, 120, 108],\n",
       "         [ 82, 117, 107],\n",
       "         [ 79, 114, 104],\n",
       "         ...,\n",
       "         [117, 149, 168],\n",
       "         [118, 149, 170],\n",
       "         [117, 148, 169]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 25,  25,  25],\n",
       "         [ 34,  32,  31],\n",
       "         [ 41,  41,  35],\n",
       "         ...,\n",
       "         [ 85,  98,  90],\n",
       "         [ 59,  71,  59],\n",
       "         [ 34,  41,  38]],\n",
       " \n",
       "        [[ 28,  29,  27],\n",
       "         [ 31,  32,  28],\n",
       "         [ 36,  38,  32],\n",
       "         ...,\n",
       "         [ 46,  58,  46],\n",
       "         [ 45,  55,  42],\n",
       "         [ 39,  46,  41]],\n",
       " \n",
       "        [[ 29,  33,  28],\n",
       "         [ 29,  33,  27],\n",
       "         [ 31,  36,  27],\n",
       "         ...,\n",
       "         [ 34,  45,  29],\n",
       "         [ 37,  47,  30],\n",
       "         [ 33,  40,  33]]], dtype=uint8),\n",
       " array([[[ 8, 27, 12],\n",
       "         [10, 18,  8],\n",
       "         [ 9, 12, 10],\n",
       "         ...,\n",
       "         [ 0,  2,  7],\n",
       "         [ 2,  2, 16],\n",
       "         [ 8,  9,  7]],\n",
       " \n",
       "        [[ 9, 26, 17],\n",
       "         [12, 23, 20],\n",
       "         [ 4,  8, 19],\n",
       "         ...,\n",
       "         [ 7,  6, 16],\n",
       "         [ 7,  7, 21],\n",
       "         [ 7,  3,  8]],\n",
       " \n",
       "        [[10, 23, 25],\n",
       "         [12, 24, 28],\n",
       "         [10, 24, 42],\n",
       "         ...,\n",
       "         [ 7,  9, 17],\n",
       "         [ 7,  3, 22],\n",
       "         [ 7,  2, 11]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7, 51,  4],\n",
       "         [ 3, 52, 20],\n",
       "         [ 8, 56, 38],\n",
       "         ...,\n",
       "         [ 1, 80, 39],\n",
       "         [ 4, 90, 28],\n",
       "         [ 0, 84, 12]],\n",
       " \n",
       "        [[ 8, 45, 11],\n",
       "         [ 1, 57, 16],\n",
       "         [ 7, 75, 34],\n",
       "         ...,\n",
       "         [ 1, 26,  0],\n",
       "         [ 1, 19,  2],\n",
       "         [ 2, 39,  7]],\n",
       " \n",
       "        [[ 4, 33, 17],\n",
       "         [ 0, 47, 14],\n",
       "         [ 7, 59, 19],\n",
       "         ...,\n",
       "         [ 3,  4,  0],\n",
       "         [ 0,  1,  5],\n",
       "         [ 2,  3, 13]]], dtype=uint8),\n",
       " array([[[14, 14, 14],\n",
       "         [15, 15, 15],\n",
       "         [15, 15, 15],\n",
       "         ...,\n",
       "         [14, 12, 12],\n",
       "         [14, 12, 12],\n",
       "         [14, 12, 12]],\n",
       " \n",
       "        [[15, 15, 15],\n",
       "         [15, 15, 15],\n",
       "         [15, 15, 15],\n",
       "         ...,\n",
       "         [13, 11, 11],\n",
       "         [14, 12, 12],\n",
       "         [14, 12, 12]],\n",
       " \n",
       "        [[15, 15, 15],\n",
       "         [16, 16, 16],\n",
       "         [16, 16, 16],\n",
       "         ...,\n",
       "         [11, 11, 11],\n",
       "         [12, 12, 12],\n",
       "         [12, 12, 12]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[87, 85, 85],\n",
       "         [89, 87, 87],\n",
       "         [90, 88, 88],\n",
       "         ...,\n",
       "         [73, 69, 68],\n",
       "         [72, 68, 67],\n",
       "         [74, 70, 69]],\n",
       " \n",
       "        [[88, 86, 86],\n",
       "         [89, 87, 87],\n",
       "         [90, 88, 88],\n",
       "         ...,\n",
       "         [76, 72, 71],\n",
       "         [75, 71, 70],\n",
       "         [76, 72, 71]],\n",
       " \n",
       "        [[88, 86, 86],\n",
       "         [90, 88, 88],\n",
       "         [90, 88, 88],\n",
       "         ...,\n",
       "         [80, 76, 75],\n",
       "         [78, 74, 73],\n",
       "         [77, 73, 72]]], dtype=uint8),\n",
       " array([[[ 45,  46,  44],\n",
       "         [ 59,  59,  59],\n",
       "         [ 62,  61,  65],\n",
       "         ...,\n",
       "         [ 75,  89,  87],\n",
       "         [ 60,  81,  73],\n",
       "         [ 37,  60,  52]],\n",
       " \n",
       "        [[ 38,  41,  39],\n",
       "         [ 50,  52,  52],\n",
       "         [ 60,  64,  65],\n",
       "         ...,\n",
       "         [ 61,  72,  69],\n",
       "         [ 58,  75,  66],\n",
       "         [ 41,  60,  51]],\n",
       " \n",
       "        [[ 43,  49,  44],\n",
       "         [ 49,  54,  52],\n",
       "         [ 53,  61,  61],\n",
       "         ...,\n",
       "         [ 44,  49,  47],\n",
       "         [ 54,  64,  58],\n",
       "         [ 42,  52,  46]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 64, 115, 111],\n",
       "         [108, 162, 157],\n",
       "         [144, 202, 197],\n",
       "         ...,\n",
       "         [ 90, 145, 160],\n",
       "         [136, 185, 193],\n",
       "         [127, 171, 178]],\n",
       " \n",
       "        [[ 78, 136, 135],\n",
       "         [105, 163, 162],\n",
       "         [139, 196, 195],\n",
       "         ...,\n",
       "         [114, 160, 177],\n",
       "         [165, 199, 212],\n",
       "         [143, 172, 181]],\n",
       " \n",
       "        [[ 88, 149, 151],\n",
       "         [101, 160, 162],\n",
       "         [142, 195, 198],\n",
       "         ...,\n",
       "         [133, 169, 187],\n",
       "         [184, 210, 224],\n",
       "         [157, 175, 186]]], dtype=uint8),\n",
       " array([[[116, 120, 139],\n",
       "         [117, 121, 140],\n",
       "         [116, 120, 139],\n",
       "         ...,\n",
       "         [ 54,  75, 102],\n",
       "         [ 63,  81, 110],\n",
       "         [ 67,  83, 112]],\n",
       " \n",
       "        [[112, 116, 135],\n",
       "         [114, 118, 137],\n",
       "         [115, 119, 138],\n",
       "         ...,\n",
       "         [ 58,  77, 104],\n",
       "         [ 67,  81, 110],\n",
       "         [ 69,  83, 112]],\n",
       " \n",
       "        [[102, 108, 127],\n",
       "         [105, 111, 130],\n",
       "         [111, 115, 134],\n",
       "         ...,\n",
       "         [ 63,  75, 103],\n",
       "         [ 70,  78, 108],\n",
       "         [ 72,  80, 110]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[137, 165, 199],\n",
       "         [133, 164, 197],\n",
       "         [127, 161, 191],\n",
       "         ...,\n",
       "         [200, 225, 245],\n",
       "         [196, 223, 243],\n",
       "         [178, 205, 225]],\n",
       " \n",
       "        [[128, 158, 193],\n",
       "         [125, 158, 191],\n",
       "         [122, 158, 188],\n",
       "         ...,\n",
       "         [189, 215, 232],\n",
       "         [180, 208, 225],\n",
       "         [192, 220, 237]],\n",
       " \n",
       "        [[121, 151, 186],\n",
       "         [122, 155, 188],\n",
       "         [124, 159, 192],\n",
       "         ...,\n",
       "         [203, 229, 245],\n",
       "         [197, 226, 241],\n",
       "         [185, 214, 229]]], dtype=uint8),\n",
       " array([[[34, 47, 93],\n",
       "         [26, 42, 85],\n",
       "         [29, 45, 87],\n",
       "         ...,\n",
       "         [28, 46, 83],\n",
       "         [30, 47, 86],\n",
       "         [27, 44, 83]],\n",
       " \n",
       "        [[32, 45, 91],\n",
       "         [26, 42, 85],\n",
       "         [29, 45, 87],\n",
       "         ...,\n",
       "         [27, 46, 84],\n",
       "         [30, 47, 86],\n",
       "         [28, 47, 85]],\n",
       " \n",
       "        [[33, 46, 90],\n",
       "         [28, 44, 86],\n",
       "         [28, 45, 84],\n",
       "         ...,\n",
       "         [25, 45, 86],\n",
       "         [30, 48, 89],\n",
       "         [26, 46, 87]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[28, 45, 84],\n",
       "         [33, 52, 90],\n",
       "         [26, 46, 87],\n",
       "         ...,\n",
       "         [28, 46, 83],\n",
       "         [32, 48, 84],\n",
       "         [32, 48, 84]],\n",
       " \n",
       "        [[29, 45, 82],\n",
       "         [30, 48, 85],\n",
       "         [27, 44, 83],\n",
       "         ...,\n",
       "         [29, 46, 85],\n",
       "         [28, 46, 83],\n",
       "         [29, 47, 84]],\n",
       " \n",
       "        [[29, 45, 82],\n",
       "         [32, 48, 85],\n",
       "         [27, 44, 83],\n",
       "         ...,\n",
       "         [28, 47, 85],\n",
       "         [28, 45, 84],\n",
       "         [29, 46, 85]]], dtype=uint8),\n",
       " array([[[234, 249, 251],\n",
       "         [234, 250, 249],\n",
       "         [234, 251, 247],\n",
       "         ...,\n",
       "         [230, 254, 242],\n",
       "         [232, 255, 241],\n",
       "         [232, 255, 241]],\n",
       " \n",
       "        [[234, 249, 251],\n",
       "         [234, 250, 249],\n",
       "         [234, 251, 247],\n",
       "         ...,\n",
       "         [230, 254, 242],\n",
       "         [232, 255, 241],\n",
       "         [232, 255, 241]],\n",
       " \n",
       "        [[234, 249, 251],\n",
       "         [234, 250, 249],\n",
       "         [234, 251, 247],\n",
       "         ...,\n",
       "         [232, 254, 242],\n",
       "         [232, 255, 241],\n",
       "         [232, 255, 241]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[230, 255, 241],\n",
       "         [230, 255, 241],\n",
       "         [232, 254, 242],\n",
       "         ...,\n",
       "         [232, 254, 242],\n",
       "         [232, 254, 242],\n",
       "         [232, 254, 242]],\n",
       " \n",
       "        [[230, 255, 241],\n",
       "         [230, 255, 241],\n",
       "         [232, 254, 242],\n",
       "         ...,\n",
       "         [232, 254, 242],\n",
       "         [232, 254, 242],\n",
       "         [232, 254, 242]],\n",
       " \n",
       "        [[230, 255, 241],\n",
       "         [230, 255, 241],\n",
       "         [232, 254, 242],\n",
       "         ...,\n",
       "         [232, 254, 242],\n",
       "         [232, 254, 242],\n",
       "         [232, 254, 242]]], dtype=uint8),\n",
       " array([[[229, 225, 224],\n",
       "         [219, 212, 217],\n",
       "         [241, 235, 240],\n",
       "         ...,\n",
       "         [245, 245, 251],\n",
       "         [252, 246, 251],\n",
       "         [249, 249, 249]],\n",
       " \n",
       "        [[228, 223, 225],\n",
       "         [221, 214, 221],\n",
       "         [241, 236, 238],\n",
       "         ...,\n",
       "         [253, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[230, 225, 227],\n",
       "         [233, 231, 230],\n",
       "         [239, 237, 236],\n",
       "         ...,\n",
       "         [251, 254, 252],\n",
       "         [251, 249, 249],\n",
       "         [245, 247, 247]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  8,   4,   3],\n",
       "         [  2,   3,   0],\n",
       "         [  5,   3,   2],\n",
       "         ...,\n",
       "         [ 24,  22,  21],\n",
       "         [ 33,  25,  25],\n",
       "         [ 42,  39,  35]],\n",
       " \n",
       "        [[  3,   4,   2],\n",
       "         [  6,   4,   3],\n",
       "         [  2,   0,   0],\n",
       "         ...,\n",
       "         [ 13,  11,  11],\n",
       "         [  9,   6,   8],\n",
       "         [ 25,  27,  27]],\n",
       " \n",
       "        [[  2,   0,   0],\n",
       "         [  0,   0,   1],\n",
       "         [  0,   3,   1],\n",
       "         ...,\n",
       "         [ 15,  16,  14],\n",
       "         [ 16,  19,  17],\n",
       "         [ 24,  25,  23]]], dtype=uint8),\n",
       " array([[[ 56,  75,  72],\n",
       "         [ 56,  75,  72],\n",
       "         [ 57,  76,  73],\n",
       "         ...,\n",
       "         [ 76, 108, 113],\n",
       "         [ 76, 108, 113],\n",
       "         [ 76, 108, 113]],\n",
       " \n",
       "        [[ 57,  76,  73],\n",
       "         [ 57,  76,  73],\n",
       "         [ 57,  76,  73],\n",
       "         ...,\n",
       "         [ 81, 116, 120],\n",
       "         [ 81, 116, 120],\n",
       "         [ 81, 116, 120]],\n",
       " \n",
       "        [[ 57,  76,  73],\n",
       "         [ 57,  76,  73],\n",
       "         [ 58,  77,  74],\n",
       "         ...,\n",
       "         [ 88, 125, 129],\n",
       "         [ 88, 125, 129],\n",
       "         [ 88, 125, 129]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 12,  17,  18],\n",
       "         [ 12,  17,  18],\n",
       "         [ 11,  16,  17],\n",
       "         ...,\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1]],\n",
       " \n",
       "        [[ 14,  19,  20],\n",
       "         [ 14,  19,  20],\n",
       "         [ 14,  19,  20],\n",
       "         ...,\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1]],\n",
       " \n",
       "        [[ 17,  22,  23],\n",
       "         [ 17,  22,  23],\n",
       "         [ 17,  22,  23],\n",
       "         ...,\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1]]], dtype=uint8),\n",
       " array([[[ 2,  4,  4],\n",
       "         [ 2,  4,  4],\n",
       "         [ 2,  4,  4],\n",
       "         ...,\n",
       "         [14, 16, 16],\n",
       "         [14, 16, 16],\n",
       "         [14, 16, 16]],\n",
       " \n",
       "        [[ 1,  3,  3],\n",
       "         [ 2,  4,  4],\n",
       "         [ 3,  5,  5],\n",
       "         ...,\n",
       "         [14, 16, 16],\n",
       "         [14, 16, 16],\n",
       "         [14, 16, 16]],\n",
       " \n",
       "        [[ 2,  4,  4],\n",
       "         [ 2,  4,  4],\n",
       "         [ 5,  5,  5],\n",
       "         ...,\n",
       "         [14, 16, 16],\n",
       "         [14, 16, 16],\n",
       "         [13, 15, 15]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[30, 32, 32],\n",
       "         [31, 33, 33],\n",
       "         [37, 39, 39],\n",
       "         ...,\n",
       "         [ 7,  9,  9],\n",
       "         [12, 14, 14],\n",
       "         [21, 23, 23]],\n",
       " \n",
       "        [[31, 33, 33],\n",
       "         [32, 34, 34],\n",
       "         [33, 35, 35],\n",
       "         ...,\n",
       "         [ 7,  9,  9],\n",
       "         [ 9, 11, 11],\n",
       "         [17, 19, 19]],\n",
       " \n",
       "        [[32, 34, 34],\n",
       "         [31, 33, 33],\n",
       "         [32, 34, 34],\n",
       "         ...,\n",
       "         [ 8,  8,  8],\n",
       "         [ 8,  8,  8],\n",
       "         [15, 15, 15]]], dtype=uint8),\n",
       " array([[[  9,  24,  33],\n",
       "         [ 10,  25,  34],\n",
       "         [ 14,  29,  38],\n",
       "         ...,\n",
       "         [  1,   2,   6],\n",
       "         [  2,   3,   7],\n",
       "         [  3,   4,   8]],\n",
       " \n",
       "        [[  9,  21,  31],\n",
       "         [ 13,  25,  35],\n",
       "         [ 15,  30,  39],\n",
       "         ...,\n",
       "         [  2,   3,   7],\n",
       "         [  2,   3,   7],\n",
       "         [  2,   3,   7]],\n",
       " \n",
       "        [[ 11,  24,  32],\n",
       "         [ 14,  27,  35],\n",
       "         [ 15,  28,  36],\n",
       "         ...,\n",
       "         [  2,   3,   7],\n",
       "         [  2,   3,   7],\n",
       "         [  2,   3,   7]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 38, 140, 115],\n",
       "         [ 41, 144, 117],\n",
       "         [ 44, 147, 120],\n",
       "         ...,\n",
       "         [ 32,  92, 114],\n",
       "         [ 36,  94, 113],\n",
       "         [ 65, 124, 143]],\n",
       " \n",
       "        [[ 41, 142, 117],\n",
       "         [ 43, 144, 119],\n",
       "         [ 52, 153, 128],\n",
       "         ...,\n",
       "         [ 41, 106, 120],\n",
       "         [ 30,  95, 103],\n",
       "         [ 55, 119, 124]],\n",
       " \n",
       "        [[ 49, 145, 121],\n",
       "         [ 52, 148, 124],\n",
       "         [ 52, 150, 126],\n",
       "         ...,\n",
       "         [ 33, 106, 110],\n",
       "         [ 29, 104, 102],\n",
       "         [ 46, 113, 108]]], dtype=uint8),\n",
       " array([[[134, 161, 171],\n",
       "         [137, 159, 170],\n",
       "         [143, 155, 167],\n",
       "         ...,\n",
       "         [ 98, 104, 103],\n",
       "         [ 96, 100,  95],\n",
       "         [102, 101,  97]],\n",
       " \n",
       "        [[142, 158, 170],\n",
       "         [144, 156, 168],\n",
       "         [148, 157, 167],\n",
       "         ...,\n",
       "         [ 85,  95,  95],\n",
       "         [ 91,  98,  95],\n",
       "         [ 99, 104, 102]],\n",
       " \n",
       "        [[144, 153, 167],\n",
       "         [144, 151, 166],\n",
       "         [158, 162, 173],\n",
       "         ...,\n",
       "         [ 71,  84,  86],\n",
       "         [ 73,  86,  88],\n",
       "         [ 74,  86,  88]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[120, 147, 173],\n",
       "         [124, 149, 175],\n",
       "         [124, 150, 174],\n",
       "         ...,\n",
       "         [ 95, 114, 129],\n",
       "         [ 92, 111, 126],\n",
       "         [ 99, 118, 133]],\n",
       " \n",
       "        [[122, 145, 171],\n",
       "         [124, 147, 173],\n",
       "         [127, 151, 175],\n",
       "         ...,\n",
       "         [ 90, 106, 122],\n",
       "         [ 93, 113, 124],\n",
       "         [ 99, 119, 130]],\n",
       " \n",
       "        [[124, 143, 170],\n",
       "         [125, 144, 171],\n",
       "         [127, 151, 175],\n",
       "         ...,\n",
       "         [ 82,  97, 116],\n",
       "         [ 90, 105, 121],\n",
       "         [ 91, 106, 122]]], dtype=uint8),\n",
       " array([[[ 28,  46,  47],\n",
       "         [ 28,  46,  47],\n",
       "         [ 27,  45,  46],\n",
       "         ...,\n",
       "         [ 49,  71,  69],\n",
       "         [ 47,  68,  69],\n",
       "         [ 45,  66,  67]],\n",
       " \n",
       "        [[ 29,  44,  47],\n",
       "         [ 29,  44,  47],\n",
       "         [ 29,  44,  47],\n",
       "         ...,\n",
       "         [ 50,  69,  72],\n",
       "         [ 49,  68,  73],\n",
       "         [ 47,  66,  71]],\n",
       " \n",
       "        [[ 28,  42,  48],\n",
       "         [ 29,  43,  49],\n",
       "         [ 29,  43,  49],\n",
       "         ...,\n",
       "         [ 50,  66,  73],\n",
       "         [ 49,  65,  71],\n",
       "         [ 49,  65,  71]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 18,  70,  83],\n",
       "         [ 69, 122, 132],\n",
       "         [104, 161, 158],\n",
       "         ...,\n",
       "         [ 50, 104,  57],\n",
       "         [ 36,  89,  39],\n",
       "         [ 30,  83,  33]],\n",
       " \n",
       "        [[ 91, 141, 161],\n",
       "         [ 37,  89, 102],\n",
       "         [ 27,  86,  82],\n",
       "         ...,\n",
       "         [ 63, 115,  68],\n",
       "         [ 37,  90,  40],\n",
       "         [ 25,  78,  28]],\n",
       " \n",
       "        [[116, 162, 193],\n",
       "         [ 49,  99, 119],\n",
       "         [ 28,  85,  86],\n",
       "         ...,\n",
       "         [ 75, 126,  82],\n",
       "         [ 43,  95,  47],\n",
       "         [ 26,  78,  30]]], dtype=uint8),\n",
       " array([[[109, 134, 130],\n",
       "         [102, 127, 123],\n",
       "         [102, 125, 120],\n",
       "         ...,\n",
       "         [ 40,  60,  48],\n",
       "         [ 42,  62,  50],\n",
       "         [ 44,  64,  52]],\n",
       " \n",
       "        [[108, 133, 129],\n",
       "         [102, 127, 123],\n",
       "         [100, 123, 119],\n",
       "         ...,\n",
       "         [ 43,  63,  51],\n",
       "         [ 43,  63,  51],\n",
       "         [ 44,  64,  52]],\n",
       " \n",
       "        [[101, 126, 122],\n",
       "         [101, 124, 120],\n",
       "         [ 96, 119, 115],\n",
       "         ...,\n",
       "         [ 42,  62,  50],\n",
       "         [ 44,  64,  52],\n",
       "         [ 43,  63,  50]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 34,  58,  64],\n",
       "         [ 40,  66,  72],\n",
       "         [ 43,  70,  74],\n",
       "         ...,\n",
       "         [209, 209, 223],\n",
       "         [210, 210, 224],\n",
       "         [209, 209, 223]],\n",
       " \n",
       "        [[ 36,  60,  66],\n",
       "         [ 38,  67,  72],\n",
       "         [ 42,  69,  73],\n",
       "         ...,\n",
       "         [209, 209, 223],\n",
       "         [210, 210, 224],\n",
       "         [209, 209, 223]],\n",
       " \n",
       "        [[ 36,  62,  69],\n",
       "         [ 41,  70,  75],\n",
       "         [ 40,  69,  73],\n",
       "         ...,\n",
       "         [210, 210, 224],\n",
       "         [210, 210, 224],\n",
       "         [210, 210, 224]]], dtype=uint8),\n",
       " array([[[123, 137, 159],\n",
       "         [118, 132, 154],\n",
       "         [118, 132, 154],\n",
       "         ...,\n",
       "         [102, 133, 164],\n",
       "         [100, 131, 162],\n",
       "         [ 98, 129, 160]],\n",
       " \n",
       "        [[122, 139, 160],\n",
       "         [120, 137, 158],\n",
       "         [120, 137, 158],\n",
       "         ...,\n",
       "         [104, 133, 164],\n",
       "         [100, 131, 162],\n",
       "         [ 99, 130, 161]],\n",
       " \n",
       "        [[116, 134, 157],\n",
       "         [118, 136, 159],\n",
       "         [121, 137, 160],\n",
       "         ...,\n",
       "         [104, 133, 164],\n",
       "         [102, 133, 164],\n",
       "         [102, 133, 164]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 93, 165, 207],\n",
       "         [ 92, 152, 198],\n",
       "         [ 59, 112, 155],\n",
       "         ...,\n",
       "         [  6,  35,  74],\n",
       "         [ 82, 120, 154],\n",
       "         [ 14,  59,  72]],\n",
       " \n",
       "        [[ 55, 115, 161],\n",
       "         [ 67, 117, 163],\n",
       "         [ 46,  90, 131],\n",
       "         ...,\n",
       "         [ 23,  46,  92],\n",
       "         [ 59,  94, 137],\n",
       "         [ 25,  62,  90]],\n",
       " \n",
       "        [[ 58, 113, 164],\n",
       "         [ 34,  81, 125],\n",
       "         [ 38,  77, 115],\n",
       "         ...,\n",
       "         [ 23,  52,  96],\n",
       "         [ 57,  99, 144],\n",
       "         [ 45,  78, 117]]], dtype=uint8),\n",
       " array([[[214, 223, 227],\n",
       "         [214, 223, 227],\n",
       "         [214, 223, 227],\n",
       "         ...,\n",
       "         [218, 229, 233],\n",
       "         [218, 229, 233],\n",
       "         [218, 229, 233]],\n",
       " \n",
       "        [[214, 223, 227],\n",
       "         [214, 223, 227],\n",
       "         [214, 223, 227],\n",
       "         ...,\n",
       "         [218, 229, 233],\n",
       "         [218, 229, 233],\n",
       "         [218, 229, 233]],\n",
       " \n",
       "        [[214, 223, 227],\n",
       "         [214, 223, 227],\n",
       "         [214, 223, 227],\n",
       "         ...,\n",
       "         [218, 229, 233],\n",
       "         [218, 229, 233],\n",
       "         [218, 229, 233]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[158, 167, 171],\n",
       "         [200, 209, 213],\n",
       "         [208, 217, 221],\n",
       "         ...,\n",
       "         [214, 225, 229],\n",
       "         [213, 224, 228],\n",
       "         [213, 224, 228]],\n",
       " \n",
       "        [[144, 153, 157],\n",
       "         [193, 202, 206],\n",
       "         [206, 215, 219],\n",
       "         ...,\n",
       "         [216, 227, 231],\n",
       "         [215, 226, 230],\n",
       "         [215, 226, 230]],\n",
       " \n",
       "        [[139, 148, 152],\n",
       "         [187, 196, 200],\n",
       "         [200, 209, 213],\n",
       "         ...,\n",
       "         [216, 227, 231],\n",
       "         [215, 226, 230],\n",
       "         [215, 226, 230]]], dtype=uint8),\n",
       " array([[[ 93, 121, 145],\n",
       "         [ 95, 121, 145],\n",
       "         [ 98, 122, 144],\n",
       "         ...,\n",
       "         [ 79, 113, 142],\n",
       "         [ 77, 111, 140],\n",
       "         [ 81, 115, 144]],\n",
       " \n",
       "        [[ 94, 122, 146],\n",
       "         [ 95, 121, 145],\n",
       "         [ 98, 122, 144],\n",
       "         ...,\n",
       "         [ 80, 114, 143],\n",
       "         [ 78, 112, 141],\n",
       "         [ 79, 113, 142]],\n",
       " \n",
       "        [[ 97, 125, 149],\n",
       "         [ 97, 123, 147],\n",
       "         [ 98, 122, 144],\n",
       "         ...,\n",
       "         [ 81, 115, 144],\n",
       "         [ 79, 113, 142],\n",
       "         [ 78, 112, 141]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[169, 171, 172],\n",
       "         [168, 170, 171],\n",
       "         [168, 170, 171],\n",
       "         ...,\n",
       "         [ 85,  97, 101],\n",
       "         [ 78,  90,  96],\n",
       "         [ 73,  82,  91]],\n",
       " \n",
       "        [[168, 170, 171],\n",
       "         [168, 170, 171],\n",
       "         [168, 170, 171],\n",
       "         ...,\n",
       "         [ 93, 105, 111],\n",
       "         [ 82,  95, 103],\n",
       "         [ 77,  88,  96]],\n",
       " \n",
       "        [[167, 169, 170],\n",
       "         [168, 170, 171],\n",
       "         [167, 169, 170],\n",
       "         ...,\n",
       "         [ 88, 102, 108],\n",
       "         [ 78,  94, 101],\n",
       "         [ 74,  87,  95]]], dtype=uint8),\n",
       " array([[[ 25,  90,  75],\n",
       "         [ 27,  92,  77],\n",
       "         [ 34,  98,  79],\n",
       "         ...,\n",
       "         [ 40,  83,  72],\n",
       "         [ 34,  81,  65],\n",
       "         [ 34,  81,  65]],\n",
       " \n",
       "        [[ 27,  92,  77],\n",
       "         [ 28,  93,  78],\n",
       "         [ 30,  96,  77],\n",
       "         ...,\n",
       "         [ 37,  80,  69],\n",
       "         [ 34,  81,  65],\n",
       "         [ 34,  83,  67]],\n",
       " \n",
       "        [[ 22,  90,  73],\n",
       "         [ 26,  94,  77],\n",
       "         [ 28,  94,  75],\n",
       "         ...,\n",
       "         [ 31,  73,  62],\n",
       "         [ 31,  77,  64],\n",
       "         [ 35,  84,  70]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 73, 122,  94],\n",
       "         [ 80, 127, 101],\n",
       "         [ 44,  85,  64],\n",
       "         ...,\n",
       "         [ 47,  87,  62],\n",
       "         [ 47,  88,  57],\n",
       "         [ 44,  83,  51]],\n",
       " \n",
       "        [[ 95, 149, 120],\n",
       "         [ 60, 108,  82],\n",
       "         [ 47,  89,  66],\n",
       "         ...,\n",
       "         [ 71, 110,  95],\n",
       "         [ 78, 119,  98],\n",
       "         [ 63, 102,  80]],\n",
       " \n",
       "        [[ 82, 137, 112],\n",
       "         [ 76, 125, 103],\n",
       "         [ 95, 136, 115],\n",
       "         ...,\n",
       "         [ 44,  84,  82],\n",
       "         [ 52,  97,  88],\n",
       "         [ 70, 116, 104]]], dtype=uint8),\n",
       " array([[[116, 130, 106],\n",
       "         [116, 130, 106],\n",
       "         [113, 129, 105],\n",
       "         ...,\n",
       "         [ 52,  35,  56],\n",
       "         [ 56,  35,  57],\n",
       "         [ 57,  34,  56]],\n",
       " \n",
       "        [[117, 131, 107],\n",
       "         [116, 130, 106],\n",
       "         [115, 129, 105],\n",
       "         ...,\n",
       "         [ 58,  44,  62],\n",
       "         [ 64,  45,  64],\n",
       "         [ 66,  46,  65]],\n",
       " \n",
       "        [[118, 131, 107],\n",
       "         [116, 130, 106],\n",
       "         [115, 128, 106],\n",
       "         ...,\n",
       "         [ 60,  49,  65],\n",
       "         [ 67,  51,  68],\n",
       "         [ 70,  52,  69]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[103, 129,  76],\n",
       "         [103, 129,  76],\n",
       "         [103, 128,  78],\n",
       "         ...,\n",
       "         [ 34,  75,  67],\n",
       "         [ 42,  79,  69],\n",
       "         [ 48,  83,  73]],\n",
       " \n",
       "        [[106, 129,  77],\n",
       "         [106, 129,  77],\n",
       "         [105, 131,  78],\n",
       "         ...,\n",
       "         [ 43,  89,  77],\n",
       "         [ 45,  87,  76],\n",
       "         [ 49,  89,  78]],\n",
       " \n",
       "        [[106, 129,  77],\n",
       "         [107, 130,  78],\n",
       "         [106, 132,  79],\n",
       "         ...,\n",
       "         [ 54, 102,  90],\n",
       "         [ 54,  97,  86],\n",
       "         [ 52,  94,  83]]], dtype=uint8),\n",
       " array([[[ 3,  1,  1],\n",
       "         [ 3,  1,  1],\n",
       "         [ 3,  1,  1],\n",
       "         ...,\n",
       "         [73, 74, 70],\n",
       "         [74, 75, 73],\n",
       "         [73, 74, 72]],\n",
       " \n",
       "        [[ 3,  1,  1],\n",
       "         [ 3,  1,  1],\n",
       "         [ 3,  1,  1],\n",
       "         ...,\n",
       "         [69, 70, 66],\n",
       "         [73, 74, 72],\n",
       "         [74, 75, 73]],\n",
       " \n",
       "        [[ 4,  2,  2],\n",
       "         [ 4,  2,  2],\n",
       "         [ 2,  2,  2],\n",
       "         ...,\n",
       "         [61, 62, 58],\n",
       "         [66, 67, 65],\n",
       "         [70, 71, 69]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  6,  4],\n",
       "         [13, 14, 12],\n",
       "         [21, 22, 20],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  1,  1]],\n",
       " \n",
       "        [[ 3,  4,  2],\n",
       "         [10, 11,  9],\n",
       "         [15, 16, 14],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  1,  1]],\n",
       " \n",
       "        [[ 1,  2,  0],\n",
       "         [ 6,  7,  5],\n",
       "         [ 9, 10,  8],\n",
       "         ...,\n",
       "         [ 0,  3,  1],\n",
       "         [ 0,  1,  1],\n",
       "         [ 0,  2,  2]]], dtype=uint8),\n",
       " array([[[ 24,  36,  42],\n",
       "         [ 21,  33,  37],\n",
       "         [ 24,  36,  40],\n",
       "         ...,\n",
       "         [ 40,  69, 106],\n",
       "         [ 61,  89, 124],\n",
       "         [ 47,  75, 110]],\n",
       " \n",
       "        [[ 24,  36,  42],\n",
       "         [ 24,  36,  40],\n",
       "         [ 23,  35,  39],\n",
       "         ...,\n",
       "         [ 44,  71, 108],\n",
       "         [ 66,  92, 129],\n",
       "         [ 57,  83, 119]],\n",
       " \n",
       "        [[ 20,  32,  38],\n",
       "         [ 25,  37,  41],\n",
       "         [ 22,  34,  38],\n",
       "         ...,\n",
       "         [ 50,  76, 113],\n",
       "         [ 60,  83, 121],\n",
       "         [ 58,  79, 117]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 58,  76,  87],\n",
       "         [ 59,  77,  88],\n",
       "         [ 58,  75,  84],\n",
       "         ...,\n",
       "         [ 69,  97, 104],\n",
       "         [ 68,  97, 104],\n",
       "         [ 69,  98, 105]],\n",
       " \n",
       "        [[ 59,  77,  88],\n",
       "         [ 57,  75,  86],\n",
       "         [ 59,  76,  85],\n",
       "         ...,\n",
       "         [ 65,  93, 100],\n",
       "         [ 65,  95, 100],\n",
       "         [ 66,  96, 101]],\n",
       " \n",
       "        [[ 58,  76,  87],\n",
       "         [ 60,  78,  89],\n",
       "         [ 56,  73,  82],\n",
       "         ...,\n",
       "         [ 66,  94, 101],\n",
       "         [ 66,  96, 101],\n",
       "         [ 66,  96, 101]]], dtype=uint8),\n",
       " array([[[ 35,  83,  31],\n",
       "         [ 44,  92,  40],\n",
       "         [ 52,  97,  48],\n",
       "         ...,\n",
       "         [ 49, 104,  35],\n",
       "         [ 46, 100,  31],\n",
       "         [ 41,  92,  24]],\n",
       " \n",
       "        [[ 42,  90,  38],\n",
       "         [ 51,  99,  47],\n",
       "         [ 61, 106,  57],\n",
       "         ...,\n",
       "         [ 60, 115,  46],\n",
       "         [ 61, 112,  44],\n",
       "         [ 54, 105,  37]],\n",
       " \n",
       "        [[ 41,  87,  35],\n",
       "         [ 51,  97,  45],\n",
       "         [ 62, 104,  56],\n",
       "         ...,\n",
       "         [ 64, 118,  51],\n",
       "         [ 66, 117,  49],\n",
       "         [ 62, 111,  43]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61, 107,  48],\n",
       "         [ 64, 110,  51],\n",
       "         [ 64, 110,  51],\n",
       "         ...,\n",
       "         [ 97, 102,  63],\n",
       "         [ 94,  99,  60],\n",
       "         [ 87,  92,  53]],\n",
       " \n",
       "        [[ 56, 101,  44],\n",
       "         [ 60, 105,  48],\n",
       "         [ 57, 105,  47],\n",
       "         ...,\n",
       "         [ 96,  98,  62],\n",
       "         [ 93,  95,  59],\n",
       "         [ 86,  88,  52]],\n",
       " \n",
       "        [[ 45,  90,  33],\n",
       "         [ 49,  94,  37],\n",
       "         [ 47,  95,  37],\n",
       "         ...,\n",
       "         [ 86,  88,  52],\n",
       "         [ 83,  85,  49],\n",
       "         [ 76,  78,  42]]], dtype=uint8),\n",
       " array([[[ 21,  52,  23],\n",
       "         [ 21,  52,  23],\n",
       "         [ 17,  51,  21],\n",
       "         ...,\n",
       "         [ 24,  65,  34],\n",
       "         [ 19,  60,  33],\n",
       "         [ 17,  60,  33]],\n",
       " \n",
       "        [[ 22,  53,  26],\n",
       "         [ 22,  53,  24],\n",
       "         [ 18,  51,  24],\n",
       "         ...,\n",
       "         [ 29,  69,  41],\n",
       "         [ 25,  65,  37],\n",
       "         [ 23,  62,  36]],\n",
       " \n",
       "        [[ 31,  61,  36],\n",
       "         [ 30,  61,  34],\n",
       "         [ 26,  58,  33],\n",
       "         ...,\n",
       "         [ 20,  58,  30],\n",
       "         [ 23,  56,  29],\n",
       "         [ 24,  55,  28]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 29,  93,  58],\n",
       "         [ 37, 100,  68],\n",
       "         [ 64, 124,  93],\n",
       "         ...,\n",
       "         [ 44,  93,  77],\n",
       "         [ 42,  95,  81],\n",
       "         [ 45,  99,  86]],\n",
       " \n",
       "        [[ 34,  94,  64],\n",
       "         [ 32,  92,  61],\n",
       "         [ 43, 104,  70],\n",
       "         ...,\n",
       "         [  0,  43,  27],\n",
       "         [  0,  46,  34],\n",
       "         [ 17,  67,  57]],\n",
       " \n",
       "        [[ 39,  97,  69],\n",
       "         [ 26,  84,  55],\n",
       "         [ 16,  76,  42],\n",
       "         ...,\n",
       "         [  0,  35,  19],\n",
       "         [  0,  27,  17],\n",
       "         [  2,  41,  33]]], dtype=uint8),\n",
       " array([[[ 20,  24,  12],\n",
       "         [ 21,  25,  13],\n",
       "         [ 19,  23,  11],\n",
       "         ...,\n",
       "         [117, 137, 142],\n",
       "         [110, 129, 134],\n",
       "         [117, 136, 141]],\n",
       " \n",
       "        [[ 25,  29,  17],\n",
       "         [ 25,  32,  19],\n",
       "         [ 28,  32,  20],\n",
       "         ...,\n",
       "         [128, 148, 153],\n",
       "         [118, 138, 143],\n",
       "         [113, 133, 138]],\n",
       " \n",
       "        [[ 39,  46,  33],\n",
       "         [ 48,  57,  44],\n",
       "         [ 40,  47,  34],\n",
       "         ...,\n",
       "         [109, 131, 136],\n",
       "         [ 99, 122, 124],\n",
       "         [ 80, 103, 105]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 10,   2,   2],\n",
       "         [  8,   0,   0],\n",
       "         [  8,   1,   0],\n",
       "         ...,\n",
       "         [ 53, 201, 137],\n",
       "         [ 54, 200, 136],\n",
       "         [ 53, 199, 135]],\n",
       " \n",
       "        [[ 11,   3,   3],\n",
       "         [  9,   1,   1],\n",
       "         [  9,   2,   0],\n",
       "         ...,\n",
       "         [ 57, 203, 139],\n",
       "         [ 57, 200, 137],\n",
       "         [ 55, 198, 135]],\n",
       " \n",
       "        [[ 13,   3,   3],\n",
       "         [ 13,   3,   3],\n",
       "         [ 10,   3,   0],\n",
       "         ...,\n",
       "         [ 59, 204, 142],\n",
       "         [ 58, 201, 138],\n",
       "         [ 56, 197, 134]]], dtype=uint8),\n",
       " array([[[ 99, 125, 119],\n",
       "         [103, 129, 123],\n",
       "         [115, 136, 134],\n",
       "         ...,\n",
       "         [120, 129, 139],\n",
       "         [126, 132, 145],\n",
       "         [131, 134, 149]],\n",
       " \n",
       "        [[ 99, 125, 119],\n",
       "         [105, 128, 123],\n",
       "         [114, 135, 133],\n",
       "         ...,\n",
       "         [116, 126, 136],\n",
       "         [128, 134, 147],\n",
       "         [135, 138, 153]],\n",
       " \n",
       "        [[ 97, 120, 115],\n",
       "         [106, 129, 124],\n",
       "         [118, 139, 137],\n",
       "         ...,\n",
       "         [107, 118, 126],\n",
       "         [120, 126, 139],\n",
       "         [124, 129, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[126, 158, 164],\n",
       "         [119, 150, 159],\n",
       "         [116, 144, 155],\n",
       "         ...,\n",
       "         [123, 139, 145],\n",
       "         [110, 123, 131],\n",
       "         [ 98, 110, 120]],\n",
       " \n",
       "        [[129, 161, 167],\n",
       "         [120, 151, 160],\n",
       "         [111, 137, 149],\n",
       "         ...,\n",
       "         [120, 136, 142],\n",
       "         [112, 124, 134],\n",
       "         [103, 113, 123]],\n",
       " \n",
       "        [[126, 158, 164],\n",
       "         [119, 150, 159],\n",
       "         [108, 134, 146],\n",
       "         ...,\n",
       "         [122, 141, 146],\n",
       "         [134, 146, 156],\n",
       "         [134, 144, 154]]], dtype=uint8),\n",
       " array([[[ 52,  90,  72],\n",
       "         [ 52,  92,  74],\n",
       "         [ 39,  80,  59],\n",
       "         ...,\n",
       "         [119, 123, 124],\n",
       "         [116, 121, 124],\n",
       "         [124, 129, 132]],\n",
       " \n",
       "        [[ 55,  91,  74],\n",
       "         [ 58,  97,  76],\n",
       "         [ 48,  89,  68],\n",
       "         ...,\n",
       "         [126, 130, 131],\n",
       "         [121, 126, 129],\n",
       "         [126, 131, 134]],\n",
       " \n",
       "        [[ 67, 102,  82],\n",
       "         [ 70, 105,  85],\n",
       "         [ 65, 103,  81],\n",
       "         ...,\n",
       "         [126, 131, 132],\n",
       "         [120, 125, 128],\n",
       "         [119, 124, 127]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[214, 210, 215],\n",
       "         [215, 211, 216],\n",
       "         [215, 211, 216],\n",
       "         ...,\n",
       "         [ 48,  65,  84],\n",
       "         [ 54,  68,  90],\n",
       "         [ 57,  74,  95]],\n",
       " \n",
       "        [[215, 211, 216],\n",
       "         [219, 215, 220],\n",
       "         [220, 216, 222],\n",
       "         ...,\n",
       "         [ 54,  68,  90],\n",
       "         [ 53,  67,  89],\n",
       "         [ 53,  67,  90]],\n",
       " \n",
       "        [[216, 212, 218],\n",
       "         [220, 216, 222],\n",
       "         [220, 217, 226],\n",
       "         ...,\n",
       "         [ 49,  61,  85],\n",
       "         [ 52,  63,  90],\n",
       "         [ 55,  66,  93]]], dtype=uint8),\n",
       " array([[[105, 106, 104],\n",
       "         [ 95, 103,  96],\n",
       "         [ 81,  93,  81],\n",
       "         ...,\n",
       "         [ 95,  70,  84],\n",
       "         [ 95,  71,  83],\n",
       "         [ 97,  73,  83]],\n",
       " \n",
       "        [[ 92,  92,  92],\n",
       "         [ 85,  93,  86],\n",
       "         [ 80,  90,  77],\n",
       "         ...,\n",
       "         [ 95,  71,  83],\n",
       "         [ 97,  73,  85],\n",
       "         [100,  75,  89]],\n",
       " \n",
       "        [[ 84,  87,  85],\n",
       "         [ 86,  90,  84],\n",
       "         [ 84,  92,  81],\n",
       "         ...,\n",
       "         [ 92,  68,  80],\n",
       "         [ 95,  71,  83],\n",
       "         [ 96,  71,  85]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 96, 120, 108],\n",
       "         [119, 140, 125],\n",
       "         [122, 148, 132],\n",
       "         ...,\n",
       "         [ 83,  73,  79],\n",
       "         [ 62,  55,  60],\n",
       "         [ 61,  50,  58]],\n",
       " \n",
       "        [[113, 135, 116],\n",
       "         [128, 149, 124],\n",
       "         [121, 149, 129],\n",
       "         ...,\n",
       "         [ 74,  67,  72],\n",
       "         [ 65,  54,  62],\n",
       "         [ 59,  46,  54]],\n",
       " \n",
       "        [[138, 161, 139],\n",
       "         [128, 154, 131],\n",
       "         [118, 149, 134],\n",
       "         ...,\n",
       "         [ 75,  69,  74],\n",
       "         [ 65,  54,  62],\n",
       "         [ 59,  46,  54]]], dtype=uint8),\n",
       " array([[[148, 172, 172],\n",
       "         [148, 172, 172],\n",
       "         [148, 172, 172],\n",
       "         ...,\n",
       "         [153, 171, 194],\n",
       "         [153, 171, 194],\n",
       "         [152, 170, 193]],\n",
       " \n",
       "        [[148, 172, 172],\n",
       "         [148, 172, 172],\n",
       "         [148, 172, 172],\n",
       "         ...,\n",
       "         [155, 173, 196],\n",
       "         [154, 172, 195],\n",
       "         [154, 172, 195]],\n",
       " \n",
       "        [[147, 171, 171],\n",
       "         [147, 171, 171],\n",
       "         [147, 171, 171],\n",
       "         ...,\n",
       "         [156, 174, 197],\n",
       "         [155, 173, 196],\n",
       "         [155, 173, 196]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 13,  19,  18],\n",
       "         [ 14,  20,  19],\n",
       "         [ 18,  24,  23],\n",
       "         ...,\n",
       "         [169, 198, 219],\n",
       "         [169, 198, 219],\n",
       "         [170, 199, 220]],\n",
       " \n",
       "        [[ 14,  20,  19],\n",
       "         [ 15,  21,  20],\n",
       "         [ 18,  25,  22],\n",
       "         ...,\n",
       "         [171, 200, 221],\n",
       "         [171, 200, 221],\n",
       "         [171, 200, 221]],\n",
       " \n",
       "        [[ 14,  20,  19],\n",
       "         [ 15,  21,  20],\n",
       "         [ 18,  25,  22],\n",
       "         ...,\n",
       "         [172, 201, 222],\n",
       "         [172, 201, 222],\n",
       "         [172, 201, 222]]], dtype=uint8),\n",
       " array([[[114, 114, 120],\n",
       "         [115, 116, 120],\n",
       "         [116, 117, 121],\n",
       "         ...,\n",
       "         [130, 129, 131],\n",
       "         [130, 129, 131],\n",
       "         [130, 129, 131]],\n",
       " \n",
       "        [[114, 114, 120],\n",
       "         [115, 116, 120],\n",
       "         [116, 117, 121],\n",
       "         ...,\n",
       "         [131, 130, 132],\n",
       "         [131, 130, 132],\n",
       "         [132, 131, 133]],\n",
       " \n",
       "        [[114, 114, 120],\n",
       "         [115, 116, 120],\n",
       "         [115, 116, 120],\n",
       "         ...,\n",
       "         [132, 132, 132],\n",
       "         [133, 133, 133],\n",
       "         [133, 133, 133]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 92,  90,  89],\n",
       "         [ 94,  90,  89],\n",
       "         [ 94,  89,  88],\n",
       "         ...,\n",
       "         [ 37,  75, 107],\n",
       "         [ 41,  76, 109],\n",
       "         [ 42,  77, 110]],\n",
       " \n",
       "        [[ 92,  90,  89],\n",
       "         [ 94,  90,  89],\n",
       "         [ 94,  89,  88],\n",
       "         ...,\n",
       "         [ 38,  76, 108],\n",
       "         [ 41,  76, 109],\n",
       "         [ 42,  77, 110]],\n",
       " \n",
       "        [[ 91,  89,  88],\n",
       "         [ 93,  89,  88],\n",
       "         [ 94,  89,  88],\n",
       "         ...,\n",
       "         [ 39,  77, 109],\n",
       "         [ 42,  77, 110],\n",
       "         [ 43,  78, 111]]], dtype=uint8),\n",
       " array([[[123, 138, 154],\n",
       "         [123, 138, 154],\n",
       "         [123, 138, 154],\n",
       "         ...,\n",
       "         [ 76,  89, 115],\n",
       "         [ 76,  89, 115],\n",
       "         [ 76,  90, 113]],\n",
       " \n",
       "        [[121, 136, 152],\n",
       "         [122, 137, 153],\n",
       "         [122, 137, 153],\n",
       "         ...,\n",
       "         [ 76,  89, 115],\n",
       "         [ 76,  89, 115],\n",
       "         [ 76,  90, 113]],\n",
       " \n",
       "        [[120, 135, 151],\n",
       "         [120, 135, 151],\n",
       "         [120, 135, 151],\n",
       "         ...,\n",
       "         [ 77,  90, 116],\n",
       "         [ 77,  90, 116],\n",
       "         [ 77,  90, 116]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[177, 194, 191],\n",
       "         [174, 191, 188],\n",
       "         [174, 188, 186],\n",
       "         ...,\n",
       "         [160, 186, 198],\n",
       "         [160, 186, 198],\n",
       "         [160, 186, 200]],\n",
       " \n",
       "        [[176, 193, 190],\n",
       "         [175, 192, 189],\n",
       "         [176, 190, 188],\n",
       "         ...,\n",
       "         [163, 190, 200],\n",
       "         [163, 190, 200],\n",
       "         [163, 189, 201]],\n",
       " \n",
       "        [[175, 192, 189],\n",
       "         [175, 192, 189],\n",
       "         [179, 193, 191],\n",
       "         ...,\n",
       "         [164, 191, 201],\n",
       "         [164, 191, 201],\n",
       "         [164, 191, 201]]], dtype=uint8),\n",
       " array([[[ 43,  82,  30],\n",
       "         [ 43,  82,  30],\n",
       "         [ 41,  79,  29],\n",
       "         ...,\n",
       "         [ 54,  82,  52],\n",
       "         [ 53,  81,  51],\n",
       "         [ 53,  81,  51]],\n",
       " \n",
       "        [[ 30,  69,  17],\n",
       "         [ 36,  75,  23],\n",
       "         [ 41,  79,  29],\n",
       "         ...,\n",
       "         [ 57,  85,  55],\n",
       "         [ 56,  84,  54],\n",
       "         [ 56,  84,  54]],\n",
       " \n",
       "        [[ 24,  63,  11],\n",
       "         [ 35,  74,  22],\n",
       "         [ 46,  84,  34],\n",
       "         ...,\n",
       "         [ 61,  86,  58],\n",
       "         [ 60,  85,  57],\n",
       "         [ 60,  85,  57]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 53, 115,  49],\n",
       "         [ 51, 113,  47],\n",
       "         [ 49, 110,  42],\n",
       "         ...,\n",
       "         [103,  99,  98],\n",
       "         [104, 100,  99],\n",
       "         [105, 101, 100]],\n",
       " \n",
       "        [[ 46, 108,  42],\n",
       "         [ 48, 110,  44],\n",
       "         [ 49, 112,  43],\n",
       "         ...,\n",
       "         [114, 110, 109],\n",
       "         [120, 115, 116],\n",
       "         [119, 117, 117]],\n",
       " \n",
       "        [[ 46, 108,  42],\n",
       "         [ 48, 110,  44],\n",
       "         [ 49, 112,  43],\n",
       "         ...,\n",
       "         [116, 112, 111],\n",
       "         [120, 118, 118],\n",
       "         [122, 120, 120]]], dtype=uint8),\n",
       " array([[[18, 30, 18],\n",
       "         [13, 23, 11],\n",
       "         [ 8, 18,  6],\n",
       "         ...,\n",
       "         [19, 29, 17],\n",
       "         [15, 32, 18],\n",
       "         [22, 41, 24]],\n",
       " \n",
       "        [[17, 32, 18],\n",
       "         [ 9, 22,  8],\n",
       "         [ 6, 18,  6],\n",
       "         ...,\n",
       "         [18, 31, 17],\n",
       "         [16, 32, 14],\n",
       "         [25, 41, 23]],\n",
       " \n",
       "        [[23, 39, 22],\n",
       "         [16, 29, 15],\n",
       "         [ 5, 18,  4],\n",
       "         ...,\n",
       "         [15, 37, 19],\n",
       "         [20, 40, 21],\n",
       "         [20, 41, 19]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[22, 63, 42],\n",
       "         [39, 75, 59],\n",
       "         [52, 76, 66],\n",
       "         ...,\n",
       "         [26, 83, 58],\n",
       "         [22, 78, 49],\n",
       "         [19, 73, 43]],\n",
       " \n",
       "        [[27, 71, 54],\n",
       "         [47, 86, 70],\n",
       "         [29, 62, 48],\n",
       "         ...,\n",
       "         [28, 80, 62],\n",
       "         [27, 77, 59],\n",
       "         [22, 72, 54]],\n",
       " \n",
       "        [[49, 87, 69],\n",
       "         [41, 77, 60],\n",
       "         [48, 82, 65],\n",
       "         ...,\n",
       "         [36, 91, 66],\n",
       "         [34, 84, 66],\n",
       "         [31, 80, 64]]], dtype=uint8),\n",
       " array([[[ 65,  99, 105],\n",
       "         [120, 155, 159],\n",
       "         [169, 201, 206],\n",
       "         ...,\n",
       "         [160, 199, 197],\n",
       "         [122, 161, 159],\n",
       "         [105, 144, 142]],\n",
       " \n",
       "        [[ 79, 114, 118],\n",
       "         [139, 174, 178],\n",
       "         [157, 189, 194],\n",
       "         ...,\n",
       "         [157, 196, 194],\n",
       "         [124, 164, 162],\n",
       "         [ 96, 136, 134]],\n",
       " \n",
       "        [[108, 145, 149],\n",
       "         [129, 164, 168],\n",
       "         [135, 168, 171],\n",
       "         ...,\n",
       "         [142, 182, 180],\n",
       "         [124, 164, 162],\n",
       "         [103, 143, 142]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 84, 110, 127],\n",
       "         [140, 166, 183],\n",
       "         [117, 145, 162],\n",
       "         ...,\n",
       "         [ 85, 141, 128],\n",
       "         [ 70, 126, 115],\n",
       "         [ 26,  69,  60]],\n",
       " \n",
       "        [[ 67,  95, 112],\n",
       "         [116, 144, 161],\n",
       "         [133, 161, 178],\n",
       "         ...,\n",
       "         [ 71, 125, 112],\n",
       "         [ 45, 101,  88],\n",
       "         [ 25,  71,  59]],\n",
       " \n",
       "        [[ 67,  95, 112],\n",
       "         [ 78, 106, 123],\n",
       "         [153, 183, 200],\n",
       "         ...,\n",
       "         [ 50, 103,  89],\n",
       "         [ 14,  73,  59],\n",
       "         [  7,  57,  45]]], dtype=uint8),\n",
       " array([[[ 88, 115, 111],\n",
       "         [ 92, 117, 113],\n",
       "         [ 98, 120, 118],\n",
       "         ...,\n",
       "         [  0,   2,   1],\n",
       "         [  0,   2,   2],\n",
       "         [  2,   2,   2]],\n",
       " \n",
       "        [[ 88, 115, 111],\n",
       "         [ 93, 118, 114],\n",
       "         [ 98, 120, 118],\n",
       "         ...,\n",
       "         [  0,   2,   1],\n",
       "         [  0,   2,   2],\n",
       "         [  2,   2,   2]],\n",
       " \n",
       "        [[ 91, 116, 112],\n",
       "         [ 93, 118, 114],\n",
       "         [ 98, 120, 118],\n",
       "         ...,\n",
       "         [  0,   2,   1],\n",
       "         [  0,   2,   2],\n",
       "         [  2,   2,   2]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 67,  98,  91],\n",
       "         [ 71, 102,  95],\n",
       "         [ 76, 105, 102],\n",
       "         ...,\n",
       "         [ 56,  74,  67],\n",
       "         [ 56,  74,  67],\n",
       "         [ 56,  74,  67]],\n",
       " \n",
       "        [[ 71, 101,  96],\n",
       "         [ 70, 100,  95],\n",
       "         [ 74, 101,  97],\n",
       "         ...,\n",
       "         [ 56,  74,  67],\n",
       "         [ 56,  74,  67],\n",
       "         [ 56,  74,  67]],\n",
       " \n",
       "        [[ 78, 108, 103],\n",
       "         [ 70, 100,  95],\n",
       "         [ 71,  99,  93],\n",
       "         ...,\n",
       "         [ 56,  74,  67],\n",
       "         [ 56,  74,  67],\n",
       "         [ 56,  74,  67]]], dtype=uint8)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cheetah_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
